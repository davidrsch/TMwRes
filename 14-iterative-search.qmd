```{r iterative-setup, include = FALSE, cache=FALSE}
knitr::opts_chunk$set(fig.path = "figures/")
library(tidymodels)
library(finetune)
library(patchwork)
library(kableExtra)
library(av)
library(doMC)
registerDoMC(cores = parallel::detectCores(logical = TRUE))
tidymodels_prefer()

source("extras/verify_results.R")
source("extras/sa_2d_plot.R")
source("extras/bo_3panel_plot.R")
load(file.path("RData", "svm_large.RData"))


data(cells)
cells <- cells %>% select(-case)
set.seed(1304)
cell_folds <- vfold_cv(cells)
roc_res <- metric_set(roc_auc)
```

# Búsqueda iterativa {#sec-iterative-search}

El [Capítulo @sec-grid-search] demostró cómo la búsqueda en cuadrícula toma un conjunto predefinido de valores candidatos, los evalúa y luego elige la mejor configuración. Los métodos de búsqueda iterativos siguen una estrategia diferente. Durante el proceso de búsqueda, predicen qué valores probar a continuación.

::: rmdnote
Cuando la búsqueda en cuadrícula no es factible o ineficiente, los métodos iterativos son un enfoque sensato para optimizar los parámetros de ajuste.
:::

Este capítulo describe dos métodos de búsqueda. Primero, analizamos la *optimización bayesiana*, que utiliza un modelo estadístico para predecir mejores configuraciones de parámetros. Después de eso, el capítulo describe un método de búsqueda global llamado *recocido simulado*.

Usamos los mismos datos sobre las características de las células que en el capítulo anterior a modo de ilustración, pero cambiamos el modelo. Este capítulo utiliza un modelo de máquina de vectores de soporte porque proporciona bonitas visualizaciones bidimensionales de los procesos de búsqueda.

## Un modelo de máquina de vectores de soporte {#sec-svm}

Una vez más utilizamos los datos de segmentación de celdas, descritos en @sec-evaluating-grid, para modelar, con un modelo de máquina de vectores de soporte (SVM) para demostrar métodos de ajuste secuencial. Consulte @apm para obtener más información sobre este modelo. Los dos parámetros de ajuste a optimizar son el valor del costo de SVM y el parámetro del núcleo de la función de base radial $\sigma$. Ambos parámetros pueden tener un efecto profundo en la complejidad y el rendimiento del modelo.

El modelo SVM utiliza un producto escalar y, por este motivo, es necesario centrar y escalar los predictores. Al igual que el modelo de perceptrón multicapa, este modelo se beneficiaría del uso de la extracción de características PCA. Sin embargo, no utilizaremos este tercer parámetro de ajuste en este capítulo para que podamos visualizar el proceso de búsqueda en dos dimensiones.

Junto con los objetos utilizados anteriormente (que se muestran en @sec-grid-summary), los objetos tidymodels `svm_rec`, `svm_spec` y `svm_wflow` definen el proceso del modelo:

```{r iterative-svm-defs, message = FALSE}
library(tidymodels)
tidymodels_prefer()

svm_rec <- 
  recipe(class ~ ., data = cells) %>%
  step_YeoJohnson(all_numeric_predictors()) %>%
  step_normalize(all_numeric_predictors())

svm_spec <- 
  svm_rbf(cost = tune(), rbf_sigma = tune()) %>% 
  set_engine("kernlab") %>% 
  set_mode("classification")

svm_wflow <- 
  workflow() %>% 
  add_model(svm_spec) %>% 
  add_recipe(svm_rec)
```

Los rangos de parámetros predeterminados para los dos parámetros de ajuste `cost` y `rbf_sigma` son:

```{r iterative-svm-param}
cost()
rbf_sigma()
```

A modo de ilustración, cambiemos ligeramente el rango de parámetros del kernel para mejorar las visualizaciones de la búsqueda:

```{r iterative-svm-param-set}
svm_param <- 
  svm_wflow %>% 
  extract_parameter_set_dials() %>% 
  Matrix::update(rbf_sigma = rbf_sigma(c(-7, -1)))
```

Antes de analizar detalles específicos sobre la búsqueda iterativa y cómo funciona, exploremos la relación entre los dos parámetros de ajuste de SVM y el área bajo la curva ROC para este conjunto de datos específico. Construimos una cuadrícula regular muy grande, compuesta por 2500 valores candidatos, y evaluamos la cuadrícula mediante remuestreo. Obviamente, esto es poco práctico en el análisis de datos regular y tremendamente ineficiente. Sin embargo, aclara el camino que debe tomar el proceso de búsqueda y dónde ocurren los valores numéricamente óptimos.

@fig-roc-surface muestra los resultados de la evaluación de esta cuadrícula, donde el color más claro corresponde a un mayor (mejor) rendimiento del modelo. Hay una gran franja en la diagonal inferior del espacio de parámetros que es relativamente plana con un rendimiento deficiente. En la parte superior derecha del espacio se produce una cresta de mejor rendimiento. El punto negro indica la mejor configuración. La transición desde la meseta de los malos resultados a la cima del mejor desempeño es muy pronunciada. También hay una fuerte caída en el área bajo la curva ROC justo a la derecha de la cresta.

```{r}
#| label: fig-roc-surface
#| out.width: "80%"
#| echo: FALSE
#| warning: FALSE
#| fig.cap: "Mapa de calor del área media bajo la curva ROC para una cuadrícula de alta densidad de valores de parámetros de ajuste. El mejor punto es un punto sólido en la esquina superior derecha."
#| fig.alt: "Un mapa de calor del área media bajo la curva ROC para una cuadrícula de alta densidad de valores de parámetros de ajuste. El mejor punto es un punto sólido en la esquina superior derecha. La superficie tiene una cresta de alto rendimiento que se desplaza hacia la parte inferior derecha. "

# Vea archivo extras/cells_svm_large.R
knitr::include_graphics("premade/roc_surface.png")
```

Los siguientes procedimientos de búsqueda requieren al menos algunas estadísticas de rendimiento remuestreadas antes de continuar. Para ello, el siguiente código crea una pequeña cuadrícula regular que reside en la parte plana del espacio de parámetros. La función `tune_grid()` vuelve a muestrear esta cuadrícula:

```{r iterative-svm-initial, message = FALSE}
set.seed(1401)
start_grid <- 
  svm_param %>% 
  Matrix::update(
    cost = cost(c(-6, 1)),
    rbf_sigma = rbf_sigma(c(-6, -4))
  ) %>% 
  grid_regular(levels = 2)

set.seed(1402)
svm_initial <- 
  svm_wflow %>% 
  tune_grid(resamples = cell_folds, grid = start_grid, metrics = roc_res)

collect_metrics(svm_initial)
```

Esta cuadrícula inicial muestra resultados bastante equivalentes, sin que ningún punto individual sea mucho mejor que los demás. Estos resultados pueden ser absorbidos por las funciones de ajuste iterativas analizadas en las siguientes secciones para usarse como valores iniciales.

## Optimización bayesiana

Las técnicas de optimización bayesiana analizan los resultados del remuestreo actual y crean un modelo predictivo para sugerir valores de parámetros de ajuste que aún no se han evaluado. A continuación se vuelve a muestrear la combinación de parámetros sugerida. Estos resultados luego se utilizan en otro modelo predictivo que recomienda más valores candidatos para realizar pruebas, y así sucesivamente. El proceso continúa durante un número determinado de iteraciones o hasta que no se produzcan más mejoras. @Shahriari y @frazier2018tutorial son buenas introducciones a la optimización bayesiana.

Cuando se utiliza la optimización bayesiana, las principales preocupaciones son cómo crear el modelo y cómo seleccionar los parámetros recomendados por ese modelo. Primero, consideremos la técnica más comúnmente utilizada para la optimización bayesiana, el modelo de proceso gaussiano.

### Un modelo de proceso gaussiano

Los modelos de proceso gaussiano (GP) [@SCHULZ20181] son técnicas estadísticas bien conocidas que tienen una historia en la estadística espacial (bajo el nombre de *métodos de kriging*). Se pueden derivar de múltiples formas, incluso como modelo bayesiano; consulte @RaWi06 para obtener una excelente referencia.

Matemáticamente, un GP es una colección de variables aleatorias cuya distribución de probabilidad conjunta es gaussiana multivariada. En el contexto de nuestra aplicación, esta es la colección de métricas de rendimiento para los valores candidatos de los parámetros de ajuste. Para la cuadrícula inicial anterior de cuatro muestras, la realización de estas cuatro variables aleatorias fue `r knitr::combine_words(round(collect_metrics(svm_initial)$mean, 4))`. Se supone que están distribuidos como gaussianos multivariados. Las entradas que definen las variables/predictores independientes para el modelo GP son los valores de los parámetros de ajuste correspondientes (que se muestran en @tbl-initial-gp-data).

```{r}
#| label: tbl-initial-gp-data
#| echo: FALSE
#| results: "asis"
#| tbl-cap: "Estadísticas de remuestreo utilizadas como sustrato inicial del modelo de proceso gaussiano."

collect_metrics(svm_initial) %>% 
  select(ROC = mean, cost, rbf_sigma) %>% 
  as.data.frame() %>% 
  format(digits = 4, scientific = FALSE) %>% 
  kable() %>% 
  kableExtra::kable_styling(full_width = FALSE) %>% 
  kableExtra::add_header_above(c("outcome" = 1, "predictors" = 2))
```

Los modelos de procesos gaussianos se especifican por sus funciones de media y covarianza, aunque esta última tiene el mayor efecto sobre la naturaleza del modelo GP. La función de covarianza a menudo se parametriza en términos de los valores de entrada (denotados como $x$). Como ejemplo, una función de covarianza comúnmente utilizada es la función exponencial al cuadrado[^14-iterative-search-1]:

[^14-iterative-search-1]: Esta ecuación también es la misma que la *función de base radial* utilizada en los métodos del núcleo, como el modelo SVM que se utiliza actualmente. Esto es una coincidencia; esta función de covarianza no está relacionada con el parámetro de ajuste SVM que estamos usando.

$$\operatorname{cov}(\boldsymbol{x}_i, \boldsymbol{x}_j) = \exp\left(-\frac{1}{2}|\boldsymbol{x}_i - \boldsymbol{x}_j|^2\right) + \sigma^2_{ij}$$ 

donde $\sigma^2_{ij}$ es un término de varianza de error constante que es cero cuando $i=j$. Esta ecuación se traduce en:

> A medida que aumenta la distancia entre dos combinaciones de parámetros de ajuste, la covarianza entre las métricas de rendimiento aumenta exponencialmente.

La naturaleza de la ecuación también implica que la variación de la métrica del resultado se minimiza en los puntos que ya se han observado (es decir, cuando $|\boldsymbol{x}_i - \boldsymbol{x}_j|^2$ es cero) .

La naturaleza de esta función de covarianza permite que el proceso gaussiano represente relaciones altamente no lineales entre el rendimiento del modelo y los parámetros de ajuste incluso cuando sólo existe una pequeña cantidad de datos.

::: rmdwarning
Sin embargo, ajustar estos modelos puede resultar difícil en algunos casos y el modelo se vuelve más costoso computacionalmente a medida que aumenta el número de combinaciones de parámetros de ajuste.
:::

Una virtud importante de este modelo es que, dado que se especifica un modelo de probabilidad total, las predicciones de nuevos insumos pueden reflejar la distribución completa del resultado. En otras palabras, se pueden predecir nuevas estadísticas de desempeño tanto en términos de media como de varianza.

Supongamos que se estuvieran considerando dos nuevos parámetros de ajuste. En @tbl-tuning-candidates, el candidato *A* tiene un valor ROC medio ligeramente mejor que el candidato *B* (el mejor actual es `r round(max(collect_metrics(svm_initial)$mean), 4)`). Sin embargo, su varianza es cuatro veces mayor que *B*. ¿Esto es bueno o malo? Elegir la opción *A* es más riesgoso pero tiene un rendimiento potencialmente mayor. El aumento en la varianza también refleja que este nuevo valor está más alejado de los datos existentes que *B*. La siguiente sección considera con más detalle estos aspectos de las predicciones de GP para la optimización bayesiana.

```{r}
#| label: tbl-tuning-candidates
#| echo: FALSE
#| result: "asis"
#| tbl-cap: "Dos ejemplos de parámetros de ajuste considerados para un muestreo posterior."

best_val <- max(collect_metrics(svm_initial)$mean)
tmp <- tibble(candidate = LETTERS[1:2], .mean = c(.90, .89), .sd = c(0.02, 0.005))
tmp %>% 
  select(candidate, mean = .mean, variance = .sd) %>% 
  mutate(variance = variance^2) %>% 
  as.data.frame() %>% 
  format(digits = 4, scientific = FALSE) %>%
  kable() %>% 
  kableExtra::kable_styling(full_width = FALSE) %>% 
  kableExtra::add_header_above(c(" " = 1, "Predicción GP de ROC AUC" = 2))
```

::: rmdnote
La optimización bayesiana es un proceso iterativo.
:::

Con base en la cuadrícula inicial de cuatro resultados, se ajusta el modelo GP, se predicen los candidatos y se selecciona una quinta combinación de parámetros de ajuste. Calculamos estimaciones de rendimiento para la nueva configuración, el GP se reajusta con los cinco resultados existentes (y así sucesivamente).

### Funciones de adquisición

Una vez que el proceso gaussiano se ajusta a los datos actuales, ¿cómo se utiliza? Nuestro objetivo es elegir la siguiente combinación de parámetros de ajuste que tenga más probabilidades de tener "mejores resultados" que los mejores actuales. Un enfoque para hacer esto es crear un gran conjunto de candidatos (quizás usando un diseño que llene el espacio) y luego hacer predicciones de media y varianza para cada uno. Utilizando esta información, elegimos el valor del parámetro de ajuste más ventajoso.

Una clase de funciones objetivo, llamadas *funciones de adquisición*, facilitan el equilibrio entre media y varianza. Recuerde que la varianza prevista de los modelos GP depende principalmente de qué tan lejos están de los datos existentes. El equilibrio entre la media y la varianza previstas para nuevos candidatos se ve frecuentemente a través del lente de la exploración y la explotación:

-   La *Exploración* sesga la selección hacia regiones donde hay menos (si es que hay alguno) modelos candidatos observados. Esto tiende a dar más peso a los candidatos con mayor variación y se centra en encontrar nuevos resultados.

-   La *explotación* se basa principalmente en la predicción media para encontrar el mejor valor (medio). Se centra en los resultados existentes.

```{r iterative-aq-data, include = FALSE}
source("extras/nonlinear_function.R")
grid <- 
  tibble(x = seq(0, 1, length.out = 200)) %>% 
  mutate(y = purrr::map_dbl(x, nonlin_function, error = FALSE))

set.seed(121)
current_iter <- tibble(x = c(.09, .41,  .55, .7, .8)) %>% 
  mutate(y = purrr::map_dbl(x, nonlin_function))

gp <- GPfit::GP_fit(matrix(current_iter$x, ncol = 1), current_iter$y)

gp_pred <- 
  predict(gp, matrix(grid$x, ncol = 1))$complete_data %>% 
  as_tibble() %>% 
  setNames(c("x", ".mean", ".sd"))  %>% 
  mutate(.sd = sqrt(.sd))

gp_pred <- 
  gp_pred %>% 
  bind_cols(
    exp_improve() %>% 
      predict(gp_pred, maximize = TRUE, iter = 1, best = max(current_iter$y)) %>% 
      setNames("exp_imp")
  ) %>% 
  bind_cols(
    conf_bound(kappa = .1) %>% 
      predict(gp_pred, maximize = TRUE, iter = 1, best = max(current_iter$y)) %>% 
      setNames("conf_int_01")
  ) %>% 
  bind_cols(
    conf_bound(kappa = 1) %>% 
      predict(gp_pred, maximize = TRUE, iter = 1, best = max(current_iter$y)) %>% 
      setNames("conf_int_1")
  )
```

Para demostrarlo, veamos un ejemplo de juguete con un único parámetro que tiene valores entre \[0, 1\] y la métrica de rendimiento es $R^2$. La función verdadera se muestra en @fig-performance-profile, junto con los valores candidatos `r xfun::numbers_to_words(nrow(current_iter))` que tienen resultados existentes como puntos.

```{r}
#| label: fig-performance-profile
#| echo: FALSE
#| fig.height: 4
#| fig.cap: "Perfil de rendimiento real hipotético sobre un parámetro de ajuste arbitrario, con cinco puntos estimados"
#| fig.alt: "Un perfil de rendimiento real hipotético sobre un parámetro de ajuste arbitrario. También se muestran cinco puntos estimados. El perfil es altamente no lineal con un pico entre dos de los puntos observados."

y_lab <- expression(Estimated ~ italic(R^2))

ggplot(grid, aes(x = x, y = y)) + 
  geom_line(color = "red", alpha = .5, linewidth = 1.25) + 
  labs(y = y_lab, x = "Optimización de Parámetros") +
  geom_point(data = current_iter)
```

Para estos datos, el ajuste del modelo GP se muestra en @fig-estimated-profile. La región sombreada indica el error estándar medio $\pm$ 1. Las dos líneas verticales indican dos puntos candidatos que se examinan con más detalle más adelante.

La región de confianza sombreada demuestra la función de varianza exponencial al cuadrado; se vuelve muy grande entre puntos y converge a cero en los puntos de datos existentes.

```{r}
#| label: fig-estimated-profile
#| echo: FALSE
#| fig.height: 4
#| fig.cap: "Perfil de rendimiento estimado generado por el modelo de proceso gaussiano. La región sombreada muestra límites de error estándar."
#| fig.alt: "El perfil de rendimiento estimado generado por el modelo de proceso gaussiano. La región sombreada muestra límites de error estándar. Dos líneas verticales muestran puntos potenciales que se muestrearán en la siguiente iteración."

y_lab <- expression(Estimated ~ italic(R^2))

gp_pred %>% 
  ggplot(aes(x = x)) + 
  geom_point(data = current_iter, aes(y = y)) + 
  geom_line(aes(y = .mean)) +
  geom_vline(xintercept = c(0.1, 0.25), lty = 2, alpha = .5) + 
  geom_ribbon(aes(ymin = .mean -  1 * .sd, ymax = .mean + 1 * .sd), alpha = .1) + 
  labs(y = y_lab, x = "Optimización de Parámetros")
```

Esta tendencia no lineal pasa por cada punto observado, pero el modelo no es perfecto. No se observan puntos cercanos al verdadero ajuste óptimo y, en esta región, el ajuste podría ser mucho mejor. A pesar de esto, el modelo GP puede orientarnos efectivamente en la dirección correcta.

Desde un punto de vista puramente de explotación, la mejor opción sería seleccionar el valor del parámetro que tenga la mejor predicción media. Aquí, esto sería un valor de `r round(gp_pred$x[which.max(gp_pred$.mean)], 3)`, justo a la derecha del punto mejor observado existente en 0,09.

Como forma de fomentar la exploración, un enfoque simple (pero no utilizado con frecuencia) es encontrar el parámetro de ajuste asociado con el intervalo de confianza más grande. Por ejemplo, al usar una única desviación estándar para el límite de confianza $R^2$, el siguiente punto a muestrear sería `r round(gp_pred$x[which.max(gp_pred$conf_int_1)], 3)`. Esto es un poco más en la región sin resultados observados. Aumentar el número de desviaciones estándar utilizadas en el límite superior empujaría la selección hacia regiones vacías.

Una de las funciones de adquisición más utilizadas es *mejora esperada*. La noción de mejora requiere un valor para los mejores resultados actuales (a diferencia del enfoque de confianza). Dado que el médico de cabecera puede describir un nuevo punto candidato utilizando una distribución, podemos ponderar las partes de la distribución que muestran una mejora utilizando la probabilidad de que se produzca la mejora.

Por ejemplo, considere dos valores de parámetros candidatos de 0,10 y 0,25 (indicados por las líneas verticales en @fig-estimated-profile). Utilizando el modelo GP ajustado, sus distribuciones $R^2$ previstas se muestran en @fig-two-candidates junto con una línea de referencia para los mejores resultados actuales.

```{r}
#| label: fig-two-candidates
#| echo: FALSE
#| fig.height: 4 
#| fig.width: 6.25 
#| out.width: "80%"
#| fig.cap: "Distribuciones de rendimiento previstas para dos valores de parámetros de ajuste muestreados"
#| fig.alt: "Distribuciones de rendimiento previstas para dos valores de parámetros de ajuste muestreados. Por un lado, la distribución es ligeramente mejor que el valor actual con un pequeño diferencial. El otro valor del parámetro es ligeramente peor pero tiene una distribución muy amplia."

small_pred <- 
  predict(gp, c(0.1, 0.25))$complete_data %>% 
  as_tibble() %>% 
  setNames(c("x", ".mean", ".sd")) %>% 
  mutate(
    value = c(0.1, 0.25),
    .sd = sqrt(.sd),
    max = .mean + 3 * .sd,
    min = .mean - 3 * .sd
  )

small_pred <- 
  small_pred %>% 
  bind_cols(
    exp_improve() %>% 
      predict(small_pred, maximize = TRUE, iter = 1, best = max(current_iter$y)) %>% 
      setNames("exp_imp")
  )

get_density <- function(dat) {
  res <- tibble(x = seq(dat$min, dat$max, length.out = 200)) %>% 
    mutate(density = dnorm(x, dat$.mean, dat$.sd),
           `Parameter Value` = format(dat$value))
  res
}

x_lab <- expression(Predicted ~ italic(R^2) ~ Distribution)

small_pred %>% 
  group_by(value) %>% 
  do(get_density(.)) %>% 
  ungroup() %>% 
  ggplot(aes(x = x, y = density, color = `Parameter Value`, lty = `Parameter Value`)) + 
  geom_line() +
  geom_vline(xintercept = max(current_iter$y), lty = 3) +  
  labs(x = x_lab) + 
  scale_color_brewer(palette = "Set1")
```

Cuando solo se considera la predicción media de $R^2$, un valor de parámetro de 0,10 es la mejor opción (consulte @tbl-two-exp-improve). Se prevé, en promedio, que la recomendación del parámetro de ajuste de 0,25 será peor que el mejor nivel actual. Sin embargo, dado que tiene una mayor varianza, tiene más área de probabilidad general por encima del mejor nivel actual. Como resultado, tiene una mejora esperada mayor:

```{r}
#| label: tbl-two-exp-improve
#| echo: FALSE
#| results: "asis"
#| tbl-cap: "Mejora esperada para los dos parámetros de ajuste candidatos."

small_pred %>% 
  select(`Parameter Value` = x, Mean = .mean, `Std Dev` = .sd, `Expected Improvment` = exp_imp) %>% 
  as.data.frame() %>% 
  format(digits = 4, scientific = FALSE) %>% 
  kable() %>% 
  kableExtra::kable_styling(full_width = FALSE) %>% 
  kableExtra::add_header_above(c(" " = 1, "Predicciones" = 3))
```

Cuando la mejora esperada se calcula en todo el rango del parámetro de ajuste, el punto de muestreo recomendado está mucho más cerca de 0,25 que de 0,10, como se muestra en @fig-expected-improvement.

```{r}
#| label: fig-expected-improvement
#| echo: FALSE
#| fig.height: 5.5 
#| fig.cap: "El perfil de rendimiento estimado generado por el modelo de proceso gaussiano (panel superior) y la mejora esperada (panel inferior). La línea vertical indica el punto de máxima mejora."
#| fig.alt: "El perfil de rendimiento estimado generado por el modelo de proceso gaussiano (panel superior) y la mejora esperada (panel inferior). La línea vertical indica el punto de máxima mejora donde el rendimiento estimado es alto y la variación prevista también es grande."

y_lab <- expression(Estimated ~ italic(R^2))

p1 <- 
  gp_pred %>% 
  ggplot(aes(x = x)) + 
  geom_point(data = current_iter, aes(y = y)) + 
  geom_line(aes(y = .mean)) +
  geom_ribbon(aes(ymin = .mean -  1 * .sd, ymax = .mean + 1 * .sd), alpha = .1) + 
  labs(y = y_lab, x = NULL) + 
  theme(
    axis.title.x=element_blank(),
    axis.text.x=element_blank(),
    axis.ticks.x=element_blank(), 
    plot.margin = unit(c(0, 0, 0, 0), "null")
  )

p2 <- 
  gp_pred %>% 
  ggplot(aes(x = x, y = exp_imp)) + 
  geom_line() + 
  labs(y = "Mejora esperada", x = "Optimización de Parámetros") + 
  theme(plot.margin = unit(c(0, 0, 0, 0), "null")) +
  geom_vline(xintercept = gp_pred$x[which.max(gp_pred$exp_imp)], lty = 2)

p1/p2
```

Se han propuesto y discutido numerosas funciones de adquisición; en tidymodels, la mejora esperada es la predeterminada.

```{r iterative-cells-bo-calcs, echo = FALSE}
# Haremos los cálculos aquí pero usaremos algunas opciones no estándar. 
# Primero, purrr se usa para capturar la salida en un vector para que 
# podamos mostrar los resultados poco a poco. Además, se utiliza una 
# opción oculta para guardar la cuadrícula de valores candidatos para 
# cada iteración de la búsqueda. Estos se utilizarán para hacer una 
# animación en una parte posterior. 
# 
# Esto significa que cualquier cambio en este fragmento debe 
# realizarse en el siguiente fragmento (donde el código se muestra 
# y no se ejecuta).

ctrl <- control_bayes(verbose = TRUE)
ctrl$save_gp_scoring <- TRUE

tune_bayes_sssshhh <- purrr::quietly(tune_bayes)

set.seed(1403)
svm_bo_sshh <-
  svm_wflow %>%
  tune_bayes_sssshhh(
    resamples = cell_folds,
    metrics = roc_res,
    initial = svm_initial,
    param_info = svm_param,
    iter = 25,
    control = ctrl
  )


# Asegúrese de que los resultados no hayan cambiado desde el 2022-02-20. Guarde los resultados con: 
#   svm_bo_metrics <- collect_metrics(svm_bo_sshh$result)
#   save(svm_bo_metrics, file = "RData/svm_bo_metrics.RData")
# Comprobar con:
verify_consistent_bo(collect_metrics(svm_bo_sshh$result))

svm_bo <- svm_bo_sshh$result
svm_bo_output <- svm_bo_sshh$messages

gp_candidates <- collect_gp_results(svm_bo)
```

### La función `tune_bayes()` {#sec-tune-bayes}

Para implementar la búsqueda iterativa mediante optimización bayesiana, utilice la función `tune_bayes()`. Su sintaxis es muy similar a `tune_grid()` pero con varios argumentos adicionales:

-   `iter` es el número máximo de iteraciones de búsqueda.

-   `initial` Puede ser un número entero, un objeto producido usando `tune_grid()` o una de las funciones de carrera. El uso de un número entero especifica el tamaño de un diseño de relleno de espacio que se muestrea antes del primer modelo GP.

-   `objective` es un argumento para qué función de adquisición se debe utilizar. El paquete `r pkg(tune)` contiene funciones para pasar aquí, como `exp_improve()` o `conf_bound()`.

-   El argumento `param_info`, en este caso, especifica el rango de los parámetros así como cualquier transformación que se utilice. Se utilizan para definir el espacio de búsqueda. En situaciones en las que los objetos de parámetros predeterminados son insuficientes, se utiliza `param_info` para anular los valores predeterminados.

El argumento `control` ahora usa los resultados de `control_bayes()`. Algunos argumentos útiles son:

-   `no_improve` es un número entero que detendrá la búsqueda si no se descubren parámetros mejorados dentro de las iteraciones `no_improve`.

-   `uncertain` también es un número entero (o `Inf`) que tomará una *muestra de incertidumbre* si no hay mejora dentro de las iteraciones `inciertas`. Esto seleccionará al siguiente candidato que tenga una gran variación. Tiene el efecto de exploración pura ya que no considera la predicción media.

-   `verbose` es un método lógico que imprimirá información de registro a medida que avanza la búsqueda.

Usemos los primeros resultados de SVM de @sec-svm como sustrato inicial para el modelo de proceso gaussiano. Recuerde que, para esta aplicación, queremos maximizar el área bajo la curva ROC. Nuestro código es:

```{r iterative-cells-bo, eval = FALSE}
ctrl <- control_bayes(verbose = TRUE)

set.seed(1403)
svm_bo <-
  svm_wflow %>%
  tune_bayes(
    resamples = cell_folds,
    metrics = roc_res,
    initial = svm_initial,
    param_info = svm_param,
    iter = 25,
    control = ctrl
  )
```

```{r iterative-cells-info, include = FALSE}
bo_res <- collect_metrics(svm_bo) %>% mutate(current_best = FALSE)
for(i in 1:nrow(bo_res)) {
  bo_res$current_best[i] <- bo_res$mean[i] > max(bo_res$mean[1:(i-1)])
}
init_vals <- bo_res %>% dplyr::filter(.iter == 0)
best_init <- max(bo_res$mean[bo_res$.iter == 0])
best_bo <- max(bo_res$mean)
best_bo_iter <- bo_res$.iter[which.max(bo_res$mean)]
new_best_iter <- bo_res$.iter[which(bo_res$current_best)]
new_best_iter <- new_best_iter[new_best_iter > 0]
num_improve <- length(new_best_iter)
last_iter <- max(collect_metrics(svm_bo)$.iter)

iter_1_roc <- bo_res$mean[bo_res$.iter == 1]
iter_1_imp <- iter_1_roc > best_init
iter_1_text <- 
  paste0(
    ifelse(iter_1_imp, "mostró una mejora, lo que resultó en un valor ROC de ",
           "no logró mejorar el resultado con un valor ROC de "),
    round(iter_1_roc, 5), "."
  )

iter_2_roc <- bo_res$mean[bo_res$.iter == 2]
iter_2_imp <- iter_2_roc > max(bo_res$mean[bo_res$.iter < 2])
iter_2_text <- 
  dplyr::case_when(
    !iter_1_imp &  !iter_2_imp ~ 
      paste0("la segunda iteración tampoco logró producir una mejora."),
    !iter_1_imp &   iter_2_imp ~ 
      paste0("la segunda iteración arrojó un mejor resultado con un área bajo la curva ROC de ", 
             round(iter_2_roc, 5), "."),
    iter_1_imp &  !iter_2_imp ~ 
      paste0("la segunda iteración no continuó la tendencia con un valor ROC subóptimo de ",
             round(iter_2_roc, 5), "."),
    iter_1_imp &  !iter_2_imp ~ 
      paste0("la segunda iteración aumentó aún más el valor del resultado (ROC = ",
             round(iter_2_roc, 5), ").") 
  )

if (num_improve > 1) {
  improve_text <-
    paste0(
      "Hubo un total de ",
      num_improve,
      " mejoras en el resultado a lo largo del camino en las iteraciones ",
      knitr::combine_words(new_best_iter),
      "."
    )
} else {
  improve_text <-
    paste0("Solo hubo una mejora en el resultado en la iteración. ",
           new_best_iter,
           ".")
}

if (last_iter < 25) {
  last_bo_text <-
    paste0(
      "No hubo más mejoras y la opción predeterminada es detener si no se logra ningún progreso después de `no_improve = ",
      ctrl$no_improve,
      "` más pasos. El último paso fue:"
    )
} else {
  last_bo_text <- "El último paso fue:"
}
```

El proceso de búsqueda comienza con un mejor valor inicial de `r round(best_init, 5)` para el área bajo la curva ROC. Un modelo de proceso gaussiano utiliza estas estadísticas `r xfun::numbers_to_words(nrow(init_vals))` para crear un modelo. El gran conjunto de candidatos se genera y califica automáticamente utilizando la función de adquisición de mejora esperada. La primera iteración `r iter_1_text` Después de ajustar otro modelo de proceso gaussiano con el nuevo valor de resultado, `r iter_2_text`

El registro de las dos primeras iteraciones, generado por la opción "detallado", fue:

```{r iterative-cells-bo-print-first, echo = FALSE}
so_stop_index <- grep("Iteración 3", svm_bo_output) 
if (length(so_stop_index) > 0) {
  cat(svm_bo_output[1:(so_stop_index - 2)], sep = "")
}
```

La búsqueda continúa. `r improve_text` El mejor resultado se produjo en la iteración `r max(new_best_iter)` con un área bajo la curva ROC de `r round(best_bo, 5)`.

```{r iterative-cells-bo-print-impr, echo = FALSE}
all_imp_index <- grep("♥", svm_bo_output)
so_stop_index <- all_imp_index[length(all_imp_index)]
if (length(all_imp_index) > 0) {
  so_start_index <- so_stop_index - 10
  cat(svm_bo_output[so_start_index:(so_stop_index + 1)], sep = "")
}
```

`r last_bo_text`

```{r iterative-cells-bo-print-last, echo = FALSE}
so_start <- paste("Iteration", last_iter)
so_start_index <- grep(so_start, svm_bo_output)
if (length(so_start_index) > 0) {
  cat(svm_bo_output[so_start_index:length(svm_bo_output)], sep = "")
}
```

Las funciones que se utilizan para interrogar los resultados son las mismas que se utilizan para la búsqueda en cuadrícula (por ejemplo, `collect_metrics()`, etc.). Por ejemplo:

```{r iterative-bo-best}
show_best(svm_bo)
```

La función `autoplot()` tiene varias opciones para métodos de búsqueda iterativos. @fig-progress-plot muestra cómo cambió el resultado durante la búsqueda usando `autoplot(svm_bo, type = "performance")`.

```{r}
#| label: fig-progress-plot
#| fig.height: 4
#| echo: FALSE
#| fig.cap: 'El progreso de la optimización bayesiana producido cuando se utiliza el método `autoplot()` con `type = "performance"`'
#| fig.alt: "El progreso de la optimización bayesiana se produce cuando se utiliza el método `autoplot()` con `type = 'performance'`. El gráfico muestra el rendimiento estimado en el eje y frente al número de iteraciones en el eje x. Se muestran intervalos de confianza para los puntos."

autoplot(svm_bo, type = "performance")
```

Un tipo adicional de gráfico utiliza `type = "parameters"` que muestra los valores de los parámetros en iteraciones.

La siguiente animación visualiza los resultados de la búsqueda. Los valores negros $\times$ muestran los valores iniciales contenidos en `svm_initial`. El panel azul superior izquierdo muestra el valor medio previsto del área bajo la curva ROC. El panel rojo en la parte superior derecha muestra la variación prevista en los valores de ROC, mientras que el gráfico inferior visualiza la mejora esperada. En cada panel, los colores más oscuros indican valores menos atractivos (por ejemplo, valores medios pequeños, variación grande y mejoras pequeñas).

```{r iterative-bo-progress, include = FALSE}
av_capture_graphics(
  make_bo_animation(gp_candidates, svm_bo),
  output = "bo_search.mp4",
  width = 760,
  height = 760,
  res = 100,
  vfilter = 'framerate=fps=10', 
  framerate = 1/3
)
```

<video width="720" height="720" controls>

<source src="bo_search.mp4" type="video/mp4">

</video>

La superficie de la superficie media prevista es muy inexacta en las primeras iteraciones de la búsqueda. A pesar de esto, ayuda a guiar el proceso hacia la región de buen desempeño. En otras palabras, el modelo del proceso gaussiano es incorrecto pero resulta muy útil. Dentro de las primeras diez iteraciones, la búsqueda realiza un muestreo cerca de la ubicación óptima.

Si bien la mejor combinación de parámetros de ajuste se encuentra en el límite del espacio de parámetros, la optimización bayesiana a menudo elegirá nuevos puntos en otros lados del límite. Si bien podemos ajustar la proporción de exploración y explotación, la búsqueda tiende a muestrear puntos fronterizos desde el principio.

::: rmdnote
Si la búsqueda se basa en una cuadrícula inicial, un diseño que llene el espacio probablemente sería una mejor opción que un diseño normal. Muestra valores más únicos del espacio de parámetros y mejoraría las predicciones de la desviación estándar en las primeras iteraciones.
:::

Finalmente, si el usuario interrumpe los cálculos de `tune_bayes()`, la función devuelve los resultados actuales (en lugar de generar un error).

## Recocido simulado

*Recocido simulado* (SA) [@kirkpatrick1983optimization; @van1987simulated] es una rutina de búsqueda no lineal general inspirada en el proceso en el que se enfría el metal. Es un método de búsqueda global que puede navegar eficazmente por muchos tipos diferentes de entornos de búsqueda, incluidas funciones discontinuas. A diferencia de la mayoría de las rutinas de optimización basadas en gradientes, el recocido simulado puede reevaluar soluciones anteriores.

### Proceso de búsqueda de recocido simulado

El proceso de uso del recocido simulado comienza con un valor inicial y se embarca en un recorrido aleatorio controlado a través del espacio de parámetros. Cada nuevo valor de parámetro candidato es una pequeña perturbación del valor anterior que mantiene el nuevo punto dentro de una vecindad local.

El punto candidato se vuelve a muestrear para obtener su valor de rendimiento correspondiente. Si con este se logran mejores resultados que los parámetros anteriores, se acepta como el nuevo mejor y el proceso continúa. Si los resultados son peores que el valor anterior, el procedimiento de búsqueda aún puede usar este parámetro para definir pasos adicionales. Esto depende de dos factores. Primero, la probabilidad de aceptar un mal resultado disminuye a medida que el desempeño empeora. En otras palabras, un resultado ligeramente peor tiene más posibilidades de aceptación que uno con una gran caída en el rendimiento. El otro factor es el número de iteraciones de búsqueda. El recocido simulado quiere aceptar menos valores subóptimos a medida que avanza la búsqueda. A partir de estos dos factores, la *probabilidad de aceptación* de un mal resultado puede formalizarse como:

$$\operatorname{Pr}[\text{accept suboptimal parameters at iteration } i] = \exp(c\times D_i \times i)$$

donde $i$ es el número de iteración, $c$ es una constante especificada por el usuario y $D_i$ es la diferencia porcentual entre los valores antiguos y nuevos (donde los valores negativos implican peores resultados). Para un mal resultado, determinamos la probabilidad de aceptación y la comparamos con un número uniforme aleatorio. Si el número aleatorio es mayor que el valor de probabilidad, la búsqueda descarta los parámetros actuales y la siguiente iteración crea su valor candidato en la vecindad del valor anterior. De lo contrario, la siguiente iteración forma el siguiente conjunto de parámetros en función de los valores actuales (subóptimos).

::: rmdnote
Las probabilidades de aceptación del recocido simulado permiten que la búsqueda avance en la dirección equivocada, al menos a corto plazo, con el potencial de encontrar una región mucho mejor del espacio de parámetros a largo plazo.
:::

¿Cómo se ven influenciadas las probabilidades de aceptación? El mapa de calor en @fig-acceptance-prob muestra cómo la probabilidad de aceptación puede cambiar a lo largo de las iteraciones, el rendimiento y el coeficiente especificado por el usuario.

```{r}
#| label: fig-acceptance-prob
#| echo: FALSE
#| dev: "png" 
#| fig.height: 4.5
#| out.width: "80%"
#| fig.cap: "Mapa de calor de las probabilidades de aceptación del recocido simuladas para diferentes valores de coeficientes"
#| fig.alt: "Un mapa de calor de las probabilidades de aceptación de recocido simuladas para diferentes valores de coeficientes. Las probabilidades se ven afectadas tanto por el número de iteraciones como por la distancia entre el rendimiento y el mejor nivel actual."

get_accept_probs <- function(coef, pct_diff) {
  # pérdida porcentual al valor absoluto
  candidate <- .8 - (pct_diff  * .8 /100) 
  
  x <- finetune:::acceptance_prob(0.8, candidate, 1:50, coef = coef, maximize = TRUE)
  tibble(
    `Acceptance Probability` = x,
    iteration = 1:50,
    pct_diff = pct_diff, 
    coefficient = coef
  )
}

prob_settings <- crossing(pct_diff = 1:10, coefficient = c(10, 20, 30)/1000)
prob_res <- purrr::map2_dfr(prob_settings$coefficient, prob_settings$pct_diff, get_accept_probs)

ggplot(prob_res, aes(x = iteration, y = pct_diff, fill = `Acceptance Probability`)) +
  geom_raster() +
  facet_wrap( ~ coefficient, labeller = label_both) +
  scale_fill_gradientn(
    colours = scales::brewer_pal(palette = "Greens")(8),
    limits = 0:1
  ) +
  labs(y = "Pérdida Porcentual", x = "Iteración")
```

El usuario puede ajustar los coeficientes para encontrar un perfil de probabilidad que se adapte a sus necesidades. En `finetune::control_sim_anneal()`, el valor predeterminado para este argumento `cooling_coef` es `r control_sim_anneal()$cooling_coef`. Disminuir este coeficiente fomentará que la búsqueda sea más indulgente con los malos resultados.

Este proceso continúa durante una cantidad determinada de iteraciones, pero puede detenerse si no se obtienen los mejores resultados globales dentro de un número predeterminado de iteraciones. Sin embargo, puede resultar muy útil establecer un *umbral de reinicio*. Si hay una serie de fallas, esta función revisa la última configuración de parámetros globalmente mejor y comienza de nuevo.

El principal detalle importante es definir cómo perturbar los parámetros de ajuste de una iteración a otra. Hay una variedad de métodos en la literatura para esto. Seguimos el método dado en @gsa llamado *recocido simulado generalizado*. Para parámetros de ajuste continuo, definimos un radio pequeño para especificar el "vecindario" local. Por ejemplo, supongamos que hay dos parámetros de ajuste y cada uno está limitado por cero y uno. El proceso de recocido simulado genera valores aleatorios en el radio circundante y elige aleatoriamente uno como valor candidato actual.

En nuestra implementación, la vecindad se determina escalando el candidato actual para que esté entre cero y uno según el rango del objeto de parámetro, por lo que los valores de radio entre 0,05 y 0,15 parecen razonables. Para estos valores, lo más rápido que puede ir la búsqueda de un lado al otro del espacio de parámetros es de aproximadamente 10 iteraciones. El tamaño del radio controla la rapidez con la que la búsqueda explora el espacio de parámetros. En nuestra implementación, se especifica un rango de radios para que diferentes magnitudes de "local" definan los nuevos valores candidatos.

Para ilustrar, usaremos los dos parámetros de ajuste principales `r pkg(glmnet)`:

-   El importe de la regularización total (`penalty`). El rango predeterminado para este parámetro es $10^{`r penalty()$range[[1]]`}$ a $10^{`r penalty()$range[[2]]`}$. Es típico utilizar una transformación logarítmica (base-10) para este parámetro.

-   La proporción de la pena de lazo (`mixture`). Esto está acotado en cero y uno sin transformación.

```{r iterative-neighborhood-calcs, echo = FALSE}
#| echo = FALSE, 
#| message = FALSE, 
#| warning = FALSE,
#| out.width = "80%",
#| fig.cap = "Cómo el recocido simulado determina la vecindad local para dos parámetros de ajuste numéricos. Las nubes de puntos muestran posibles siguientes valores donde se seleccionaría uno al azar. ",
#| fig.alt = "Una ilustración de cómo el recocido simulado determina cuál es la vecindad local para dos parámetros de ajuste numéricos. Las nubes de puntos muestran posibles siguientes valores donde se seleccionaría uno al azar. Los puntos candidatos son pequeñas nubes circulares que rodean el mejor punto actual."

glmn_param <- parameters(penalty(), mixture())
pen_rng <- unlist(range_get(penalty(), original = TRUE))
mix_rng <- 0:1

iter_1 <- tibble(penalty = 0.025, mixture = .05)
next_neighbors <- 
  finetune:::random_real_neighbor(iter_1, iter_1, glmn_param, retain = 300) %>% 
  mutate(Iteration = 1)

set.seed(1)
neighbors_values <- next_neighbors
best_values <- iter_1 %>% mutate(Iteration = 1)

scoring <- function(x) {
  - log10(x$penalty) * .1 + x$mixture * 2 + rnorm(nrow(x), sd = .5)
}

path <- best_values

for (i in 2:6) {
  set.seed(i + 5)
  next_scores <- scoring(next_neighbors)
  next_ind <- which.max(next_scores)
  next_value <- next_neighbors %>% slice(next_ind) %>% mutate(Iteration = i)
  
  best_values <- 
    bind_rows(
      best_values,
      next_value
    )
  path <- bind_rows(path, best_values %>% mutate(Iteration = i))
  
  next_neighbors <- 
    finetune:::random_real_neighbor(next_value %>% select(-Iteration), 
                                    path %>% select(-Iteration), 
                                    glmn_param, retain = 300) %>% 
    mutate(Iteration = i)
  neighbors_values <- 
    bind_rows(
      neighbors_values,
      next_neighbors
    )  
}
```

El proceso comienza con valores iniciales de `penalty = 0,025` y `mixture = 0,050`. Utilizando un radio que fluctúa aleatoriamente entre 0,050 y 0,015, los datos se escalan adecuadamente, se generan valores aleatorios en los radios alrededor del punto inicial y luego se elige uno al azar como candidato. A modo de ilustración, asumiremos que todos los valores candidatos son mejoras. Utilizando el nuevo valor, se genera un conjunto de nuevos vecinos aleatorios, se elige uno, y así sucesivamente. @fig-iterative-neighborhood muestra `r xfun::numbers_to_words(max(best_values$Iteration))` iteraciones a medida que la búsqueda avanza hacia la esquina superior izquierda.

```{r}
#| label: fig-iterative-neighborhood
#| echo: FALSE
#| message: FALSE 
#| warning: FALSE
#| out.width: "80%"
#| fig.cap: "Una ilustración de cómo el recocido simulado determina cuál es la vecindad local para dos parámetros de ajuste numéricos. Las nubes de puntos muestran posibles siguientes valores donde se seleccionaría uno al azar. "
#| fig.alt: "Una ilustración de cómo el recocido simulado determina cuál es la vecindad local para dos parámetros de ajuste numéricos. Las nubes de puntos muestran posibles siguientes valores donde se seleccionaría uno al azar. Los puntos candidatos son pequeñas nubes circulares que rodean el mejor punto actual."

ggplot(neighbors_values, aes(x = penalty, y = mixture)) + 
  geom_point(alpha = .3, size = 3/4, aes(color = factor(Iteration)), show.legend = FALSE) + 
  scale_x_continuous(trans = "log10", limits = pen_rng) + 
  scale_y_continuous(limits = mix_rng) + 
  geom_point(data = best_values) + 
  geom_path(data = path) + 
  geom_point(data = path) + 
  facet_wrap(vars(Iteration), labeller = label_both) + 
  labs(
    x = paste(penalty()$label, "(penalización)"),
    y = paste(mixture()$label, "(mezcla)")
  )
```

Tenga en cuenta que, durante algunas iteraciones, los conjuntos candidatos a lo largo del radio excluyen puntos fuera de los límites del parámetro. Además, nuestra implementación desvía la elección de las siguientes configuraciones de parámetros de ajuste *lejos* de nuevos valores que son muy similares a las configuraciones anteriores.

Para parámetros no numéricos, asignamos una probabilidad de con qué frecuencia cambia el valor del parámetro.

### La función `tune_sim_anneal()` {#sec-tune-sim-anneal}

Para implementar la búsqueda iterativa mediante recocido simulado, utilice la función `tune_sim_anneal()`. La sintaxis de esta función es casi idéntica a `tune_bayes()`. No hay opciones para funciones de adquisición o muestreo de incertidumbre. La función `control_sim_anneal()` tiene algunos detalles que definen la vecindad local y el programa de enfriamiento:

-   `no_improve`, para recocido simulado, es un número entero que detendrá la búsqueda si no se descubren resultados globales mejores o mejorados dentro de las iteraciones `no_improve`. Los parámetros subóptimos aceptados o descartados cuentan como "sin mejora".

-   `restart` es el número de iteraciones sin nuevos mejores resultados antes de comenzar con los mejores resultados anteriores.

-   `radius` es un vector numérico en (0, 1) que define el radio mínimo y máximo de la vecindad local alrededor del punto inicial.

-   `flip` es un valor de probabilidad que define las posibilidades de alterar el valor de parámetros categóricos o enteros.

-   `cooling_coef` es el coeficiente $c$ en $\exp(c\times D_i \times i)$ que modula la rapidez con la que la probabilidad de aceptación disminuye a lo largo de las iteraciones. Los valores más grandes de `cooling_coef` disminuyen la probabilidad de aceptar una configuración de parámetro subóptima.

Para los datos de segmentación de celdas, la sintaxis es muy consistente con las funciones utilizadas anteriormente:

```{r iterative-cells-sa-calcs, include = FALSE}
# Como hicimos anteriormente, este fragmento ejecuta el código 
# con algunas opciones adicionales que capturan la salida y guardan 
# algunos objetos internos para trazar. 

# Esto significa que cualquier cambio en este fragmento debe realizarse
# en el siguiente fragmento (donde el código se muestra y no se ejecuta).

ctrl_sa <- control_sim_anneal(no_improve = 10L, verbose = TRUE, save_history = TRUE)

tune_sim_anneal_sssshhh <- purrr::quietly(tune_sim_anneal)

set.seed(1404)
svm_sa_sshh <- svm_wflow %>%
  tune_sim_anneal_sssshhh(
    resamples = cell_folds,
    metrics = roc_res,
    initial = svm_initial,
    param_info = svm_param,
    iter = 50,
    control = ctrl_sa
  )

# Asegúrese de que los resultados no hayan cambiado desde el 2022-02-20. Guarde los resultados con:
  # svm_sa_metrics <- collect_metrics(svm_sa_sshh$result)
  # save(svm_sa_metrics, file = "RData/svm_sa_metrics.RData")
# Comprobar con:
  #verify_consistent_sa(collect_metrics(svm_sa_sshh$result))

svm_sa <- svm_sa_sshh$result
svm_sa_output <- svm_sa_sshh$messages

# Configuramos tune_sim_anneal() para guardar un archivo en el directorio temporal.
file.copy(
  file.path(tempdir(), "sa_history.RData"),
  "RData/sa_history.RData",
  overwrite = TRUE
)
```

```{r iterative-cells-sa, eval = FALSE}
ctrl_sa <- control_sim_anneal(verbose = TRUE, no_improve = 10L)

set.seed(1404)
svm_sa <-
  svm_wflow %>%
  tune_sim_anneal(
    resamples = cell_folds,
    metrics = roc_res,
    initial = svm_initial,
    param_info = svm_param,
    iter = 50,
    control = ctrl_sa
  )
```

```{r iterative-sa-history, include = FALSE}
load("RData/sa_history.RData")

restart_iter <- result_history$.iter[result_history$results == "restart from best"]
restart_num <- length(restart_iter)
sa_iter_list <- knitr::combine_words(restart_iter)
restart_txt <- 
  dplyr::case_when(
    restart_num == 0 ~ paste0("No hubo reinicios durante la búsqueda."),
    restart_num == 1 ~ paste0("Hubo un único reinicio en la iteración.", restart_iter)[1],
    TRUE ~ paste0("Había ", restart_num, " se reinicia en iteraciones ", sa_iter_list)[1]
  )
discard_num<- length(result_history$.iter[result_history$results == "descartar subóptimo"])
if (discard_num > 0) {
  restart_txt <-
    paste0(
      restart_txt, 
      " así como ", 
      discard_num, 
      " descartado ", 
      ifelse(discard_num > 1, "candidatos ", "candidato "),
      "durante el proceso."
    )
} else {
  restart_txt <- paste0(restart_txt, ".")
}


best_iters <- result_history$.iter[result_history$results == "nuevo mejor"]
best_init <- max(result_history$mean[result_history$.iter == 0])
best_sa_res <- max(result_history$mean[result_history$.iter > 0])
best_sa_inds <- result_history$.iter[which.max(result_history$mean)]
best_txt <-
  dplyr::case_when(
    restart_num == 1 ~ paste0("un nuevo óptimo global una vez en la iteración ", best_iters, "."),
    TRUE ~ paste0("nuevos óptimos globales en ", length(best_iters), " diferentes iteraciones.")[1]
  )
best_txt <- best_txt[1]
if (length(best_iters) > 1) {
  best_txt <-
    paste0(
      best_txt,
      " La primera mejora fue en la iteración.",
      min(best_iters),
      " y el óptimo final ocurrió en la iteración ",
      max(best_iters),
      ". The best overall results occured at iteration ", 
      best_sa_inds, " con un área media bajo la curva ROC de ",
      round(best_sa_res, 4), " (comparado con un mejor inicial de ",
      round(best_init, 4), ")."
    )
}
```

El proceso de recocido simulado descubrió `r best_txt` `r restart_txt`

La opción `verbose` imprime detalles del proceso de búsqueda. El resultado de las primeras cinco iteraciones fue:

```{r iterative-cells-sa-print-start, echo = FALSE}
so_stop_index <- grep("^ 5", svm_sa_output)
if (length(so_stop_index) > 0) {
  cat(svm_sa_output[1:so_stop_index], sep = "\n")
}
```

El resultado de las últimas diez iteraciones fue:

```{r iterative-cells-sa-print-end, echo = FALSE}
last_sa_iter <- max(result_history$.iter)

so_start_index <- grep(paste0("^", last_sa_iter - 10), svm_sa_output)
so_stop_index  <- grep(paste0("^", last_sa_iter), svm_sa_output)
if (length(so_stop_index) > 0) {
  cat(svm_sa_output[so_start_index:so_stop_index], sep = "\n")
}
```

Al igual que con las otras funciones `tune_*()`, la función `autoplot()` correspondiente produce evaluaciones visuales de los resultados. El uso de `autoplot(svm_sa, type = "performance")` muestra el rendimiento en iteraciones (@fig-sa-iterations) mientras que `autoplot(svm_sa, type = "parameters")` traza el rendimiento versus valores de parámetros de ajuste específicos (@fig-sa-parameters).

```{r}
#| label: fig-sa-iterations
#| fig.height: 4
#| echo: FALSE
#| fig.cap: 'El progreso del proceso de recocido simulado se muestra cuando se usa el método `autoplot()` con `type = "performance"`'
#| fig.alt: "El progreso del proceso de recocido simulado se muestra cuando se usa el método `autoplot()` con `type = 'performance'`. El gráfico muestra el rendimiento estimado en el eje y frente al número de iteraciones en el eje x. Se muestran intervalos de confianza para los puntos."

autoplot(svm_sa, type = "performance")
```

```{r}
#| label: fig-sa-parameters
#| fig.height: 4
#| echo: FALSE
#| fig.cap: 'Rendimiento versus valores de parámetros de ajuste cuando el método `autoplot()` se usa con `type = "parameters"`.'
#| fig.alt: "Una visualización del rendimiento frente a los valores de los parámetros de ajuste cuando se utiliza el método `autoplot()` con `type = 'parameters'`. El gráfico muestra diferentes paneles para cada parámetro de sintonización en sus unidades transformadas."

autoplot(svm_sa, type = "parameters")
```

Una visualización de la ruta de búsqueda ayuda a comprender dónde funcionó bien el proceso de búsqueda y dónde se extravió:

```{r iterative-sa-plot, include = FALSE}
av_capture_graphics(
  sa_2d_plot(svm_sa, result_history, svm_large),
  output = "sa_search.mp4",
  width = 720,
  height = 720,
  res = 120,
  vfilter = 'framerate=fps=10', 
  framerate = 1/3
)
```

<video width="720" height="720" controls>

<source src="sa_search.mp4" type="video/mp4">

</video>

Al igual que `tune_bayes()`, detener manualmente la ejecución devolverá las iteraciones completadas.

## Resumen del capítulo {#sec-iterative-summary}

Este capítulo describió dos métodos de búsqueda iterativos para optimizar los parámetros de ajuste. La optimización de Bayes utiliza un modelo predictivo entrenado en los resultados de remuestreo existentes para sugerir valores de parámetros de ajuste, mientras que el recocido simulado recorre el espacio de hiperparámetros para encontrar buenos valores. Ambos pueden ser eficaces para encontrar buenos valores por sí solos o como método de seguimiento utilizado después de una búsqueda inicial en la cuadrícula para mejorar el rendimiento de `r pkg(finetune)`.
