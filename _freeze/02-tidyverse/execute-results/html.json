{
  "hash": "cf28a6e4e16fdaecc06e3b95f6fad5d7",
  "result": {
    "markdown": "# A Tidyverse Primer {#sec-tidyverse}\n\n\n\n\n\nWhat is the tidyverse, and where does the tidymodels framework fit in? The tidyverse is a collection of R packages for data analysis that are developed with common ideas and norms. From @tidyverse:\n\n> \"At a high level, the tidyverse is a language for solving data science challenges with R code. Its primary goal is to facilitate a conversation between a human and a computer about data. Less abstractly, the tidyverse is a collection of R packages that share a high-level design philosophy and low-level grammar and data structures, so that learning one package makes it easier to learn the next.\"\n\nIn this chapter, we briefly discuss important principles of the tidyverse design philosophy and how they apply in the context of modeling software that is easy to use properly and supports good statistical practice, like we outlined in [Chapter -@sec-software-modeling]. The next chapter covers modeling conventions from the core R language. Together, you can use these discussions to understand the relationships between the tidyverse, tidymodels, and the core or base R language. Both tidymodels and the tidyverse build on the R language, and tidymodels applies tidyverse principles to building models.\n\n## Tidyverse Principles\n\nThe full set of strategies and tactics for writing R code in the tidyverse style can be found at the website <https://design.tidyverse.org>. Here we can briefly describe several of the general tidyverse design principles, their motivation, and how we think about modeling as an application of these principles.\n\n### Design for humans\n\nThe tidyverse focuses on designing R packages and functions that can be easily understood and used by a broad range of people. Both historically and today, a substantial percentage of R users are not people who create software or tools but instead people who create analyses or models. As such, R users do not typically have (or need) computer science backgrounds, and many are not interested in writing their own R packages.\n\nFor this reason, it is critical that R code be easy to work with to accomplish your goals. Documentation, training, accessibility, and other factors play an important part in achieving this. However, if the syntax itself is difficult for people to easily comprehend, documentation is a poor solution. The software itself must be intuitive.\n\nTo contrast the tidyverse approach with more traditional R semantics, consider sorting a data frame. Data frames can represent different types of data in each column, and multiple values in each row. Using only the core language, we can sort a data frame using one or more columns by reordering the rows via R's subscripting rules in conjunction with `order()`; you cannot successfully use a function you might be tempted to try in such a situation because of its name, `sort()`. To sort the `mtcars` data by two of its columns, the call might look like:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmtcars[order(mtcars$gear, mtcars$mpg), ]\n```\n:::\n\n\nWhile very computationally efficient, it would be difficult to argue that this is an intuitive user interface. In <span class=\"pkg\">dplyr</span> by contrast, the tidyverse function `arrange()` takes a set of variable names as input arguments directly:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(dplyr)\narrange(.data = mtcars, gear, mpg)\n```\n:::\n\n\n::: rmdnote\nThe variable names used here are \"unquoted\"; many traditional R functions require a character string to specify variables, but tidyverse functions take unquoted names or *selector functions*. The selectors allow for one or more readable rules that are applied to the column names. For example, `ends_with(\"t\")` would select the `drat` and `wt` columns of the `mtcars` data frame.\n:::\n\nAdditionally, naming is crucial. If you were new to R and were writing data analysis or modeling code involving linear algebra, you might be stymied when searching for a function that computes the matrix inverse. Using `apropos(\"inv\")` yields no candidates. It turns out that the base R function for this task is `solve()`, for solving systems of linear equations. For a matrix `X`, you would use `solve(X)` to invert `X` (with no vector for the right-hand side of the equation). This is only documented in the description of one of the *arguments* in the help file. In essence, you need to know the name of the solution to be able to find the solution.\n\nThe tidyverse approach is to use function names that are descriptive and explicit over those that are short and implicit. There is a focus on verbs (e.g., `fit`, `arrange`, etc.) for general methods. Verb-noun pairs are particularly effective; consider `invert_matrix()` as a hypothetical function name. In the context of modeling, it is also important to avoid highly technical jargon, such as Greek letters or obscure terms in terms. Names should be as self-documenting as possible.\n\nWhen there are similar functions in a package, function names are designed to be optimized for tab-completion. For example, the <span class=\"pkg\">glue</span> package has a collection of functions starting with a common prefix (`glue_`) that enables users to quickly find the function they are looking for.\n\n### Reuse existing data structures\n\nWhenever possible, functions should avoid returning a novel data structure. If the results are conducive to an existing data structure, it should be used. This reduces the cognitive load when using software; no additional syntax or methods are required.\n\nThe data frame is the preferred data structure in tidyverse and tidymodels packages, because its structure is a good fit for such a broad swath of data science tasks. Specifically, the tidyverse and tidymodels favor the tibble, a modern reimagining of R's data frame that we describe in the next section on example tidyverse syntax.\n\nAs an example, the <span class=\"pkg\">rsample</span> package can be used to create *resamples* of a data set, such as cross-validation or the bootstrap (described in [Chapter @sec-resampling]). The resampling functions return a tibble with a column called `splits` of objects that define the resampled data sets. Three bootstrap samples of a data set might look like:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nboot_samp <- rsample::bootstraps(mtcars, times = 3)\nboot_samp\n## # Bootstrap sampling \n## # A tibble: 3 × 2\n##   splits          id        \n##   <list>          <chr>     \n## 1 <split [32/10]> Bootstrap1\n## 2 <split [32/12]> Bootstrap2\n## 3 <split [32/13]> Bootstrap3\nclass(boot_samp)\n## [1] \"bootstraps\" \"rset\"       \"tbl_df\"     \"tbl\"        \"data.frame\"\n```\n:::\n\n\nWith this approach, vector-based functions can be used with these columns, such as `vapply()` or `purrr::map()`.[^02-tidyverse-1] This `boot_samp` object has multiple classes but inherits methods for data frames (`\"data.frame\"`) and tibbles (`\"tbl_df\"`). Additionally, new columns can be added to the results without affecting the class of the data. This is much easier and more versatile for users to work with than a completely new object type that does not make its data structure obvious.\n\n[^02-tidyverse-1]: If you've never seen `::` in R code before, it is an explicit method for calling a function. The value of the left-hand side is the *namespace* where the function lives (usually a package name). The right-hand side is the function name. In cases where two packages use the same function name, this syntax ensures that the correct function is called.\n\nOne downside to relying on common data structures is the potential loss of computational performance. In some situations, data can be encoded in specialized formats that are more efficient representations of the data. For example:\n\n-   In computational chemistry, the structure-data file format (SDF) is a tool to take chemical structures and encode them in a format that is computationally efficient to work with.\n\n-   Data that have a large number of values that are the same (such as zeros for binary data) can be stored in a sparse matrix format. This format can reduce the size of the data as well as enable more efficient computational techniques.\n\nThese formats are advantageous when the problem is well scoped and the potential data processing methods are both well defined and suited to such a format.[^02-tidyverse-2] However, once such constraints are violated, specialized data formats are less useful. For example, if we perform a transformation of the data that converts the data into fractional numbers, the output is no longer sparse; the sparse matrix representation is helpful for one specific algorithmic step in modeling, but this is often not true before or after that specific step.\n\n[^02-tidyverse-2]: Not all algorithms can take advantage of sparse representations of data. In such cases, a sparse matrix must be converted to a more conventional format before proceeding.\n\n::: rmdwarning\nA specialized data structure is not flexible enough for an entire modeling workflow in the way that a common data structure is.\n:::\n\nOne important feature in the tibble produced by <span class=\"pkg\">rsample</span> is that the `splits` column is a list. In this instance, each element of the list has the same type of object: an `rsplit` object that contains the information about which rows of `mtcars` belong in the bootstrap sample. *List columns* can be very useful in data analysis and, as will be seen throughout this book, are important to tidymodels.\n\n### Design for the pipe and functional programming\n\nThe <span class=\"pkg\">magrittr</span> pipe operator (`%>%`) is a tool for chaining together a sequence of R functions.[^02-tidyverse-3] To demonstrate, consider the following commands that sort a data frame and then retain the first 10 rows:\n\n[^02-tidyverse-3]: In R 4.1.0, a native pipe operator `|>` was introduced as well. In this book, we use the <span class=\"pkg\">magrittr</span> pipe since users on older versions of R will not have the new native pipe.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsmall_mtcars <- arrange(mtcars, gear)\nsmall_mtcars <- slice(small_mtcars, 1:10)\n\n# or more compactly: \nsmall_mtcars <- slice(arrange(mtcars, gear), 1:10)\n```\n:::\n\n\nThe pipe operator substitutes the value of the left-hand side of the operator as the first argument to the right-hand side, so we can implement the same result as before with:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsmall_mtcars <- \n  mtcars %>% \n  arrange(gear) %>% \n  slice(1:10)\n```\n:::\n\n\nThe piped version of this sequence is more readable; this readability increases as more operations are added to a sequence. This approach to programming works in this example because all of the functions we used return the same data structure (a data frame) that is then the first argument to the next function. This is by design. When possible, create functions that can be incorporated into a pipeline of operations.\n\nIf you have used <span class=\"pkg\">ggplot2</span>, this is not unlike the layering of plot components into a `ggplot` object with the `+` operator. To make a scatter plot with a regression line, the initial `ggplot()` call is augmented with two additional operations:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() + \n  geom_smooth(method = lm)\n```\n:::\n\n\nWhile similar to the <span class=\"pkg\">dplyr</span> pipeline, note that the first argument to this pipeline is a data set (`mtcars`) and that each function call returns a `ggplot` object. Not all pipelines need to keep the returned values (plot objects) the same as the initial value (a data frame). Using the pipe operator with <span class=\"pkg\">dplyr</span> operations has acclimated many R users to expect to return a data frame when pipelines are used; as shown with <span class=\"pkg\">ggplot2</span>, this does not need to be the case. Pipelines are incredibly useful in modeling workflows but modeling pipelines can return, instead of a data frame, objects such as model components.\n\nR has excellent tools for creating, changing, and operating on functions, making it a great language for functional programming. This approach can replace iterative loops in many situations, such as when a function returns a value without other side effects.[^02-tidyverse-4]\n\n[^02-tidyverse-4]: Examples of function side effects could include changing global data or printing a value.\n\nLet's look at an example. Suppose you are interested in the logarithm of the ratio of the fuel efficiency to the car weight. To those new to R and/or coming from other programming languages, a loop might seem like a good option:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nn <- nrow(mtcars)\nratios <- rep(NA_real_, n)\nfor (car in 1:n) {\n  ratios[car] <- log(mtcars$mpg[car]/mtcars$wt[car])\n}\nhead(ratios)\n## [1] 2.081 1.988 2.285 1.896 1.693 1.655\n```\n:::\n\n\nThose with more experience in R may know that there is a much simpler and faster vectorized version that can be computed by:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nratios <- log(mtcars$mpg/mtcars$wt)\n```\n:::\n\n\nHowever, in many real-world cases, the element-wise operation of interest is too complex for a vectorized solution. In such a case, a good approach is to write a function to do the computations. When we design for functional programming, it is important that the output depends only on the inputs and that the function has no side effects. Violations of these ideas in the following function are shown with comments:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncompute_log_ratio <- function(mpg, wt) {\n  log_base <- getOption(\"log_base\", default = exp(1)) # gets external data\n  results <- log(mpg/wt, base = log_base)\n  print(mean(results))                                # prints to the console\n  done <<- TRUE                                       # sets external data\n  results\n}\n```\n:::\n\n\nA better version would be:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncompute_log_ratio <- function(mpg, wt, log_base = exp(1)) {\n  log(mpg/wt, base = log_base)\n}\n```\n:::\n\n\nThe <span class=\"pkg\">purrr</span> package contains tools for functional programming. Let's focus on the `map()` family of functions, which operates on vectors and always returns the same type of output. The most basic function, `map()`, always returns a list and uses the basic syntax of `map(vector, function)`. For example, to take the square root of our data, we could:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmap(head(mtcars$mpg, 3), sqrt)\n## [[1]]\n## [1] 4.583\n## \n## [[2]]\n## [1] 4.583\n## \n## [[3]]\n## [1] 4.775\n```\n:::\n\n\nThere are specialized variants of `map()` that return values when we know or expect that the function will generate one of the basic vector types. For example, since the square root returns a double-precision number:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmap_dbl(head(mtcars$mpg, 3), sqrt)\n## [1] 4.583 4.583 4.775\n```\n:::\n\n\nThere are also mapping functions that operate across multiple vectors:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlog_ratios <- map2_dbl(mtcars$mpg, mtcars$wt, compute_log_ratio)\nhead(log_ratios)\n## [1] 2.081 1.988 2.285 1.896 1.693 1.655\n```\n:::\n\n\nThe `map()` functions also allow for temporary, anonymous functions defined using the tilde character. The argument values are `.x` and `.y` for `map2()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmap2_dbl(mtcars$mpg, mtcars$wt, ~ log(.x/.y)) %>% \n  head()\n## [1] 2.081 1.988 2.285 1.896 1.693 1.655\n```\n:::\n\n\nThese examples have been trivial but, in later sections, will be applied to more complex problems.\n\n::: rmdnote\nFor functional programming in tidy modeling, functions should be defined so that functions like `map()` can be used for iterative computations.\n:::\n\n## Examples of Tidyverse Syntax\n\nLet's begin our discussion of tidyverse syntax by exploring more deeply what a tibble is, and how tibbles work. Tibbles have slightly different rules than basic data frames in R. For example, tibbles naturally work with column names that are not syntactically valid variable names:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Wants valid names:\ndata.frame(`variable 1` = 1:2, two = 3:4)\n##   variable.1 two\n## 1          1   3\n## 2          2   4\n# But can be coerced to use them with an extra option:\ndf <- data.frame(`variable 1` = 1:2, two = 3:4, check.names = FALSE)\ndf\n##   variable 1 two\n## 1          1   3\n## 2          2   4\n\n# But tibbles just work:\ntbbl <- tibble(`variable 1` = 1:2, two = 3:4)\ntbbl\n## # A tibble: 2 × 2\n##   `variable 1`   two\n##          <int> <int>\n## 1            1     3\n## 2            2     4\n```\n:::\n\n\nStandard data frames enable *partial matching* of arguments so that code using only a portion of the column names still works. Tibbles prevent this from happening since it can lead to accidental errors.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf$tw\n## [1] 3 4\n\ntbbl$tw\n## Warning: Unknown or uninitialised column: `tw`.\n## NULL\n```\n:::\n\n\nTibbles also prevent one of the most common R errors: dropping dimensions. If a standard data frame subsets the columns down to a single column, the object is converted to a vector. Tibbles never do this:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ndf[, \"two\"]\n## [1] 3 4\n\ntbbl[, \"two\"]\n## # A tibble: 2 × 1\n##     two\n##   <int>\n## 1     3\n## 2     4\n```\n:::\n\n\nThere are other advantages to using tibbles instead of data frames, such as better printing and more.[^02-tidyverse-5]\n\n[^02-tidyverse-5]: Chapter 10 of @wickham2016 has more details on tibbles.\n\n\n\n\n\nTo demonstrate some syntax, let's use tidyverse functions to read in data that could be used in modeling. The data set comes from the city of Chicago's data portal and contains daily ridership data for the city's elevated train stations. The data set has columns for:\n\n-   the station identifier (numeric)\n-   the station name (character)\n-   the date (character in `mm/dd/yyyy` format)\n-   the day of the week (character)\n-   the number of riders (numeric)\n\nOur tidyverse pipeline will conduct the following tasks, in order:\n\n1.  Use the tidyverse package <span class=\"pkg\">readr</span> to read the data from the source website and convert them into a tibble. To do this, the `read_csv()` function can determine the type of data by reading an initial number of rows. Alternatively, if the column names and types are already known, a column specification can be created in R and passed to `read_csv()`.\n\n2.  Filter the data to eliminate a few columns that are not needed (such as the station ID) and change the column `stationname` to `station`. The function `select()` is used for this. When filtering, use either the column names or a <span class=\"pkg\">dplyr</span> selector function. When selecting names, a new variable name can be declared using the argument format `new_name = old_name`.\n\n3.  Convert the date field to the R date format using the `mdy()` function from the <span class=\"pkg\">lubridate</span> package. We also convert the ridership numbers to thousands. Both of these computations are executed using the `dplyr::mutate()` function.\n\n4.  Use the maximum number of rides for each station and day combination. This mitigates the issue of a small number of days that have more than one record of ridership numbers at certain stations. We group the ridership data by station and day, and then summarize within each of the 1999 unique combinations with the maximum statistic.\n\nThe tidyverse code for these steps is:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(lubridate)\n\nurl <- \"https://data.cityofchicago.org/api/views/5neh-572f/rows.csv?accessType=DOWNLOAD&bom=true&format=true\"\n\nall_stations <- \n  # Step 1: Read in the data.\n  read_csv(url) %>% \n  # Step 2: filter columns and rename stationname\n  dplyr::select(station = stationname, date, rides) %>% \n  # Step 3: Convert the character date field to a date encoding.\n  # Also, put the data in units of 1K rides\n  mutate(date = mdy(date), rides = rides / 1000) %>% \n  # Step 4: Summarize the multiple records using the maximum.\n  group_by(date, station) %>% \n  summarize(rides = max(rides), .groups = \"drop\")\n```\n:::\n\n\nThis pipeline of operations illustrates why the tidyverse is popular. A series of data manipulations is used that have simple and easy to understand functions for each transformation; the series is bundled in a streamlined, readable way. The focus is on how the user interacts with the software. This approach enables more people to learn R and achieve their analysis goals, and adopting these same principles for modeling in R has the same benefits.\n\n## Chapter Summary\n\nThis chapter introduced the tidyverse, with a focus on applications for modeling and how tidyverse design principles inform the tidymodels framework. Think of the tidymodels framework as applying tidyverse principles to the domain of building models. We described differences in conventions between the tidyverse and base R, and introduced two important components of the tidyverse system, tibbles and the pipe operator `%>%`. Data cleaning and processing can feel mundane at times, but these tasks are important for modeling in the real world; we illustrated how to use tibbles, the pipe, and tidyverse functions in an example data import and processing exercise.\n",
    "supporting": [
      "02-tidyverse_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}