{
  "hash": "8e1814a019c898672dd60216e446ed9e",
  "result": {
    "markdown": "# A Review of R Modeling Fundamentals {#sec-base-r}\n\n\n\n\n\nBefore describing how to use tidymodels for applying tidy data principles to building models with R, let's review how models are created, trained, and used in the core R language (often called \"base R\"). This chapter is a brief illustration of core language conventions that are important to be aware of even if you never use base R for models at all. This chapter is not exhaustive, but it provides readers (especially those new to R) the basic, most commonly used motifs.\n\nThe S language, on which R is based, has had a rich data analysis environment since the publication of @WhiteBook (commonly known as The White Book). This version of S introduced standard infrastructure components familiar to R users today, such as symbolic model formulae, model matrices, and data frames, as well as standard object-oriented programming methods for data analysis. These user interfaces have not substantively changed since then.\n\n## An Example\n\nTo demonstrate some fundamentals for modeling in base R, let's use experimental data from @mcdonald2009, by way of @mangiafico2015, on the relationship between the ambient temperature and the rate of cricket chirps per minute. Data were collected for two species: *O. exclamationis* and *O. niveus*. The data are contained in a data frame called `crickets` with a total of 31 data points. These data are shown in @fig-cricket-plot using the following <span class=\"pkg\">ggplot2</span> code.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\ndata(crickets, package = \"modeldata\")\nnames(crickets)\n\n# Plot the temperature on the x-axis, the chirp rate on the y-axis. The plot\n# elements will be colored differently for each species:\nggplot(crickets, \n       aes(x = temp, y = rate, color = species, pch = species, lty = species)) + \n  # Plot points for each data point and color by species\n  geom_point(size = 2) + \n  # Show a simple linear model fit created separately for each species:\n  geom_smooth(method = lm, se = FALSE, alpha = 0.5) + \n  scale_color_brewer(palette = \"Paired\") +\n  labs(x = \"Temperature (C)\", y = \"Chirp Rate (per minute)\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```\n## [1] \"species\" \"temp\"    \"rate\"\n```\n\n::: {.cell-output-display}\n![Relationship between chirp rate and temperature for two different species of crickets](figures/fig-cricket-plot-1.png){#fig-cricket-plot fig-align='center' fig-alt='A scatter plot of the chirp rate and temperature for two different species of crickets with linear trend lines per species. The trends are linearly increasing with a separation between the two species.' width=70%}\n:::\n:::\n\n\nThe data exhibit fairly linear trends for each species. For a given temperature, *O. exclamationis* appears to chirp more per minute than the other species. For an inferential model, the researchers might have specified the following null hypotheses prior to seeing the data:\n\n-   Temperature has no effect on the chirp rate.\n\n-   There are no differences between the species' chirp rate.\n\nThere may be some scientific or practical value in predicting the chirp rate but in this example we will focus on inference.\n\nTo fit an ordinary linear model in R, the `lm()` function is commonly used. The important arguments to this function are a model formula and a data frame that contains the data. The formula is *symbolic*. For example, the simple formula:\n\n``` r\nrate ~ temp\n```\n\nspecifies that the chirp rate is the outcome (since it is on the left-hand side of the tilde `~`) and that the temperature value is the predictor.[^03-base-r-1] Suppose the data contained the time of day in which the measurements were obtained in a column called `time`. The formula:\n\n[^03-base-r-1]: Most model functions implicitly add an intercept column.\n\n``` r\nrate ~ temp + time\n```\n\nwould not add the time and temperature values together. This formula would symbolically represent that temperature and time should be added as separate *main effects* to the model. A main effect is a model term that contains a single predictor variable.\n\nThere are no time measurements in these data but the species can be added to the model in the same way:\n\n``` r\nrate ~ temp + species\n```\n\nSpecies is not a quantitative variable; in the data frame, it is represented as a factor column with levels `\"O. exclamationis\"` and `\"O. niveus\"`. The vast majority of model functions cannot operate on nonnumeric data. For species, the model needs to encode the species data in a numeric format. The most common approach is to use indicator variables (also known as dummy variables) in place of the original qualitative values. In this instance, since species has two possible values, the model formula will automatically encode this column as numeric by adding a new column that has a value of zero when the species is `\"O. exclamationis\"` and a value of one when the data correspond to `\"O. niveus\"`. The underlying formula machinery automatically converts these values for the data set used to create the model, as well as for any new data points (for example, when the model is used for prediction).\n\n::: rmdnote\nSuppose there were five species instead of two. The model formula, in this case, would create four binary columns that are binary indicators for four of the species. The *reference level* of the factor (i.e., the first level) is always left out of the predictor set. The idea is that, if you know the values of the four indicator variables, the value of the species can be determined. We discuss binary indicator variables in more detail in [Section -@sec-dummies].\n:::\n\nThe model formula `rate ~ temp + species` creates a model with different y-intercepts for each species; the slopes of the regression lines could be different for each species as well. To accommodate this structure, an interaction term can be added to the model. This can be specified in a few different ways, and the most basic uses the colon:\n\n``` r\nrate ~ temp + species + temp:species\n\n# A shortcut can be used to expand all interactions containing\n# interactions with two variables:\nrate ~ (temp + species)^2\n\n# Another shortcut to expand factors to include all possible\n# interactions (equivalent for this example):\nrate ~ temp * species\n```\n\nIn addition to the convenience of automatically creating indicator variables, the formula offers a few other niceties:\n\n-   *In-line* functions can be used in the formula. For example, to use the natural log of the temperature, we can create the formula `rate ~ log(temp)`. Since the formula is symbolic by default, literal math can also be applied to the predictors using the identity function `I()`. To use Fahrenheit units, the formula could be `rate ~ I( (temp * 9/5) + 32 )` to convert from Celsius.\n\n-   R has many functions that are useful inside of formulas. For example, `poly(x, 3)` adds linear, quadratic, and cubic terms for `x` to the model as main effects. The <span class=\"pkg\">splines</span> package also has several functions to create nonlinear spline terms in the formula.\n\n-   For data sets where there are many predictors, the period shortcut is available. The period represents main effects for all of the columns that are not on the left-hand side of the tilde. Using `~ (.)^3` would add main effects as well as all two- and three-variable interactions to the model.\n\nReturning to our chirping crickets, let's use a two-way interaction model. In this book, we use the suffix `_fit` for R objects that are fitted models.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ninteraction_fit <-  lm(rate ~ (temp + species)^2, data = crickets) \n\n# To print a short summary of the model:\ninteraction_fit\n## \n## Call:\n## lm(formula = rate ~ (temp + species)^2, data = crickets)\n## \n## Coefficients:\n##           (Intercept)                   temp       speciesO. niveus  \n##               -11.041                  3.751                 -4.348  \n## temp:speciesO. niveus  \n##                -0.234\n```\n:::\n\n\nThis output is a little hard to read. For the species indicator variables, R mashes the variable name (`species`) together with the factor level (`O. niveus`) with no delimiter.\n\nBefore going into any inferential results for this model, the fit should be assessed using diagnostic plots. We can use the `plot()` method for `lm` objects. This method produces a set of four plots for the object, each showing different aspects of the fit, as shown in Figure @fig-interaction-plots.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Place two plots next to one another:\npar(mfrow = c(1, 2))\n\n# Show residuals vs predicted values:\nplot(interaction_fit, which = 1)\n\n# A normal quantile plot on the residuals:\nplot(interaction_fit, which = 2)\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Residual diagnostic plots for the linear model with interactions, which appear reasonable enough to conduct inferential analysis](figures/fig-interaction-plots-1.png){#fig-interaction-plots fig-align='center' fig-alt='On the left is a scatter plot of the model residuals versus predicted values. There are no strong trends in the data. The right-hand panel shows a normal quantile-quantile plot where the points indicate that normality is probably a good assumption.' width=100%}\n:::\n:::\n\n\n::: rmdnote\nWhen it comes to the technical details of evaluating expressions, R is *lazy* (as opposed to eager). This means that model fitting functions typically compute the minimum possible quantities at the last possible moment. For example, if you are interested in the coefficient table for each model term, this is not automatically computed with the model but is instead computed via the `summary()` method.\n:::\n\nOur next order of business with the crickets is to assess if the inclusion of the interaction term is necessary. The most appropriate approach for this model is to recompute the model without the interaction term and use the `anova()` method.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Fit a reduced model:\nmain_effect_fit <-  lm(rate ~ temp + species, data = crickets) \n\n# Compare the two:\nanova(main_effect_fit, interaction_fit)\n## Analysis of Variance Table\n## \n## Model 1: rate ~ temp + species\n## Model 2: rate ~ (temp + species)^2\n##   Res.Df  RSS Df Sum of Sq    F Pr(>F)\n## 1     28 89.3                         \n## 2     27 85.1  1      4.28 1.36   0.25\n```\n:::\n\n\nThis statistical test generates a p-value of 0.25. This implies that there is a lack of evidence against the null hypothesis that the interaction term is not needed by the model. For this reason, we will conduct further analysis on the model without the interaction.\n\nResidual plots should be reassessed to make sure that our theoretical assumptions are valid enough to trust the p-values produced by the model (plots not shown here but spoiler alert: they are).\n\nWe can use the `summary()` method to inspect the coefficients, standard errors, and p-values of each model term:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsummary(main_effect_fit)\n## \n## Call:\n## lm(formula = rate ~ temp + species, data = crickets)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -3.013 -1.130 -0.391  0.965  3.780 \n## \n## Coefficients:\n##                  Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)       -7.2109     2.5509   -2.83   0.0086 ** \n## temp               3.6028     0.0973   37.03  < 2e-16 ***\n## speciesO. niveus -10.0653     0.7353  -13.69  6.3e-14 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 1.79 on 28 degrees of freedom\n## Multiple R-squared:  0.99,\tAdjusted R-squared:  0.989 \n## F-statistic: 1.33e+03 on 2 and 28 DF,  p-value: <2e-16\n```\n:::\n\n\nThe chirp rate for each species increases by 3.6 chirps as the temperature increases by a single degree. This term shows strong statistical significance as evidenced by the p-value. The species term has a value of -10.07. This indicates that, across all temperature values, *O. niveus* has a chirp rate that is about 10 fewer chirps per minute than *O. exclamationis*. Similar to the temperature term, the species effect is associated with a very small p-value.\n\nThe only issue in this analysis is the intercept value. It indicates that at 0° C, there are negative chirps per minute for both species. While this doesn't make sense, the data only go as low as 17.2° C and interpreting the model at 0° C would be an extrapolation. This would be a bad idea. That being said, the model fit is good within the *applicable range* of the temperature values; the conclusions should be limited to the observed temperature range.\n\nIf we needed to estimate the chirp rate at a temperature that was not observed in the experiment, we could use the `predict()` method. It takes the model object and a data frame of new values for prediction. For example, the model estimates the chirp rate for *O. exclamationis* for temperatures between 15° C and 20° C can be computed via:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nnew_values <- data.frame(species = \"O. exclamationis\", temp = 15:20)\npredict(main_effect_fit, new_values)\n##     1     2     3     4     5     6 \n## 46.83 50.43 54.04 57.64 61.24 64.84\n```\n:::\n\n\n::: rmdwarning\nNote that the non-numeric value of `species` is passed to the predict method, as opposed to the numeric, binary indicator variable.\n:::\n\nWhile this analysis has obviously not been an exhaustive demonstration of R's modeling capabilities, it does highlight some major features important for the rest of this book:\n\n-   The language has an expressive syntax for specifying model terms for both simple and quite complex models.\n\n-   The R formula method has many conveniences for modeling that are also applied to new data when predictions are generated.\n\n-   There are numerous helper functions (e.g., `anova()`, `summary()` and `predict()`) that you can use to conduct specific calculations after the fitted model is created.\n\nFinally, as previously mentioned, this framework was first published in 1992. Most of these ideas and methods were developed in that period but have remained remarkably relevant to this day. It highlights that the S language and, by extension R, has been designed for data analysis since its inception.\n\n## What Does the R Formula Do? {#formula}\n\nThe R model formula is used by many modeling packages. It usually serves multiple purposes:\n\n-   The formula defines the columns that the model uses.\n\n-   The standard R machinery uses the formula to encode the columns into an appropriate format.\n\n-   The roles of the columns are defined by the formula.\n\nFor the most part, practitioners' understanding of what the formula does is dominated by the last purpose. Our focus when typing out a formula is often to declare how the columns should be used. For example, the previous specification we discussed sets up predictors to be used in a specific way:\n\n``` r\n(temp + species)^2\n```\n\nOur focus, when seeing this, is that there are two predictors and the model should contain their main effects and the two-way interactions. However, this formula also implies that, since `species` is a factor, it should also create indicator variable columns for this predictor (see [Section -@sec-dummies]) and multiply those columns by the `temp` column to create the interactions. This transformation represents our second bullet point on encoding; the formula also defines how each column is encoded and can create additional columns that are not in the original data.\n\n::: rmdwarning\nThis is an important point that will come up multiple times in this text, especially when we discuss more complex feature engineering in [Chapter -@sec-recipes] and beyond. The formula in R has some limitations, and our approaches to overcoming them contend with all three aspects.\n:::\n\n## Why Tidiness Is Important for Modeling {#tidiness-modeling}\n\nOne of the strengths of R is that it encourages developers to create a user interface that fits their needs. As an example, here are three common methods for creating a scatter plot of two numeric variables in a data frame called `plot_data`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nplot(plot_data$x, plot_data$y)\n\nlibrary(lattice)\nxyplot(y ~ x, data = plot_data)\n\nlibrary(ggplot2)\nggplot(plot_data, aes(x = x, y = y)) + geom_point()\n```\n:::\n\n\nIn these three cases, separate groups of developers devised three distinct interfaces for the same task. Each has advantages and disadvantages.\n\nIn comparison, the *Python Developer's Guide* espouses the notion that, when approaching a problem:\n\n> \"There should be one -- and preferably only one -- obvious way to do it.\"\n\nR is quite different from Python in this respect. An advantage of R's diversity of interfaces is that it can evolve over time and fit different needs for different users.\n\nUnfortunately, some of the syntactical diversity is due to a focus on the needs of the person *developing* the code instead of the needs of the person *using* the code. Inconsistencies among packages can be a stumbling block for R users.\n\nSuppose your modeling project has an outcome with two classes. There are a variety of statistical and machine learning models you could choose from. In order to produce a class probability estimate for each sample, it is common for a model function to have a corresponding `predict()` method. However, there is significant heterogeneity in the argument values used by those methods to make class probability predictions; this heterogeneity can be difficult for even experienced users to navigate. A sampling of these argument values for different models is shown in @tbl-probability-args.\n\n\n::: {#tbl-probability-args .cell layout-align=\"center\" tbl-cap='Heterogeneous argument names for different modeling functions.'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Function </th>\n   <th style=\"text-align:left;\"> Package </th>\n   <th style=\"text-align:left;\"> Code </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;font-family: monospace;\"> lda() </td>\n   <td style=\"text-align:left;\"> MASS </td>\n   <td style=\"text-align:left;font-family: monospace;\"> predict(object) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-family: monospace;\"> glm() </td>\n   <td style=\"text-align:left;\"> stats </td>\n   <td style=\"text-align:left;font-family: monospace;\"> predict(object, type = \"response\") </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-family: monospace;\"> gbm() </td>\n   <td style=\"text-align:left;\"> gbm </td>\n   <td style=\"text-align:left;font-family: monospace;\"> predict(object, type = \"response\", n.trees) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-family: monospace;\"> mda() </td>\n   <td style=\"text-align:left;\"> mda </td>\n   <td style=\"text-align:left;font-family: monospace;\"> predict(object, type = \"posterior\") </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-family: monospace;\"> rpart() </td>\n   <td style=\"text-align:left;\"> rpart </td>\n   <td style=\"text-align:left;font-family: monospace;\"> predict(object, type = \"prob\") </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> various </td>\n   <td style=\"text-align:left;\"> RWeka </td>\n   <td style=\"text-align:left;font-family: monospace;\"> predict(object, type = \"probability\") </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-family: monospace;\"> logitboost() </td>\n   <td style=\"text-align:left;\"> LogitBoost </td>\n   <td style=\"text-align:left;font-family: monospace;\"> predict(object, type = \"raw\", nIter) </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;font-family: monospace;\"> pamr.train() </td>\n   <td style=\"text-align:left;\"> pamr </td>\n   <td style=\"text-align:left;font-family: monospace;\"> pamr.predict(object, type = \"posterior\") </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nNote that the last example has a custom function to make predictions instead of using the more common `predict()` interface (the generic `predict()` method). This lack of consistency is a barrier to day-to-day usage of R for modeling.\n\nAs another example of unpredictability, the R language has conventions for missing data that are handled inconsistently. The general rule is that missing data propagate more missing data; the average of a set of values with a missing data point is itself missing and so on. When models make predictions, the vast majority require all of the predictors to have complete values. There are several options baked in to R at this point with the generic function `na.action()`. This sets the policy for how a function should behave if there are missing values. The two most common policies are `na.fail()` and `na.omit()`. The former produces an error if missing data are present while the latter removes the missing data prior to calculations by case-wise deletion. From our previous example:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# Add a missing value to the prediction set\nnew_values$temp[1] <- NA\n\n# The predict method for `lm` defaults to `na.pass`:\npredict(main_effect_fit, new_values)\n##     1     2     3     4     5     6 \n##    NA 50.43 54.04 57.64 61.24 64.84\n\n# Alternatively \npredict(main_effect_fit, new_values, na.action = na.fail)\n## Error in na.fail.default(structure(list(temp = c(NA, 16L, 17L, 18L, 19L, : missing values in object\n\npredict(main_effect_fit, new_values, na.action = na.omit)\n##     2     3     4     5     6 \n## 50.43 54.04 57.64 61.24 64.84\n```\n:::\n\n\nFrom a user's point of view, `na.omit()` can be problematic. In our example, `new_values` has 6 rows but only 5 would be returned with `na.omit()`. To adjust for this, the user would have to determine which row had the missing value and interleave a missing value in the appropriate place if the predictions were merged into `new_values`.[^03-base-r-2] While it is rare that a prediction function uses `na.omit()` as its missing data policy, this does occur. Users who have determined this as the cause of an error in their code find it quite memorable.\n\n[^03-base-r-2]: A base R policy called `na.exclude()` does exactly this.\n\nTo resolve the usage issues described here, the tidymodels packages have a set of design goals. Most of the tidymodels design goals fall under the existing rubric of \"Design for Humans\" from the tidyverse [@tidyverse], but with specific applications for modeling code. There are a few additional tidymodels design goals that complement those of the tidyverse. Some examples:\n\n-   R has excellent capabilities for object-oriented programming, and we use this in lieu of creating new function names (such as a hypothetical new `predict_samples()` function).\n\n-   *Sensible defaults* are very important. Also, functions should have no default for arguments when it is more appropriate to force the user to make a choice (e.g., the file name argument for `read_csv()`).\n\n-   Similarly, argument values whose default can be derived from the data should be. For example, for `glm()` the `family` argument could check the type of data in the outcome and, if no `family` was given, a default could be determined internally.\n\n-   Functions should take the *data structures that users have* as opposed to the data structure that developers want. For example, a model function's only interface should not be constrained to matrices. Frequently, users will have non-numeric predictors such as factors.\n\nMany of these ideas are described in the tidymodels guidelines for model implementation.[^03-base-r-3] In subsequent chapters, we will illustrate examples of existing issues, along with their solutions.\n\n[^03-base-r-3]: <https://tidymodels.github.io/model-implementation-principles>\n\n::: rmdnote\nA few existing R packages provide a unified interface to harmonize these heterogeneous modeling APIs, such as <span class=\"pkg\">caret</span> and <span class=\"pkg\">mlr</span>. The tidymodels framework is similar to these in adopting a unification of the function interface, as well as enforcing consistency in the function names and return values. It is different in its opinionated design goals and modeling implementation, discussed in detail throughout this book.\n:::\n\nThe `broom::tidy()` function, which we use throughout this book, is another tool for standardizing the structure of R objects. It can return many types of R objects in a more usable format. For example, suppose that predictors are being screened based on their correlation to the outcome column. Using `purrr::map()`, the results from `cor.test()` can be returned in a list for each predictor:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncorr_res <- map(mtcars %>% select(-mpg), cor.test, y = mtcars$mpg)\n\n# The first of ten results in the vector: \ncorr_res[[1]]\n## \n## \tPearson's product-moment correlation\n## \n## data:  .x[[i]] and mtcars$mpg\n## t = -8.9, df = 30, p-value = 6e-10\n## alternative hypothesis: true correlation is not equal to 0\n## 95 percent confidence interval:\n##  -0.9258 -0.7163\n## sample estimates:\n##     cor \n## -0.8522\n```\n:::\n\n\nIf we want to use these results in a plot, the standard format of hypothesis test results are not very useful. The `tidy()` method can return this as a tibble with standardized names:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(broom)\n\ntidy(corr_res[[1]])\n## # A tibble: 1 × 8\n##   estimate statistic  p.value parameter conf.low conf.high method        alternative\n##      <dbl>     <dbl>    <dbl>     <int>    <dbl>     <dbl> <chr>         <chr>      \n## 1   -0.852     -8.92 6.11e-10        30   -0.926    -0.716 Pearson's pr… two.sided\n```\n:::\n\n\nThese results can be \"stacked\" and added to a `ggplot()`, as shown in @fig-corr-plot.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncorr_res %>% \n  # Convert each to a tidy format; `map_dfr()` stacks the data frames \n  map_dfr(tidy, .id = \"predictor\") %>% \n  ggplot(aes(x = fct_reorder(predictor, estimate))) + \n  geom_point(aes(y = estimate)) + \n  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = .1) +\n  labs(x = NULL, y = \"Correlation with mpg\")\n```\n:::\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Correlations (and 95% confidence intervals) between predictors and the outcome in the `mtcars` data set](figures/fig-corr-plot-1.png){#fig-corr-plot fig-align='center' fig-alt='A plot of the correlations (and 95% confidence intervals) between predictors and the outcome in the `mtcars` data set. None of the intervals overlap with zero. The car weight had the largest negative correlation and the rear axle ratio has the highest positive correlation.' width=672}\n:::\n:::\n\n\nCreating such a plot is possible using core R language functions, but automatically reformatting the results makes for more concise code with less potential for errors.\n\n## Combining Base R Models and the Tidyverse\n\nR modeling functions from the core language or other R packages can be used in conjunction with the tidyverse, especially with the <span class=\"pkg\">dplyr</span>, <span class=\"pkg\">purrr</span>, and <span class=\"pkg\">tidyr</span> packages. For example, if we wanted to fit separate models for each cricket species, we can first break out the cricket data by this column using `dplyr::group_nest()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nsplit_by_species <- \n  crickets %>% \n  group_nest(species) \nsplit_by_species\n## # A tibble: 2 × 2\n##   species                        data\n##   <fct>            <list<tibble[,2]>>\n## 1 O. exclamationis           [14 × 2]\n## 2 O. niveus                  [17 × 2]\n```\n:::\n\n\nThe `data` column contains the `rate` and `temp` columns from `crickets` in a *list column*. From this, the `purrr::map()` function can create individual models for each species:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_by_species <- \n  split_by_species %>% \n  mutate(model = map(data, ~ lm(rate ~ temp, data = .x)))\nmodel_by_species\n## # A tibble: 2 × 3\n##   species                        data model \n##   <fct>            <list<tibble[,2]>> <list>\n## 1 O. exclamationis           [14 × 2] <lm>  \n## 2 O. niveus                  [17 × 2] <lm>\n```\n:::\n\n\nTo collect the coefficients for each of these models, use `broom::tidy()` to convert them to a consistent data frame format so that they can be unnested:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel_by_species %>% \n  mutate(coef = map(model, tidy)) %>% \n  select(species, coef) %>% \n  unnest(cols = c(coef))\n## # A tibble: 4 × 6\n##   species          term        estimate std.error statistic  p.value\n##   <fct>            <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n## 1 O. exclamationis (Intercept)   -11.0      4.77      -2.32 3.90e- 2\n## 2 O. exclamationis temp            3.75     0.184     20.4  1.10e-10\n## 3 O. niveus        (Intercept)   -15.4      2.35      -6.56 9.07e- 6\n## 4 O. niveus        temp            3.52     0.105     33.6  1.57e-15\n```\n:::\n\n\n::: rmdnote\nList columns can be very powerful in modeling projects. List columns provide containers for any type of R objects, from a fitted model itself to the important data frame structure.\n:::\n\n## The tidymodels Metapackage\n\nThe tidyverse ([Chapter -@sec-tidyverse]) is designed as a set of modular R packages, each with a fairly narrow scope. The tidymodels framework follows a similar design. For example, the <span class=\"pkg\">rsample</span> package focuses on data splitting and resampling. Although resampling methods are critical to other activities of modeling (e.g., measuring performance), they reside in a single package, and performance metrics are contained in a different, separate package, <span class=\"pkg\">yardstick</span>. There are many benefits to adopting this philosophy of modular packages, from less bloated model deployment to smoother package maintenance.\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nThe downside to this philosophy is that there are a lot of packages in the tidymodels framework. To compensate for this, the tidymodels *package* (which you can think of as a metapackage like the tidyverse package) loads a core set of tidymodels and tidyverse packages. Loading the package shows which packages are attached:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidymodels)\n## ── Attaching packages ─────────────────────────────────────────── tidymodels 1.1.1 ──\n## ✔ broom        1.0.5     ✔ recipes      1.0.8\n## ✔ dials        1.2.0     ✔ rsample      1.2.0\n## ✔ dplyr        1.1.3     ✔ tibble       3.2.1\n## ✔ ggplot2      3.4.3     ✔ tidyr        1.3.0\n## ✔ infer        1.0.5     ✔ tune         1.1.2\n## ✔ modeldata    1.2.0     ✔ workflows    1.1.3\n## ✔ parsnip      1.1.1     ✔ workflowsets 1.0.1\n## ✔ purrr        1.0.2     ✔ yardstick    1.2.0\n## ── Conflicts ────────────────────────────────────────────── tidymodels_conflicts() ──\n## ✖ purrr::discard() masks scales::discard()\n## ✖ dplyr::filter()  masks stats::filter()\n## ✖ dplyr::lag()     masks stats::lag()\n## ✖ recipes::step()  masks stats::step()\n## • Dig deeper into tidy modeling with R at https://www.tmwr.org\n```\n:::\n\n\nIf you have used the tidyverse, you'll notice some familiar names as a few tidyverse packages, such as <span class=\"pkg\">dplyr</span> and <span class=\"pkg\">ggplot2</span>, are loaded together with the tidymodels packages. We've already said that the tidymodels framework applies tidyverse principles to modeling, but the tidymodels framework also literally builds on some of the most fundamental tidyverse packages such as these.\n\nLoading the metapackage also shows if there are function naming conflicts with previously loaded packages. As an example of a naming conflict, before loading <span class=\"pkg\">tidymodels</span>, invoking the `filter()` function will execute the function in the <span class=\"pkg\">stats</span> package. After loading tidymodels, it will execute the <span class=\"pkg\">dplyr</span> function of the same name.\n\nThere are a few ways to handle naming conflicts. The function can be called with its namespace (e.g., `stats::filter()`). This is not bad practice, but it does make the code less readable.\n\nAnother option is to use the <span class=\"pkg\">conflicted</span> package. We can set a rule that remains in effect until the end of the R session to ensure that one specific function will always run if no namespace is given in the code. As an example, if we prefer the <span class=\"pkg\">dplyr</span> version of the previous function:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(conflicted)\nconflict_prefer(\"filter\", winner = \"dplyr\")\n```\n:::\n\n\nFor convenience, <span class=\"pkg\">tidymodels</span> contains a function that captures most of the common naming conflicts that we might encounter:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidymodels_prefer(quiet = FALSE)\n## [conflicted] Will prefer agua::refit over any other package.\n## [conflicted] Will prefer dials::Laplace over any other package.\n## [conflicted] Will prefer dials::max_rules over any other package.\n## [conflicted] Will prefer dials::neighbors over any other package.\n## [conflicted] Will prefer dials::prune over any other package.\n## [conflicted] Will prefer dials::smoothness over any other package.\n## [conflicted] Will prefer dplyr::collapse over any other package.\n## [conflicted] Will prefer dplyr::combine over any other package.\n## [conflicted] Will prefer dplyr::filter over any other package.\n## [conflicted] Will prefer dplyr::rename over any other package.\n## [conflicted] Will prefer dplyr::select over any other package.\n## [conflicted] Will prefer dplyr::slice over any other package.\n## [conflicted] Will prefer ggplot2::`%+%` over any other package.\n## [conflicted] Will prefer ggplot2::margin over any other package.\n## [conflicted] Will prefer parsnip::bart over any other package.\n## [conflicted] Will prefer parsnip::fit over any other package.\n## [conflicted] Will prefer parsnip::mars over any other package.\n## [conflicted] Will prefer parsnip::pls over any other package.\n## [conflicted] Will prefer purrr::cross over any other package.\n## [conflicted] Will prefer purrr::invoke over any other package.\n## [conflicted] Will prefer purrr::map over any other package.\n## [conflicted] Will prefer recipes::discretize over any other package.\n## [conflicted] Will prefer recipes::step over any other package.\n## [conflicted] Will prefer rsample::populate over any other package.\n## [conflicted] Will prefer scales::rescale over any other package.\n## [conflicted] Will prefer themis::step_downsample over any other package.\n## [conflicted] Will prefer themis::step_upsample over any other package.\n## [conflicted] Will prefer tidyr::expand over any other package.\n## [conflicted] Will prefer tidyr::extract over any other package.\n## [conflicted] Will prefer tidyr::pack over any other package.\n## [conflicted] Will prefer tidyr::unpack over any other package.\n## [conflicted] Will prefer tune::parameters over any other package.\n## [conflicted] Will prefer tune::tune over any other package.\n## [conflicted] Will prefer yardstick::get_weights over any other package.\n## [conflicted] Will prefer yardstick::precision over any other package.\n## [conflicted] Will prefer yardstick::recall over any other package.\n## [conflicted] Will prefer yardstick::spec over any other package.\n## [conflicted] Will prefer recipes::update over Matrix::update.\n## ── Conflicts ───────────────────────────────────────────────── tidymodels_prefer() ──\n```\n:::\n\n\n::: rmdwarning\nBe aware that using this function opts you in to using `conflicted::conflict_prefer()` for all namespace conflicts, making every conflict an error and forcing you to choose which function to use. The function `tidymodels::tidymodels_prefer()` handles the most common conflicts from tidymodels functions, but you will need to handle other conflicts in your R session yourself.\n:::\n\n## Chapter Summary\n\nThis chapter reviewed core R language conventions for creating and using models that are an important foundation for the rest of this book. The formula operator is an expressive and important aspect of fitting models in R and often serves multiple purposes in non-tidymodels functions. Traditional R approaches to modeling have some limitations, especially when it comes to fluently handling and visualizing model output. The <span class=\"pkg\">tidymodels</span> metapackage applies tidyverse design philosophy to modeling packages.\n",
    "supporting": [
      "03-base-r_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}