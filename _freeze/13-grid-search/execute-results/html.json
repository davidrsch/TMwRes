{
  "hash": "5f6c724a013d27c8c2dd0c14fcc97361",
  "result": {
    "markdown": "\n\n\n# Búsqueda De Cuadrícula {#sec-grid-search}\n\nEn el [Capítulo @sec-tuning] demostramos cómo los usuarios pueden marcar o etiquetar argumentos en recetas de preprocesamiento y/o especificaciones de modelo para optimización usando la función `tune()`. Una vez que sabemos qué optimizar, es hora de abordar la cuestión de cómo optimizar los parámetros. Este capítulo describe los métodos de *búsqueda en cuadrícula* que especifican los posibles valores de los parámetros *a priori*. [Capítulo @sec-iterative-search] continuará la discusión describiendo los métodos de búsqueda iterativa).\n\nComencemos viendo dos enfoques principales para ensamblar una cuadrícula.\n\n## Cuadrículas Regulares Y No Regulares {#sec-grids}\n\nHay dos tipos principales de cuadrículas. Una cuadrícula regular combina cada parámetro (con su correspondiente conjunto de valores posibles) factorialmente, es decir, utilizando todas las combinaciones de los conjuntos. Alternativamente, una cuadrícula no regular es aquella en la que las combinaciones de parámetros no se forman a partir de un pequeño conjunto de puntos.\n\nAntes de analizar cada tipo con más detalle, consideremos un modelo de ejemplo: el modelo de perceptrón multicapa (también conocido como red neuronal artificial de una sola capa). Los parámetros marcados para tuning son:\n\n-   el número de unidades ocultas\n\n-   el número de épocas/iteraciones de ajuste en el entrenamiento del modelo\n\n-   la cantidad de penalización por pérdida de peso\n\n::: rmdnote\nHistóricamente, el número de épocas estuvo determinado por la detención temprana; un conjunto de validación separado determinó la duración del entrenamiento en función de la tasa de error, ya que volver a predecir el conjunto de entrenamiento conducía a un sobreajuste. En nuestro caso, el uso de una penalización por disminución de peso debería prohibir el sobreajuste, y hay poco daño en ajustar la penalización y el número de épocas.\n:::\n\nUsando <span class=\"pkg\">parsnip</span>, la especificación para un modelo de clasificación que se ajusta usando el paquete <span class=\"pkg\">nnet</span> es:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-mlp_e7df18bce5bd2d42e80fd70823df9513'}\n\n```{.r .cell-code}\nlibrary(tidymodels)\ntidymodels_prefer()\n\nmlp_spec <- \n  mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% \n  set_engine(\"nnet\", trace = 0) %>% \n  set_mode(\"classification\")\n```\n:::\n\n\nEl argumento `trace = 0` evita el registro adicional del proceso de entrenamiento. Como se muestra en @sec-tuning-params-tidymodels, la función `extract_parameter_set_dials()` puede extraer el conjunto de argumentos con valores desconocidos y establece sus objetos <span class=\"pkg\">dials</span>:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-mlp-param_7a3775f11506a5b3cd8c5caf0084364d'}\n\n```{.r .cell-code}\nmlp_param <- extract_parameter_set_dials(mlp_spec)\nmlp_param %>% extract_parameter_dials(\"hidden_units\")\n## # Hidden Units (quantitative)\n## Range: [1, 10]\nmlp_param %>% extract_parameter_dials(\"penalty\")\n## Amount of Regularization (quantitative)\n## Transformer: log-10 [1e-100, Inf]\n## Range (transformed scale): [-10, 0]\nmlp_param %>% extract_parameter_dials(\"epochs\")\n## # Epochs (quantitative)\n## Range: [10, 1000]\n```\n:::\n\n\nEsta salida indica que los objetos de parámetros están completos e imprime sus rangos predeterminados. Estos valores se utilizarán para demostrar cómo crear diferentes tipos de cuadrículas de parámetros.\n\n### Cuadrículas regulares {.unnumbered}\n\nLas cuadrículas regulares son combinaciones de conjuntos separados de valores de parámetros. Primero, el usuario crea un conjunto distinto de valores para cada parámetro. El número de valores posibles no tiene por qué ser el mismo para cada parámetro. La función <span class=\"pkg\">tidyr</span> `crossing()` es una forma de crear una cuadrícula regular:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-crossing_b72b63f3f6e442bf8b46cced93d413f1'}\n\n```{.r .cell-code}\ncrossing(\n  hidden_units = 1:3,\n  penalty = c(0.0, 0.1),\n  epochs = c(100, 200)\n)\n## # A tibble: 12 × 3\n##   hidden_units penalty epochs\n##          <int>   <dbl>  <dbl>\n## 1            1     0      100\n## 2            1     0      200\n## 3            1     0.1    100\n## 4            1     0.1    200\n## 5            2     0      100\n## 6            2     0      200\n## # ℹ 6 more rows\n```\n:::\n\n\nEl objeto de parámetro conoce los rangos de los parámetros. El paquete <span class=\"pkg\">dials</span> contiene un conjunto de funciones `grid_*()` que toman el objeto parámetro como entrada para producir diferentes tipos de cuadrículas. Por ejemplo:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-reg_77cdd3e13c920ac5bd06ec68aa98cad2'}\n\n```{.r .cell-code}\ngrid_regular(mlp_param, levels = 2)\n## # A tibble: 8 × 3\n##   hidden_units      penalty epochs\n##          <int>        <dbl>  <int>\n## 1            1 0.0000000001     10\n## 2           10 0.0000000001     10\n## 3            1 1                10\n## 4           10 1                10\n## 5            1 0.0000000001   1000\n## 6           10 0.0000000001   1000\n## # ℹ 2 more rows\n```\n:::\n\n\nEl argumento `levels` es el número de niveles por parámetro a crear. También puede tomar un vector de valores con nombre:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-reg-lvls_5efe11cd8635c404ea42c3f6471b7da8'}\n\n```{.r .cell-code}\nmlp_param %>% \n  grid_regular(levels = c(hidden_units = 3, penalty = 2, epochs = 2))\n## # A tibble: 12 × 3\n##   hidden_units      penalty epochs\n##          <int>        <dbl>  <int>\n## 1            1 0.0000000001     10\n## 2            5 0.0000000001     10\n## 3           10 0.0000000001     10\n## 4            1 1                10\n## 5            5 1                10\n## 6           10 1                10\n## # ℹ 6 more rows\n```\n:::\n\n\nExisten técnicas para crear cuadrículas regulares que no utilizan todos los valores posibles de cada conjunto de parámetros. Estos *diseños factoriales fraccionales* [@BHH] también podrían usarse. Para obtener más información, consulte la Vista de tareas de CRAN para el diseño experimental.[^13-grid-search-1]\n\n[^13-grid-search-1]: <https://CRAN.R-project.org/view=ExperimentalDesign>\n\n::: rmdwarning\nEl uso de cuadrículas regulares puede ser costoso desde el punto de vista computacional, especialmente cuando hay una cantidad media a grande de parámetros de ajuste. Esto es cierto para muchos modelos pero no para todos. Como se analiza en @sec-ficient-grids a continuación, ¡hay muchos modelos cuyo tiempo de ajuste *disminuye* con una cuadrícula normal!\n:::\n\nUna ventaja de utilizar una cuadrícula regular es que las relaciones y patrones entre los parámetros de ajuste y las métricas del modelo se entienden fácilmente. La naturaleza factorial de estos diseños permite examinar cada parámetro por separado con poca confusión entre los parámetros.\n\n### Rejillas irregulares {.unnumbered}\n\nHay varias opciones para crear cuadrículas no regulares. La primera es utilizar un muestreo aleatorio en toda la gama de parámetros. La función `grid_random()` genera números aleatorios uniformes independientes en todos los rangos de parámetros. Si el objeto parámetro tiene una transformación asociada (como la que tenemos para \"penalización\", `penalty`), los números aleatorios se generan en la escala transformada. Creemos una cuadrícula aleatoria para los parámetros de nuestra red neuronal de ejemplo:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-rand_4c53308f6aa7c3427769d1895b8d2171'}\n\n```{.r .cell-code}\nset.seed(1301)\nmlp_param %>% \n  grid_random(size = 1000) %>% # 'size' es el número de combinaciones\n  summary()\n##   hidden_units      penalty           epochs   \n##  Min.   : 1.00   Min.   :0.0000   Min.   : 10  \n##  1st Qu.: 3.00   1st Qu.:0.0000   1st Qu.:266  \n##  Median : 5.00   Median :0.0000   Median :497  \n##  Mean   : 5.38   Mean   :0.0437   Mean   :510  \n##  3rd Qu.: 8.00   3rd Qu.:0.0027   3rd Qu.:761  \n##  Max.   :10.00   Max.   :0.9814   Max.   :999\n```\n:::\n\n\nPara la \"penalización\", `penalty`, los números aleatorios son uniformes en la escala logarítmica (base-10), pero los valores en la cuadrícula están en unidades naturales.\n\nEl problema con las cuadrículas aleatorias es que, en las cuadrículas pequeñas y medianas, los valores aleatorios pueden dar como resultado combinaciones de parámetros superpuestos. Además, la cuadrícula aleatoria debe cubrir todo el espacio de parámetros, pero la probabilidad de una buena cobertura aumenta con el número de valores de la cuadrícula. Incluso para una muestra de 15 puntos candidatos, @fig-random-grid muestra cierta superposición entre puntos para nuestro perceptrón multicapa de ejemplo.\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-random-matrix_4df76eaf925c0c8e9544cf092eef249d'}\n\n```{.r .cell-code}\nlibrary(ggforce)\nset.seed(1302)\nmlp_param %>% \n  # La opción 'original = FALSE' mantiene la penalización en log10 unidades\n  grid_random(size = 20, original = FALSE) %>% \n  ggplot(aes(x = .panel_x, y = .panel_y)) + \n  geom_point() +\n  geom_blank() +\n  facet_matrix(vars(hidden_units, penalty, epochs), layer.diag = 2) + \n  labs(title = \"Diseño aleatorio con 20 candidatos\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/fig-random-grid_89c002ebb54e9fb6955f49efebb4060a'}\n::: {.cell-output-display}\n![Tres parámetros de ajuste con 15 puntos generados al azar](13-grid-search_files/figure-html/fig-random-grid-1.png){#fig-random-grid fig-align='center' fig-alt='Una matriz de diagrama de dispersión para tres parámetros de ajuste con 20 puntos generados al azar. Existen lagunas importantes en el espacio de parámetros.' width=576}\n:::\n:::\n\n\nUn enfoque mucho mejor es utilizar un conjunto de diseños experimentales llamados *diseños de relleno de espacio*. Si bien los diferentes métodos de diseño tienen objetivos ligeramente diferentes, generalmente encuentran una configuración de puntos que cubre el espacio de parámetros con la menor posibilidad de superposición o valores redundantes. Ejemplos de tales diseños son los hipercubos latinos [@lhd], los diseños de máxima entropía [@maxent], los diseños de máxima proyección [@maxproj] y otros. Consulte @santner2003design para obtener una descripción general.\n\nEl paquete <span class=\"pkg\">dials</span> contiene funciones para diseños de hipercubo latino y de máxima entropía. Al igual que con `grid_random()`, las entradas principales son el número de combinaciones de parámetros y un objeto de parámetro. Comparemos un diseño aleatorio con un diseño de hipercubo latino para 20 valores de parámetros candidatos en @fig-space-filling-design.\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-sfd-compare_c4ed961abe2aaaeaeaeb63b566890a57'}\n\n```{.r .cell-code}\nset.seed(1303)\nmlp_param %>% \n  grid_latin_hypercube(size = 20, original = FALSE) %>% \n  ggplot(aes(x = .panel_x, y = .panel_y)) + \n  geom_point() +\n  geom_blank() +\n  facet_matrix(vars(hidden_units, penalty, epochs), layer.diag = 2) + \n  labs(title = \"Diseño de Hipercubo Latino con 20 candidatos\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/fig-space-filling-design_8da2c808055f52f8bbab1a7ceb63b277'}\n::: {.cell-output-display}\n![Tres parámetros de ajuste con 20 puntos generados mediante un diseño que llena el espacio](13-grid-search_files/figure-html/fig-space-filling-design-1.png){#fig-space-filling-design fig-align='center' fig-alt='Una matriz de diagrama de dispersión para tres parámetros de ajuste con 15 puntos generados mediante un diseño de relleno de espacio. Hay menos espacios en el espacio de parámetros en comparación con la cuadrícula aleatoria.' width=576}\n:::\n:::\n\n\nSi bien no es perfecto, este diseño de hipercubo latino aleja los puntos entre sí y permite una mejor exploración del espacio de hiperparámetros.\n\nLos diseños que llenan el espacio pueden ser muy eficaces para representar el espacio de parámetros. El diseño predeterminado utilizado por el paquete <span class=\"pkg\">tune</span> es el diseño de máxima entropía. Estos tienden a producir cuadrículas que cubren bien el espacio candidato y aumentan drásticamente las posibilidades de encontrar buenos resultados.\n\n## Evaluación De La Cuadrícula {#sec-evaluating-grid}\n\nPara elegir la mejor combinación de parámetros de ajuste, cada conjunto candidato se evalúa utilizando datos que no se utilizaron para entrenar ese modelo. Los métodos de remuestreo o un único conjunto de validación funcionan bien para este propósito. El proceso (y la sintaxis) se parece mucho al enfoque en @sec-resampling-performance que utilizó la función `fit_resamples()` del paquete <span class=\"pkg\">tune</span>.\n\nDespués del remuestreo, el usuario selecciona el conjunto de parámetros candidatos más apropiado. Podría tener sentido elegir la mejor combinación de parámetros empíricamente o sesgar la elección hacia otros aspectos del ajuste del modelo, como la simplicidad.\n\nUsamos un conjunto de datos de clasificación para demostrar el ajuste del modelo en este y el próximo capítulo. Los datos provienen de @Hill, quien desarrolló una herramienta de laboratorio de microscopía automatizada para la investigación del cáncer. Los datos consisten en 56 mediciones de imágenes de 2019 células de cáncer de mama humano. Estos predictores representan características de forma e intensidad de diferentes partes de las células (por ejemplo, el núcleo, el límite celular, etc.). Existe un alto grado de correlación entre los predictores. Por ejemplo, existen varios predictores diferentes que miden el tamaño y la forma del núcleo y el límite celular. Además, individualmente, muchos predictores tienen distribuciones sesgadas.\n\nCada celda pertenece a una de dos clases. Dado que esto es parte de una prueba de laboratorio automatizada, la atención se centró en la capacidad de predicción en lugar de la inferencia.\n\nLos datos están incluidos en el paquete <span class=\"pkg\">modeldata</span>. Eliminemos una columna que no es necesaria para el análisis (`caso`):\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-cells_71bc187eeca78926b736cc7428519a98'}\n\n```{.r .cell-code}\nlibrary(tidymodels)\ndata(cells)\ncells <- cells %>% select(-case)\n```\n:::\n\n\nDadas las dimensiones de los datos, podemos calcular métricas de rendimiento utilizando una validación cruzada de 10 veces:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-cells-folds_434642c1474f21ef87f1c56b9acf3e16'}\n\n```{.r .cell-code}\nset.seed(1304)\ncell_folds <- vfold_cv(cells)\n```\n:::\n\n\nDebido al alto grado de correlación entre los predictores, tiene sentido utilizar la extracción de características PCA para descorrelacionar los predictores. La siguiente receta contiene pasos para transformar los predictores para aumentar la simetría, normalizarlos para que estén en la misma escala y luego realizar la extracción de características. También se ajusta la cantidad de componentes PCA que se conservarán, junto con los parámetros del modelo.\n\n::: rmdwarning\nSi bien los componentes PCA resultantes están técnicamente en la misma escala, los componentes de rango inferior tienden a tener un rango más amplio que los componentes de rango superior. Por esta razón, volvemos a normalizar para obligar a los predictores a tener la misma media y varianza.\n:::\n\nMuchos de los predictores tienen distribuciones sesgadas. Dado que el PCA se basa en la varianza, los valores extremos pueden tener un efecto perjudicial en estos cálculos. Para contrarrestar esto, agreguemos un paso de receta que estime una transformación de Yeo-Johnson para cada predictor [@yeo2000new]. Si bien originalmente se pensó como una transformación del resultado, también se puede utilizar para estimar transformaciones que fomentan distribuciones más simétricas. Este paso `step_YeoJohnson()` ocurre en la receta justo antes de la normalización inicial mediante `step_normalize()`. Luego, combinemos esta receta de ingeniería de características con nuestra especificación de modelo de red neuronal `mlp_spec`.\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-cells-objects_a2e1845dd5f494ba49f64151ebc19116'}\n\n```{.r .cell-code}\nmlp_rec <-\n  recipe(class ~ ., data = cells) %>%\n  step_YeoJohnson(all_numeric_predictors()) %>% \n  step_normalize(all_numeric_predictors()) %>% \n  step_pca(all_numeric_predictors(), num_comp = tune()) %>% \n  step_normalize(all_numeric_predictors())\n\nmlp_wflow <- \n  workflow() %>% \n  add_model(mlp_spec) %>% \n  add_recipe(mlp_rec)\n```\n:::\n\n\nCreemos un objeto de parámetro `mlp_param` para ajustar algunos de los rangos predeterminados. Podemos cambiar el número de épocas para tener un rango más pequeño (50 a 200 épocas). Además, el rango predeterminado para `num_comp()` es un rango muy estrecho (de uno a cuatro componentes); podemos aumentar el rango a 40 componentes y establecer el valor mínimo en cero:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-cells-workflow_65b9ccfb947e4538aa64ca5bf151ebcc'}\n\n```{.r .cell-code}\nmlp_param <- \n  mlp_wflow %>% \n  extract_parameter_set_dials() %>% \n  Matrix::update(\n    epochs = epochs(c(50, 200)),\n    num_comp = num_comp(c(0, 40))\n  )\n```\n:::\n\n\n::: rmdnote\nEn `step_pca()`, usar cero componentes PCA es un atajo para omitir la extracción de funciones. De esta manera, los predictores originales se pueden comparar directamente con los resultados que incluyen componentes PCA.\n:::\n\nLa función `tune_grid()` es la función principal para realizar búsquedas en la cuadrícula. Su funcionalidad es muy similar a `fit_resamples()` de @sec-resampling-performance, aunque tiene argumentos adicionales relacionados con la cuadrícula:\n\n-   `grid`: Un número entero o marco de datos. Cuando se utiliza un número entero, la función crea un diseño que llena el espacio con un número de `grid` de combinaciones de parámetros candidatos. Si existen combinaciones de parámetros específicas, el parámetro `grid` se utiliza para pasarlas a la función.\n\n-   `param_info`: Un argumento opcional para definir los rangos de parámetros. El argumento es más útil cuando `grid` es un número entero.\n\nDe lo contrario, la interfaz para `tune_grid()` es la misma que `fit_resamples()`. El primer argumento es una especificación del modelo o un flujo de trabajo. Cuando se da un modelo, el segundo argumento puede ser una receta o una fórmula. El otro argumento requerido es un objeto de remuestreo <span class=\"pkg\">rsample</span> (como `cell_folds`). La siguiente llamada también pasa un conjunto de métricas para que el área bajo la curva ROC se mida durante el remuestreo.\n\nPara comenzar, evaluemos una cuadrícula regular con tres niveles en los remuestreos:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-cells-regular_785d7594690fa4308051482d7aa587be'}\n\n```{.r .cell-code}\nroc_res <- metric_set(roc_auc)\nset.seed(1305)\nmlp_reg_tune <-\n  mlp_wflow %>%\n  tune_grid(\n    cell_folds,\n    grid = mlp_param %>% grid_regular(levels = 3),\n    metrics = roc_res\n  )\nmlp_reg_tune\n## # Tuning results\n## # 10-fold cross-validation \n## # A tibble: 10 × 4\n##   splits             id     .metrics          .notes          \n##   <list>             <chr>  <list>            <list>          \n## 1 <split [1817/202]> Fold01 <tibble [81 × 8]> <tibble [0 × 3]>\n## 2 <split [1817/202]> Fold02 <tibble [81 × 8]> <tibble [0 × 3]>\n## 3 <split [1817/202]> Fold03 <tibble [81 × 8]> <tibble [0 × 3]>\n## 4 <split [1817/202]> Fold04 <tibble [81 × 8]> <tibble [0 × 3]>\n## 5 <split [1817/202]> Fold05 <tibble [81 × 8]> <tibble [0 × 3]>\n## 6 <split [1817/202]> Fold06 <tibble [81 × 8]> <tibble [0 × 3]>\n## # ℹ 4 more rows\n```\n:::\n\n\nExisten funciones de conveniencia de alto nivel que podemos utilizar para comprender los resultados. Primero, el método `autoplot()` para cuadrículas regulares muestra los perfiles de rendimiento en todos los parámetros de ajuste en @fig-regular-grid-plot.\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-cells-reg-plot_2a5fe7c12bed6c55f85ed316ab254be0'}\n\n```{.r .cell-code}\nautoplot(mlp_reg_tune) + \n  scale_color_viridis_d(direction = -1) + \n  theme(legend.position = \"top\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/fig-regular-grid-plot_a36d61292de8f3d84e0b3c1a9df73beb'}\n::: {.cell-output-display}\n![Los resultados regulares de la cuadrícula.](13-grid-search_files/figure-html/fig-regular-grid-plot-1.png){#fig-regular-grid-plot fig-align='center' fig-alt='Un gráfico de líneas de los resultados de la cuadrícula regular. El eje x muestra el número de unidades ocultas y el eje y es el AUC ROC remuestreado. Hay líneas separadas para el monto de la regularización. Hay nueve paneles para tres valores para la cantidad de componentes PCA y la cantidad de épocas. En promedio, la cantidad de regularización es importante cuando más es mejor. Además, en promedio, el aumento del número de unidades ocultas disminuye la eficacia del modelo.' width=672}\n:::\n:::\n\n\nSegún estos datos, el monto de la penalización tiene el mayor impacto en el área bajo la curva ROC. El número de épocas no parece tener un efecto pronunciado en el rendimiento. El cambio en el número de unidades ocultas parece ser más importante cuando la cantidad de regularización es baja (y perjudica el rendimiento). Hay varias configuraciones de parámetros que tienen un rendimiento aproximadamente equivalente, como se ve usando la función `show_best()`:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-cells-reg-best_a9608818c6423a9a7bec8b47f0c55f77'}\n\n```{.r .cell-code}\nshow_best(mlp_reg_tune) %>% select(-.estimator)\n## # A tibble: 5 × 9\n##   hidden_units penalty epochs num_comp .metric  mean     n std_err .config          \n##          <int>   <dbl>  <int>    <int> <chr>   <dbl> <int>   <dbl> <chr>            \n## 1            5       1     50        0 roc_auc 0.897    10 0.00857 Preprocessor1_Mo…\n## 2           10       1    125        0 roc_auc 0.895    10 0.00898 Preprocessor1_Mo…\n## 3           10       1     50        0 roc_auc 0.894    10 0.00960 Preprocessor1_Mo…\n## 4            5       1    200        0 roc_auc 0.894    10 0.00784 Preprocessor1_Mo…\n## 5            5       1    125        0 roc_auc 0.892    10 0.00822 Preprocessor1_Mo…\n```\n:::\n\n\nCon base en estos resultados, tendría sentido realizar otra ejecución de búsqueda de cuadrícula con valores mayores de penalización por disminución de peso.\n\nPara utilizar un diseño que llene el espacio, al argumento `grid` se le puede dar un número entero o una de las funciones `grid_*()` puede producir un marco de datos. Para evaluar el mismo rango utilizando un diseño de máxima entropía con 20 valores candidatos:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-cells-sdf_1639612023fef58125589a12af2aaace'}\n\n```{.r .cell-code}\nset.seed(1306)\nmlp_sfd_tune <-\n  mlp_wflow %>%\n  tune_grid(\n    cell_folds,\n    grid = 20,\n    # Pase el objeto de parámetro para usar el rango apropiado: \n    param_info = mlp_param,\n    metrics = roc_res\n  )\nmlp_sfd_tune\n## # Tuning results\n## # 10-fold cross-validation \n## # A tibble: 10 × 4\n##   splits             id     .metrics          .notes          \n##   <list>             <chr>  <list>            <list>          \n## 1 <split [1817/202]> Fold01 <tibble [20 × 8]> <tibble [0 × 3]>\n## 2 <split [1817/202]> Fold02 <tibble [20 × 8]> <tibble [0 × 3]>\n## 3 <split [1817/202]> Fold03 <tibble [20 × 8]> <tibble [0 × 3]>\n## 4 <split [1817/202]> Fold04 <tibble [20 × 8]> <tibble [0 × 3]>\n## 5 <split [1817/202]> Fold05 <tibble [20 × 8]> <tibble [0 × 3]>\n## 6 <split [1817/202]> Fold06 <tibble [20 × 8]> <tibble [0 × 3]>\n## # ℹ 4 more rows\n```\n:::\n\n\nEl método `autoplot()` también funcionará con estos diseños, aunque el formato de los resultados será diferente. @fig-sfd-plot se produjo usando `autoplot(mlp_sfd_tune)`.\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/fig-sfd-plot_376c9746421a699e35e86f17603eda47'}\n::: {.cell-output-display}\n![El método `autoplot()` resulta cuando se usa con un diseño que llena el espacio](13-grid-search_files/figure-html/fig-sfd-plot-1.png){#fig-sfd-plot fig-align='center' fig-alt='El método `autoplot()` resulta cuando se usa con un diseño que llena el espacio. Las tendencias muestran un rendimiento decreciente con la cantidad de componentes PCA, así como con la cantidad de unidades ocultas.' width=672}\n:::\n:::\n\n\nEste gráfico de efectos marginales (@fig-sfd-plot) muestra la relación de cada parámetro con la métrica de rendimiento.\n\n::: rmdwarning\nTenga cuidado al examinar esta trama; dado que no se utiliza una cuadrícula normal, los valores de los demás parámetros de ajuste pueden afectar a cada panel.\n:::\n\nEl parámetro de penalización parece dar como resultado un mejor rendimiento con menores cantidades de pérdida de peso. Esto es lo opuesto a los resultados de la cuadrícula normal. Dado que cada punto de cada panel se comparte con los otros tres parámetros de ajuste, las tendencias de un panel pueden verse afectadas por los demás. Utilizando una cuadrícula regular, cada punto de cada panel se promedia por igual con respecto a los demás parámetros. Por esta razón, el efecto de cada parámetro se aísla mejor con cuadrículas regulares.\n\nAl igual que con la cuadrícula normal, `show_best()` puede informar sobre los mejores resultados numéricamente:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-cells-sdf-best_20a342ae3c723ba946e5ef3ce5270908'}\n\n```{.r .cell-code}\nshow_best(mlp_sfd_tune) %>% select(-.estimator)\n## # A tibble: 5 × 9\n##   hidden_units       penalty epochs num_comp .metric  mean     n std_err .config    \n##          <int>         <dbl>  <int>    <int> <chr>   <dbl> <int>   <dbl> <chr>      \n## 1            8 0.594             97       22 roc_auc 0.880    10 0.00998 Preprocess…\n## 2            3 0.00000000649    135        8 roc_auc 0.878    10 0.00953 Preprocess…\n## 3            9 0.141            177       11 roc_auc 0.873    10 0.0104  Preprocess…\n## 4            8 0.0000000103      74        9 roc_auc 0.869    10 0.00761 Preprocess…\n## 5            6 0.00581          129       15 roc_auc 0.865    10 0.00658 Preprocess…\n```\n:::\n\n\nGeneralmente, es una buena idea evaluar los modelos según múltiples métricas para tener en cuenta diferentes aspectos del ajuste del modelo. Además, a menudo tiene sentido elegir una combinación de parámetros ligeramente subóptima asociada con un modelo más simple. Para este modelo, la simplicidad corresponde a valores de penalización mayores y/o menos unidades ocultas.\n\nAl igual que con los resultados de `fit_resamples()`, normalmente no tiene ningún valor conservar los ajustes del modelo intermediario entre los remuestreos y los parámetros de ajuste. Sin embargo, como antes, la opción `extraer` de `control_grid()` permite conservar los modelos y/o recetas ajustados. Además, configurar la opción `save_pred` en `TRUE` conserva las predicciones del conjunto de evaluación y se puede acceder a ellas usando `collect_predictions()`.\n\n## Finalizando El Modelo\n\nSi uno de los conjuntos de posibles parámetros del modelo encontrados mediante `show_best()` fuera una opción final atractiva para estos datos, es posible que deseemos evaluar qué tan bien funciona en el conjunto de prueba. Sin embargo, los resultados de `tune_grid()` solo proporcionan el sustrato para elegir los parámetros de ajuste apropiados. La función *no se ajusta* a un modelo final.\n\nPara ajustar un modelo final, se debe determinar un conjunto final de valores de parámetros. Hay dos métodos para hacerlo:\n\n-   seleccionar manualmente los valores que parezcan apropiados o\n-   utilice una función `select_*()`.\n\nPor ejemplo, `select_best()` elegirá los parámetros con los mejores resultados numéricamente. Volvamos a nuestros resultados habituales de la cuadrícula y veamos cuál es mejor:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-select_6bc7a6fcfdede8b8d8e97c953f10bd90'}\n\n```{.r .cell-code}\nselect_best(mlp_reg_tune, metric = \"roc_auc\")\n## # A tibble: 1 × 5\n##   hidden_units penalty epochs num_comp .config              \n##          <int>   <dbl>  <int>    <int> <chr>                \n## 1            5       1     50        0 Preprocessor1_Model08\n```\n:::\n\n\nMirando hacia atrás en @fig-regular-grid-plot, podemos ver que un modelo con una sola unidad oculta entrenada durante 125 épocas en los predictores originales con una gran cantidad de penalización tiene un rendimiento competitivo con esta opción y es más simple. ¡Esto es básicamente una regresión logística penalizada! Para especificar manualmente estos parámetros, podemos crear un tibble con estos valores y luego usar una función de *finalización* para unir los valores nuevamente en el flujo de trabajo:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-finalize-manual_c2a9e711a933410cf1ee6dad8a460ddb'}\n\n```{.r .cell-code}\nlogistic_param <- \n  tibble(\n    num_comp = 0,\n    epochs = 125,\n    hidden_units = 1,\n    penalty = 1\n  )\n\nfinal_mlp_wflow <- \n  mlp_wflow %>% \n  finalize_workflow(logistic_param)\nfinal_mlp_wflow\n## ══ Workflow ═════════════════════════════════════════════════════════════════════════\n## Preprocessor: Recipe\n## Model: mlp()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## 4 Recipe Steps\n## \n## • step_YeoJohnson()\n## • step_normalize()\n## • step_pca()\n## • step_normalize()\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## Single Layer Neural Network Model Specification (classification)\n## \n## Main Arguments:\n##   hidden_units = 1\n##   penalty = 1\n##   epochs = 125\n## \n## Engine-Specific Arguments:\n##   trace = 0\n## \n## Computational engine: nnet\n```\n:::\n\n\nNo se incluyen más valores de `tune()` en este flujo de trabajo finalizado. Ahora el modelo se puede ajustar a todo el conjunto de entrenamiento:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-final-model_1bccdec6958247f0c52e5b371640f0d6'}\n\n```{.r .cell-code}\nfinal_mlp_fit <- \n  final_mlp_wflow %>% \n  fit(cells)\n```\n:::\n\n\nEste objeto ahora se puede utilizar para hacer predicciones futuras sobre nuevos datos.\n\nSi no usó un flujo de trabajo, la finalización de un modelo y/o receta se realiza usando `finalize_model()` y `finalize_recipe()`.\n\n## Herramientas Para Crear Especificaciones De Ajuste {#sec-tuning-usemodels}\n\nEl paquete <span class=\"pkg\">usemodels</span> puede tomar un marco de datos y una fórmula de modelo, luego escribir código R para ajustar el modelo. El código también crea una receta adecuada cuyos pasos dependen del modelo solicitado, así como de los datos del predictor.\n\nPor ejemplo, para los datos de vivienda de Ames, el código de modelado `xgboost` podría crearse con:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/models-use-models-code_5ebc6d55414a65811a1df32646d86bef'}\n\n```{.r .cell-code}\nlibrary(usemodels)\n\nuse_xgboost(Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type + \n              Latitude + Longitude, \n            data = ames_train,\n            # Agregue comentarios que expliquen parte del código:\n            verbose = TRUE)\n```\n:::\n\n\nEl código resultante es el siguiente:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/models-use-models-res_7fd8b91174d87b5c09fde3234349d445'}\n\n```{.r .cell-code}\nxgboost_recipe <- \n  recipe(formula = Sale_Price ~ Neighborhood + Gr_Liv_Area + Year_Built + Bldg_Type + \n    Latitude + Longitude, data = ames_train) %>% \n  step_novel(all_nominal_predictors()) %>% \n  ## Este modelo requiere que los predictores sean numéricos. \n  ## El método más común para convertir predictores cualitativos \n  ## en numéricos es crear variables indicadoras binarias \n  ## (también conocidas como variables ficticias) a partir de estos \n  ## predictores. Sin embargo, para este modelo, se pueden crear \n  ## variables indicadoras binarias para cada uno de los niveles de \n  ## los factores (lo que se conoce como \"codificación one-hot\").\n  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>% \n  step_zv(all_predictors()) \n\nxgboost_spec <- \n  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), \n    loss_reduction = tune(), sample_size = tune()) %>% \n  set_mode(\"regression\") %>% \n  set_engine(\"xgboost\") \n\nxgboost_workflow <- \n  workflow() %>% \n  add_recipe(xgboost_recipe) %>% \n  add_model(xgboost_spec) \n\nset.seed(69305)\nxgboost_tune <-\n  tune_grid(xgboost_workflow, \n            resamples = stop(\"agregue su objeto rsample\"), \n            grid = stop(\"agregar número de puntos candidatos\"))\n```\n:::\n\n\nSegún lo que entiende <span class=\"pkg\">usemodels</span> sobre los datos, este código es el preprocesamiento mínimo requerido. Para otros modelos, se agregan operaciones como `step_normalize()` para satisfacer las necesidades básicas del modelo. Tenga en cuenta que es nuestra responsabilidad, como practicante del modelado, elegir qué remuestras, `resamples`, usar para la afinación, así como qué tipo de cuadrícula, `grid`.\n\n::: rmdnote\nEl paquete <span class=\"pkg\">usemodels</span> también se puede utilizar para crear código de ajuste de modelo sin ajuste estableciendo el argumento `tune = FALSE`.\n:::\n\n## Herramientas Para Una Búsqueda Eficiente En La Cuadrícula {#sec-efficient-grids}\n\nEs posible hacer que la búsqueda en cuadrícula sea más eficiente desde el punto de vista computacional aplicando algunos trucos y optimizaciones diferentes. Esta sección describe varias técnicas.\n\n### Optimización del submodelo {#sec-submodel-trick}\n\nHay tipos de modelos en los que, a partir de un único ajuste de modelo, se pueden evaluar múltiples parámetros de ajuste sin necesidad de reajustarlos.\n\nPor ejemplo, los mínimos cuadrados parciales (PLS) son una versión supervisada del análisis de componentes principales [@Geladi:1986]. Crea componentes que maximizan la variación en los predictores (como PCA) pero simultáneamente intenta maximizar la correlación entre estos predictores y el resultado. Exploraremos más PLS en el [Capítulo @sec-dimensionality]. Un parámetro de ajuste es el número de componentes PLS que se conservarán. Supongamos que un conjunto de datos con 100 predictores se ajusta mediante PLS. El número de posibles componentes a conservar puede oscilar entre uno y cincuenta. Sin embargo, en muchas implementaciones, un único ajuste de modelo puede calcular valores predichos en muchos valores de `num_comp`. Como resultado, un modelo PLS creado con 100 componentes también puede hacer predicciones para cualquier `num_comp <= 100`. Esto ahorra tiempo ya que, en lugar de crear ajustes de modelo redundantes, se puede utilizar un ajuste único para evaluar muchos submodelos.\n\nSi bien no todos los modelos pueden aprovechar esta característica, muchos de los más utilizados sí lo hacen.\n\n-   Los modelos de impulso normalmente pueden hacer predicciones en múltiples valores para el número de iteraciones de impulso.\n\n-   Los métodos de regularización, como el modelo <span class=\"pkg\">glmnet</span>, pueden realizar predicciones simultáneas sobre la cantidad de regularización utilizada para ajustar el modelo.\n\n-   Los splines de regresión adaptativa multivariada (MARS) añaden un conjunto de características no lineales a los modelos de regresión lineal [@Friedman:1991p109]. El número de términos a retener es un parámetro de ajuste y es computacionalmente rápido hacer predicciones sobre muchos valores de este parámetro a partir de un único ajuste de modelo.\n\nEl paquete <span class=\"pkg\">tune</span> aplica automáticamente este tipo de optimización cada vez que se ajusta un modelo aplicable.\n\nPor ejemplo, si se ajustó un modelo de clasificación C5.0 mejorado [@apm] a los datos de la celda, podemos ajustar el número de iteraciones de refuerzo (\"árboles\"). Con todos los demás parámetros establecidos en sus valores predeterminados, podemos evaluar iteraciones de 1 a 100 en las mismas muestras utilizadas anteriormente:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-c5_2a1418c1e063f4f629228057af7e776b'}\n\n```{.r .cell-code}\nc5_spec <- \n  boost_tree(trees = tune()) %>% \n  set_engine(\"C5.0\") %>% \n  set_mode(\"classification\")\n\nset.seed(1307)\nc5_spec %>%\n  tune_grid(\n    class ~ .,\n    resamples = cell_folds,\n    grid = data.frame(trees = 1:100),\n    metrics = roc_res\n  )\n```\n:::\n\n\nSin la optimización del submodelo, la llamada a `tune_grid()` usó 62.2 minutos para volver a muestrear 100 submodelos. Con la optimización, la misma llamada tomó 100 *segundos* (una aceleración de 37). El tiempo reducido es la diferencia entre `tune_grid()` que ajusta 1000 modelos frente a 10 modelos.\n\n::: rmdnote\nAunque ajustamos el modelo con y sin el truco de predicción del submodelo, esta optimización se aplica automáticamente mediante <span class=\"pkg\">parsnip</span>.\n:::\n\n### Procesamiento en paralelo\n\nComo se mencionó anteriormente en @sec-parallel, el procesamiento paralelo es un método eficaz para disminuir el tiempo de ejecución al volver a muestrear modelos. Esta ventaja se transmite al ajuste del modelo mediante búsqueda en cuadrícula, aunque existen consideraciones adicionales.\n\nConsideremos dos esquemas de procesamiento paralelo diferentes.\n\nAl ajustar modelos mediante búsqueda de cuadrícula, hay dos bucles distintos: uno sobre remuestreos y otro sobre combinaciones únicas de parámetros de ajuste. En pseudocódigo, este proceso se vería así:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-resamples-algo_99fdd3b817a9cbe8ad96107046b0656f'}\n\n```{.r .cell-code}\nfor (rs in resamples) {\n  # Crear conjuntos de análisis y evaluación.\n  # Preprocesar datos (por ejemplo, fórmula o receta)\n  for (mod in configurations) {\n    # Ajustar el modelo {mod} al conjunto de análisis {rs}\n    # Predecir el conjunto de evaluación {rs}\n  }\n}\n```\n:::\n\n\nDe forma predeterminada, el paquete <span class=\"pkg\">tune</span> paraleliza solo sobre remuestreos (el bucle externo), a diferencia de los bucles externo e interno.\n\nEste es el escenario óptimo cuando el método de preprocesamiento es costoso. Sin embargo, este enfoque tiene dos posibles desventajas:\n\n-   Limita las aceleraciones alcanzables cuando el preprocesamiento no es caro.\n\n-   El número de trabajadores paralelos está limitado por el número de remuestras. Por ejemplo, con una validación cruzada de 10 veces, puede utilizar solo 10 trabajadores paralelos incluso cuando la computadora tiene más de 10 núcleos.\n\nPara ilustrar cómo funciona el procesamiento paralelo, usaremos un caso en el que hay 7 valores de parámetros de ajuste del modelo, con validación cruzada quíntuple. @fig-one-resample-per-worker muestra cómo se asignan las tareas a los procesos de trabajo.\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/fig-one-resample-per-worker_1ddb07a6e5f5dc78fc0e62e397b054d2'}\n::: {.cell-output-display}\n![Procesos de trabajo cuando el procesamiento paralelo hace coincidir los remuestreos con un proceso de trabajo específico](13-grid-search_files/figure-html/fig-one-resample-per-worker-1.png){#fig-one-resample-per-worker fig-align='center' fig-alt='Un diagrama de los procesos de trabajo cuando el procesamiento paralelo coincide con los remuestreos de un proceso de trabajo específico. Una vez finalizadas las operaciones de preproceso, cada ajuste de modelo se ejecuta en el mismo proceso de trabajo.' width=50%}\n:::\n:::\n\n\nTenga en cuenta que cada pliegue se asigna a su propio proceso de trabajo y, dado que solo se están ajustando los parámetros del modelo, el preprocesamiento se realiza una vez por pliegue/trabajador. Si se utilizaran menos de cinco procesos de trabajo, algunos trabajadores recibirían múltiples pliegues.\n\nEn las funciones de control para las funciones `tune_*()`, el argumento `parallel_over` controla cómo se ejecuta el proceso. Para utilizar la estrategia de paralelización anterior, el argumento es `parallel_over = \"resamples\"`.\n\nEn lugar de procesar los remuestreos en paralelo, un esquema alternativo combina los bucles sobre los remuestreos y los modelos en un solo bucle. En pseudocódigo, este proceso se vería así:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-everything-algo_133d0e7c23488a2ece697c1ac8e1284e'}\n\n```{.r .cell-code}\nall_tasks <- crossing(resamples, configurations)\n\nfor (iter in all_tasks) {                           \n  # Crear conjuntos de análisis y evaluación para {iter}\n  # Preprocesar datos (e.j. formula or recipe)\n  # Ajustar el modelo {iter} al conjunto de análisis {iter}\n  # Predecir el conjunto de evaluación {iter}\n}\n```\n:::\n\n\nEn este caso, la paralelización se produce ahora en un bucle único. Por ejemplo, si utilizamos validación cruzada quíntuple con valores de parámetros de ajuste $M$, el bucle se ejecuta en $5\\times M$ iteraciones. Esto aumenta el número de trabajadores potenciales que se pueden utilizar. Sin embargo, el trabajo relacionado con el preprocesamiento de datos se repite varias veces. Si esas medidas son costosas, este enfoque será ineficiente.\n\nEn tidymodels, los conjuntos de validación se tratan como un único remuestreo. En estos casos, este esquema de paralelización sería el mejor.\n\n@fig-distributed-tasks ilustra la delegación de tareas a los trabajadores en este plan; se utiliza el mismo ejemplo pero con 10 trabajadores.\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/fig-distributed-tasks_8cf08d773d8828b90816f60b8dd0701b'}\n::: {.cell-output-display}\n![Procesos de trabajo cuando las tareas de preprocesamiento y modelado se distribuyen a muchos trabajadores](13-grid-search_files/figure-html/fig-distributed-tasks-1.png){#fig-distributed-tasks fig-align='center' fig-alt='Un diagrama de los procesos de los trabajadores cuando las tareas de preprocesamiento y modelado se distribuyen a muchos trabajadores. En este caso, se utiliza una paralelización más completa, pero algunas tareas de preprocesamiento se repiten en todos los procesos de trabajo.' width=70%}\n:::\n:::\n\n\nAquí, cada proceso de trabajo maneja múltiples pliegues y el preprocesamiento se repite innecesariamente. Por ejemplo, para el primer pliegue, el preprocesamiento se calculó seven veces en lugar de una vez.\n\nPara este esquema, el argumento de la función de control es `parallel_over = \"everything\"`.\n\n### Evaluación comparativa de árboles potenciados\n\nPara comparar diferentes esquemas de paralelización posibles, ajustamos un árbol potenciado con el motor <span class=\"pkg\">xgboost</span> utilizando un conjunto de datos de 4000 muestras, con validación cruzada quíntuple y 10 modelos candidatos. Estos datos requirieron algún procesamiento previo de referencia que no requirió ninguna estimación. El preprocesamiento se manejó de tres maneras diferentes:\n\n1.  Preprocese los datos antes de modelar utilizando una canalización <span class=\"pkg\">dplyr</span> (etiquetada como \"ninguna\" en los gráficos posteriores).\n2.  Realice el mismo preprocesamiento mediante una receta (que se muestra como preprocesamiento \"ligero\").\n3.  Con una receta, agregar un paso adicional que tenga un alto costo computacional (etiquetado como \"caro\").\n\nLa primera y segunda opciones de preprocesamiento están diseñadas para comparar, para medir el costo computacional de la receta en la segunda opción. La tercera opción mide el costo de realizar cálculos redundantes con `parallel_over = \"everything\"`.\n\nEvaluamos este proceso usando números variables de procesos de trabajo y usando las dos opciones `parallel_over`, en una computadora con 10 núcleos físicos y 20 núcleos virtuales (mediante hyper-threading).\n\nPrimero, consideremos los tiempos de ejecución sin procesar en @fig-parallel-times.\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/fig-parallel-times_1a6064b093e7df511908b2f08c8f2ae4'}\n::: {.cell-output-display}\n![Tiempos de ejecución para el ajuste del modelo versus la cantidad de trabajadores que utilizan diferentes esquemas de delegación](13-grid-search_files/figure-html/fig-parallel-times-1.png){#fig-parallel-times fig-align='center' fig-alt='Tiempos de ejecución para el ajuste del modelo versus la cantidad de trabajadores que utilizan diferentes esquemas de delegación.' width=70%}\n:::\n:::\n\n\nDado que solo hubo cinco remuestreos, el número de núcleos utilizados cuando `parallel_over = \"resamples\"` está limitado a cinco.\n\nComparando las curvas en los dos primeros paneles para \"none\" y \"light\":\n\n-   Hay poca diferencia en los tiempos de ejecución entre los paneles. Esto indica que, para estos datos, no existe una penalización computacional real por realizar los pasos de preprocesamiento en una receta.\n\n-   Hay algunos beneficios al usar `parallel_over = \"everything\"` con muchos núcleos. Sin embargo, como se muestra en la figura, la mayor parte del beneficio del procesamiento paralelo ocurre en los primeros cinco trabajadores.\n\nCon el costoso paso de preprocesamiento, existe una diferencia considerable en los tiempos de ejecución. Usar `parallel_over = \"everything\"` es problemático ya que, incluso usando todos los núcleos, nunca alcanza el tiempo de ejecución que `parallel_over = \"resamples\"` logra con solo cinco núcleos. Esto se debe a que el costoso paso de preprocesamiento se repite innecesariamente en el esquema computacional.\n\nTambién podemos ver estos datos en términos de aceleraciones en @fig-parallel-speedups.\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/fig-parallel-speedups_a38a60955abac7b8d94b0fc8f18b9593'}\n::: {.cell-output-display}\n![Aceleraciones en el ajuste del modelo frente al número de trabajadores que utilizan diferentes esquemas de delegación. La línea negra diagonal indica una aceleración lineal donde la adición de un nuevo proceso de trabajo tiene el máximo efecto.](13-grid-search_files/figure-html/fig-parallel-speedups-1.png){#fig-parallel-speedups fig-align='center' fig-alt='Aceleraciones en el ajuste del modelo frente al número de trabajadores que utilizan diferentes esquemas de delegación. La línea negra diagonal indica una aceleración lineal donde la adición de un nuevo proceso de trabajo tiene el máximo efecto. El esquema \\'todo\\' muestra que los beneficios disminuyen después de tres o cuatro trabajadores, especialmente cuando hay un procesamiento previo costoso. El esquema de \\'nuevas muestras\\' tiene aceleraciones casi lineales en todas las tareas.' width=70%}\n:::\n:::\n\n\nLas mejores aceleraciones, para estos datos, ocurren cuando `parallel_over = \"resamples\"` y cuando los cálculos son costosos. Sin embargo, en este último caso, recuerde que el análisis anterior indica que los ajustes generales del modelo son más lentos.\n\n¿Cuál es el beneficio de utilizar el método de optimización de submodelos junto con el procesamiento paralelo? El modelo de clasificación C5.0 que se muestra en @sec-submodel-trick también se ejecutó en paralelo con diez trabajadores. Los cálculos paralelos tomaron 13,3 segundos para acelerar 7.5 (ambas ejecuciones utilizaron el truco de optimización del submodelo). Entre el truco de optimización del submodelo y el procesamiento paralelo, hubo una aceleración total de 282 sobre el código de búsqueda de cuadrícula más básico.\n\n::: rmdwarning\nEn general, tenga en cuenta que el aumento de los ahorros computacionales variará de un modelo a otro y también se verá afectado por el tamaño de la cuadrícula, la cantidad de remuestreos, etc. Es posible que un modelo muy eficiente desde el punto de vista computacional no se beneficie tanto del procesamiento paralelo.\n:::\n\n### Acceso a variables globales\n\nCuando se utilizan tidymodels, es posible utilizar valores en su entorno local (normalmente el entorno global) en los objetos del modelo.\n\n::: rmdnote\n¿Qué entendemos aquí por \"medio ambiente\"? Piense en un entorno en R como un lugar para almacenar variables con las que puede trabajar. Consulte el capítulo \"Entornos\" de @wickham2019advanced para obtener más información.\n:::\n\nSi definimos una variable para usar como parámetro del modelo y luego la pasamos a una función como `linear_reg()`, la variable normalmente se define en el entorno global.\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-spec-global_c4545922d996ccfeb73a2cd4c45ae40a'}\n\n```{.r .cell-code}\ncoef_penalty <- 0.1\nspec <- linear_reg(penalty = coef_penalty) %>% set_engine(\"glmnet\")\nspec\n## Linear Regression Model Specification (regression)\n## \n## Main Arguments:\n##   penalty = coef_penalty\n## \n## Computational engine: glmnet\n```\n:::\n\n\nLos modelos creados con el paquete parsnip guardan argumentos como estos como *quosures*; se trata de objetos que rastrean tanto el nombre del objeto como el entorno donde vive:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-spec-quo_0cfa0644a2d936a278f624a7665bf973'}\n\n```{.r .cell-code}\nspec$args$penalty\n## <quosure>\n## expr: ^coef_penalty\n## env:  global\n```\n:::\n\n\nObserve que tenemos `env: global` porque esta variable se creó en el entorno global. La especificación del modelo definida por `spec` funciona correctamente cuando se ejecuta en la sesión normal de un usuario porque esa sesión también utiliza el entorno global; R puede encontrar fácilmente el objeto `coef_penalty`.\n\n::: rmdwarning\nCuando un modelo de este tipo se evalúa con trabajadores paralelos, puede fallar. Dependiendo de la tecnología particular que se utilice para el procesamiento paralelo, es posible que los trabajadores no tengan acceso al entorno global.\n:::\n\nAl escribir código que se ejecutará en paralelo, es una buena idea insertar los datos reales en los objetos en lugar de la referencia al objeto. Los paquetes <span class=\"pkg\">rlang</span> y <span class=\"pkg\">dplyr</span> pueden resultar muy útiles para esto. Por ejemplo, el operador `!!` puede unir un único valor en un objeto:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-spec-bang-bang_56e7ab473d44998cc9acb09b1b4d6057'}\n\n```{.r .cell-code}\nspec <- linear_reg(penalty = !!coef_penalty) %>% set_engine(\"glmnet\")\nspec$args$penalty\n## <quosure>\n## expr: ^0.1\n## env:  empty\n```\n:::\n\n\nAhora la salida es `^0.1`, lo que indica que el valor está ahí en lugar de la referencia al objeto. Cuando tiene varios valores externos para insertar en un objeto, el operador `!!!` puede ayudar:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-spec-bang-bang-bang_6a5664a0088475ff6838a3c4f503a102'}\n\n```{.r .cell-code}\nmcmc_args <- list(chains = 3, iter = 1000, cores = 3)\n\nlinear_reg() %>% set_engine(\"stan\", !!!mcmc_args)\n## Linear Regression Model Specification (regression)\n## \n## Engine-Specific Arguments:\n##   chains = 3\n##   iter = 1000\n##   cores = 3\n## \n## Computational engine: stan\n```\n:::\n\n\nLos selectores de recetas son otro lugar donde es posible que desees acceder a variables globales. Suponga que tiene un paso de receta que debería utilizar todos los predictores en los datos de la celda que se midieron utilizando el segundo canal óptico. Podemos crear un vector de estos nombres de columnas:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-ch-2_1fec5a5f1767f1fff3cc35e7743fa348'}\n\n```{.r .cell-code}\nlibrary(stringr)\nch_2_vars <- str_subset(names(cells), \"ch_2\")\nch_2_vars\n## [1] \"avg_inten_ch_2\"   \"total_inten_ch_2\"\n```\n:::\n\n\nPodríamos codificarlos en un paso de receta, pero sería mejor hacer referencia a ellos mediante programación en caso de que los datos cambien. Dos formas de hacer esto son:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-ch-2-rec_89943f77079c69db9bb4d22c63af2a42'}\n\n```{.r .cell-code}\n# Todavía utiliza una referencia a datos globales. (~_~;)\nrecipe(class ~ ., data = cells) %>% \n  step_spatialsign(all_of(ch_2_vars))\n## \n## ── Recipe ───────────────────────────────────────────────────────────────────────────\n## \n## ── Inputs\n## Number of variables by role\n## outcome:    1\n## predictor: 56\n## \n## ── Operations\n## • Spatial sign on: all_of(ch_2_vars)\n\n# Inserta los valores en el paso. ヽ(•‿•)ノ\nrecipe(class ~ ., data = cells) %>% \n  step_spatialsign(!!!ch_2_vars)\n## \n## ── Recipe ───────────────────────────────────────────────────────────────────────────\n## \n## ── Inputs\n## Number of variables by role\n## outcome:    1\n## predictor: 56\n## \n## ── Operations\n## • Spatial sign on: \"avg_inten_ch_2\", \"total_inten_ch_2\"\n```\n:::\n\n\nEste último es mejor para el procesamiento paralelo porque toda la información necesaria está integrada en el objeto de receta.\n\n### Métodos de carrera {#sec-racing}\n\nUn problema con la búsqueda de cuadrícula es que todos los modelos deben ajustarse en todas las muestras antes de poder evaluar cualquier parámetro de ajuste. Sería útil si, en cambio, en algún momento durante el ajuste, se pudiera realizar un análisis intermedio para eliminar cualquier parámetro candidato realmente terrible. Esto sería similar al *análisis de inutilidad* en ensayos clínicos. Si un nuevo fármaco tiene un rendimiento excesivamente malo (o bueno), es potencialmente poco ético esperar hasta que finalice el ensayo para tomar una decisión.\n\nEn el aprendizaje automático, el conjunto de técnicas llamadas *métodos de carrera* proporcionan una función similar [@maron1994hoeffding]. Aquí, el proceso de ajuste evalúa todos los modelos en un subconjunto inicial de remuestreos. Según sus métricas de rendimiento actuales, algunos conjuntos de parámetros no se consideran en remuestreos posteriores.\n\n\n\n\n\nComo ejemplo, en el proceso de ajuste del perceptrón multicapa con una cuadrícula regular explorado en este capítulo, ¿cómo se verían los resultados después de solo los primeros tres pliegues? Usando técnicas similares a las que se muestran en el [Capítulo @sec-compare], podemos ajustar un modelo donde el resultado es el área remuestreada bajo la curva ROC y el predictor es un indicador para la combinación de parámetros. El modelo tiene en cuenta el efecto de remuestreo a remuestreo y produce estimaciones puntuales y de intervalo para cada configuración de parámetro. Los resultados del modelo son intervalos de confianza unilaterales del 95% que miden la pérdida del valor ROC en relación con los parámetros de mejor rendimiento actualmente, como se muestra en @fig-racing-process.\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/fig-racing-process_496967409ccf2e0a027bdb4b585dd43b'}\n::: {.cell-output-display}\n![El proceso de carrera para 20 parámetros de afinación y 10 resampleos.](13-grid-search_files/figure-html/fig-racing-process-1.png){#fig-racing-process fig-align='center' fig-alt='Una ilustración del proceso de carrera para 20 parámetros de ajuste y 10 remuestreos. El análisis se realiza en la primera, tercera y última muestra. A medida que aumenta el número de remuestras, los intervalos de confianza muestran algunas configuraciones del modelo que no tienen intervalos de confianza que se superpongan con cero. Estos quedan excluidos de remuestreos posteriores.' width=80%}\n:::\n:::\n\n\nCualquier conjunto de parámetros cuyo intervalo de confianza incluya cero carecería de evidencia de que su desempeño sea estadísticamente diferente de los mejores resultados. Mantenemos la configuración de 6; estos se vuelven a muestrear más. Los submodelos restantes 14 ya no se consideran.\n\n\n\n\n\n<video width=\"720\" height=\"720\" controls>\n\n<source src=\"race_results.mp4\" type=\"video/mp4\">\n\n</video>\n\nEl proceso continúa para cada nueva muestra; después del siguiente conjunto de métricas de rendimiento, se ajusta un nuevo modelo a estas estadísticas y potencialmente se descartan más submodelos.[^13-grid-search-2]\n\n[^13-grid-search-2]: Consulte @kuhn2014futility para obtener más detalles sobre los aspectos computacionales de este enfoque.\n\n::: rmdwarning\nLos métodos de carrera pueden ser más eficientes que la búsqueda básica en la cuadrícula siempre que el análisis intermedio sea rápido y algunas configuraciones de parámetros tengan un rendimiento deficiente. También es más útil cuando el modelo *no* tiene la capacidad de explotar las predicciones del submodelo.\n:::\n\nEl paquete <span class=\"pkg\">finetune</span> contiene funciones para carreras. La función `tune_race_anova()` realiza un modelo ANOVA para probar la significancia estadística de las diferentes configuraciones del modelo. La sintaxis para reproducir el filtrado mostrado anteriormente es:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-cells-race-code_29d57aa1fa57f6aaec1136d0a1b59ef8'}\n\n```{.r .cell-code}\nlibrary(finetune)\n\nset.seed(1308)\nmlp_sfd_race <-\n  mlp_wflow %>%\n  tune_race_anova(\n    cell_folds,\n    grid = 20,\n    param_info = mlp_param,\n    metrics = roc_res,\n    control = control_race(verbose_elim = TRUE)\n  )\n```\n:::\n\n\nLos argumentos reflejan los de `tune_grid()`. La función `control_race()` tiene opciones para el procedimiento de eliminación.\n\nComo se muestra en la animación anterior, se estaban considerando combinaciones de parámetros de ajuste one una vez que se evaluó el conjunto completo de remuestreos. `show_best()` devuelve los mejores modelos (clasificados por rendimiento) pero solo devuelve las configuraciones que nunca fueron eliminadas:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/grid-race-best_76366ec3d832d12f3e1c050e91a633c0'}\n\n```{.r .cell-code}\nshow_best(mlp_sfd_race, n = 10)\n## # A tibble: 1 × 10\n##   hidden_units penalty epochs num_comp .metric .estimator  mean     n std_err\n##          <int>   <dbl>  <int>    <int> <chr>   <chr>      <dbl> <int>   <dbl>\n## 1            8   0.814    177       15 roc_auc binary     0.890    10 0.00966\n## # ℹ 1 more variable: .config <chr>\n```\n:::\n\n\nExisten otras técnicas de análisis intermedio para descartar configuraciones. Por ejemplo, @krueger15a usa métodos de análisis secuencial tradicionales, mientras que @kuhn2014futility trata los datos como una competencia deportiva y usa el modelo Bradley-Terry [@bradley1952rank] para medir la capacidad ganadora de la configuración de parámetros.\n\n## Resumen Del Capítulo {#sec-grid-summary}\n\nEste capítulo analizó las dos clases principales de búsqueda de cuadrículas (regular y no regular) que se pueden usar para ajustar el modelo y demostró cómo construir estas cuadrículas, ya sea manualmente o usando la familia de funciones `grid_*()`. La función `tune_grid()` puede evaluar estos conjuntos candidatos de parámetros del modelo mediante remuestreo. El capítulo también mostró cómo finalizar un modelo, receta o flujo de trabajo para actualizar los valores de los parámetros para el ajuste final. La búsqueda en cuadrícula puede ser costosa desde el punto de vista computacional, pero las decisiones bien pensadas en el diseño experimental de dichas búsquedas pueden hacerlas manejables.\n\nEl código de análisis de datos que se reutilizará en el próximo capítulo es:\n\n\n::: {.cell layout-align=\"center\" hash='13-grid-search_cache/html/resampling-summary_cff382e9ff11c5712a1a11fcc70960f0'}\n\n```{.r .cell-code}\nlibrary(tidymodels)\n\ndata(cells)\ncells <- cells %>% select(-case)\n\nset.seed(1304)\ncell_folds <- vfold_cv(cells)\n\nroc_res <- metric_set(roc_auc)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}