{
  "hash": "15c686f901c0a0936a26c3dbd1894dca",
  "result": {
    "markdown": "\n\n\n# Un Flujo De Modelado {#sec-workflows}\n\nEn el capítulo anterior, analizamos el paquete <span class=\"pkg\">parsnip</span>, que se puede utilizar para definir y ajustar el modelo. Este capítulo presenta un nuevo concepto llamado *flujo de modelado*. El propósito de este concepto (y el objeto tidymodels `workflow()` correspondiente) es encapsular las partes principales del proceso de modelado (discutido en @sec-model-phases). El flujo de trabajo es importante en dos sentidos. En primer lugar, utilizar un concepto de flujo de trabajo fomenta una buena metodología, ya que es un punto de entrada único a los componentes de estimación de un análisis de datos. En segundo lugar, permite al usuario organizar mejor los proyectos. Estos dos puntos se analizan en las siguientes secciones.\n\n## ¿Dónde Comienza Y Termina El Modelo? {#sec-begin-model-end}\n\nHasta ahora, cuando hemos utilizado el término \"el modelo\", nos referimos a una ecuación estructural que relaciona algunos predictores con uno o más resultados. Consideremos nuevamente la regresión lineal como ejemplo. Los datos de resultado se indican como $y_i$, donde hay $i = 1 \\ldots n$ muestras en el conjunto de entrenamiento. Supongamos que hay $p$ predictores $x_{i1}, \\ldots, x_{ip}$ que se utilizan en el modelo. La regresión lineal produce una ecuación modelo de\n\n$$ \\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_{i1} + \\ldots + \\hat{\\beta}_px_{ip} $$\n\nSi bien este es un modelo lineal, es lineal sólo en los parámetros. Los predictores podrían ser términos no lineales (como el $\\log(x_i)$).\n\n::: rmdwarning\nLa forma convencional de pensar sobre el proceso de modelado es que sólo incluye el ajuste del modelo.\n:::\n\nPara algunos conjuntos de datos sencillos, ajustar el modelo en sí puede ser todo el proceso. Sin embargo, a menudo se presentan una variedad de opciones y pasos adicionales antes de que el modelo se ajuste:\n\n-   Si bien nuestro modelo de ejemplo tiene predictores $p$, es común comenzar con más predictores candidatos $p$. Mediante un análisis de datos exploratorio o utilizando el conocimiento del dominio, algunos de los predictores pueden excluirse del análisis. En otros casos, se puede utilizar un algoritmo de selección de características para realizar una elección basada en datos para el conjunto de predictores mínimo para el modelo.\n-   Hay ocasiones en las que falta el valor de un predictor importante. En lugar de eliminar esta muestra del conjunto de datos, el valor faltante podría imputarse utilizando otros valores de los datos. Por ejemplo, si faltara $x_1$ pero estuviera correlacionado con los predictores $x_2$ y $x_3$, un método de imputación podría estimar la observación faltante de $x_1$ a partir de los valores de $x_2$ y $x_3$.\n-   Puede resultar beneficioso transformar la escala de un predictor. Si no hay información *a priori* sobre cuál debería ser la nueva escala, podemos estimar la escala adecuada utilizando una técnica de transformación estadística, los datos existentes y algún criterio de optimización. Otras transformaciones, como PCA, toman grupos de predictores y los transforman en nuevas características que se utilizan como predictores.\n\nSi bien estos ejemplos están relacionados con pasos que ocurren antes de que el modelo se ajuste, también puede haber operaciones que ocurren después de que se crea el modelo. Cuando se crea un modelo de clasificación donde el resultado es binario (por ejemplo, \"evento\" y \"no evento\"), se acostumbra utilizar un límite de probabilidad del 50% para crear una predicción de clase discreta, también conocida como predicción dura. Por ejemplo, un modelo de clasificación podría estimar que la probabilidad de un evento era del 62%. Usando el valor predeterminado típico, la predicción difícil sería \"evento\". Sin embargo, es posible que el modelo deba centrarse más en reducir los resultados falsos positivos (es decir, donde los verdaderos no eventos se clasifican como eventos). Una forma de hacerlo es elevar el límite del 50% a un valor mayor. Esto aumenta el nivel de evidencia requerido para llamar evento a una nueva muestra. Si bien esto reduce la tasa de verdaderos positivos (lo cual es malo), puede tener un efecto más dramático en la reducción de falsos positivos. La elección del valor de corte debe optimizarse utilizando datos. Este es un ejemplo de un paso de posprocesamiento que tiene un efecto significativo en el funcionamiento del modelo, aunque no esté incluido en el paso de ajuste del modelo.\n\nEs importante centrarse en el *proceso de modelado* más amplio, en lugar de ajustar únicamente el modelo específico utilizado para estimar los parámetros. Este proceso más amplio incluye cualquier paso de preprocesamiento, el ajuste del modelo en sí mismo, así como posibles actividades de posprocesamiento. En este libro, nos referiremos a este concepto más completo como *flujo de modelado* y resaltaremos cómo manejar todos sus componentes para producir una ecuación de modelo final.\n\n::: rmdnote\nEn otro software, como Python o Spark, colecciones similares de pasos se denominan *pipelines*. En tidymodels, el término \"pipeline\" ya connota una secuencia de operaciones encadenadas con un operador de pipe (como `%>%` de <span class=\"pkg\">magrittr</span> o el nativo más nuevo `|>`). En lugar de utilizar terminología ambigua en este contexto, llamamos a la secuencia de operaciones computacionales relacionadas con el modelado *flujos de trabajo*.\n:::\n\nUnir los componentes analíticos del análisis de datos es importante por otra razón. Los capítulos futuros demostrarán cómo medir con precisión el rendimiento, así como también cómo optimizar los parámetros estructurales (es decir, ajuste del modelo). Para cuantificar correctamente el rendimiento del modelo en el conjunto de entrenamiento, \\[Capítulo \\@ sec-resampling\\] recomienda el uso de métodos de remuestreo. Para hacer esto correctamente, no se debe excluir de la validación ninguna parte del análisis basada en datos. Para ello, el flujo de trabajo debe incluir todos los pasos de estimación importantes.\n\nA modo de ejemplo, considere la extracción de señales del análisis de componentes principales (PCA). Hablaremos más sobre esto en @sec-example-steps y en el [Capítulo @sec-dimensionality]; PCA es una forma de reemplazar predictores correlacionados con nuevas características artificiales que no están correlacionadas y capturan la mayor parte de la información del conjunto original. Las nuevas características podrían usarse como predictores y la regresión de mínimos cuadrados podría usarse para estimar los parámetros del modelo.\n\nHay dos formas de pensar sobre el flujo de trabajo del modelo. @fig-bad-workflow ilustra el método *incorrecto*: pensar que el paso de preprocesamiento de PCA *no forma parte del flujo de trabajo de modelado*.\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/fig-bad-workflow_bbba6c1b8b2e2862ef1790770c3dc1a8'}\n::: {.cell-output-display}\n![Modelo mental incorrecto de dónde ocurre la estimación del modelo en el proceso de análisis de datos](premade/bad-workflow.svg){#fig-bad-workflow fig-align='center' fig-alt='Un modelo mental incorrecto de dónde ocurre la estimación del modelo en el proceso de análisis de datos. Los datos y el conjunto de predictores son sustratos para un paso de preprocesamiento inicial utilizando PCA. Estos datos se pasan al algoritmo de ajuste del modelo para producir un modelo ajustado. La figura indica que el flujo de trabajo del modelo solo incluye el proceso de ajuste del modelo. Esto implica que el ajuste del modelo es el único lugar donde se produce la estimación.' width=80%}\n:::\n:::\n\n\nLa falacia aquí es que, aunque PCA realiza cálculos importantes para producir los componentes, se supone que sus operaciones no tienen incertidumbre asociada con ellos. Los componentes de PCA se tratan como *conocidos* y, si no se incluyen en el flujo de trabajo del modelo, el efecto de PCA no se podría medir adecuadamente.\n\n@fig-good-workflow muestra un enfoque *apropiado*.\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/fig-good-workflow_d44fa432b0d75f2b5599e760d7b116ed'}\n::: {.cell-output-display}\n![Modelo mental correcto de dónde ocurre la estimación del modelo en el proceso de análisis de datos.](premade/proper-workflow.svg){#fig-good-workflow fig-align='center' fig-alt='Un modelo mental correcto de dónde ocurre la estimación del modelo en el proceso de análisis de datos. Los datos y el conjunto de predictores son sustratos para un paso de preprocesamiento inicial utilizando PCA. Estos datos se pasan al algoritmo de ajuste del modelo para producir un modelo ajustado. La figura indica que el flujo de trabajo del modelo incluye el proceso de ajuste del modelo y el paso PCA. Esto implica que ambas operaciones deben considerarse pasos de estimación.' width=80%}\n:::\n:::\n\n\nDe esta forma, el preprocesamiento PCA se considera parte del proceso de modelado.\n\n## Conceptos Básicos Del Flujo De Trabajo\n\nEl paquete <span class=\"pkg\">workflows</span> permite al usuario vincular objetos de modelado y preprocesamiento. Empecemos de nuevo con los datos de Ames y un modelo lineal simple:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-simple_dc9c662766a6046b9011c78a422aee61'}\n\n```{.r .cell-code}\nlibrary(tidymodels)  # Incluye el paquete de flujos de trabajo.\ntidymodels_prefer()\n\nlm_model <- \n  linear_reg() %>% \n  set_engine(\"lm\")\n```\n:::\n\n\nUn flujo de trabajo siempre requiere un objeto modelo <span class=\"pkg\">parsnip</span>:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-model-only_3377624690cf1684a0c38b6eded79866'}\n\n```{.r .cell-code}\nlm_wflow <- \n  workflow() %>% \n  add_model(lm_model)\n\nlm_wflow\n## ══ Workflow ═════════════════════════════════════════════════════════════════════════\n## Preprocessor: None\n## Model: linear_reg()\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n```\n:::\n\n\nTenga en cuenta que aún no hemos especificado cómo este flujo de trabajo debe preprocesar los datos: `Preprocessor: None`.\n\nSi nuestro modelo es muy simple, se puede utilizar una fórmula R estándar como preprocesador:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-form_d8230d131f1f26b8249b5a42d658f5b9'}\n\n```{.r .cell-code}\nlm_wflow <- \n  lm_wflow %>% \n  add_formula(Sale_Price ~ Longitude + Latitude)\n\nlm_wflow\n## ══ Workflow ═════════════════════════════════════════════════════════════════════════\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Sale_Price ~ Longitude + Latitude\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n```\n:::\n\n\nLos flujos de trabajo tienen un método `fit()` que se puede utilizar para crear el modelo. Usando los objetos creados en @sec-models-summary:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-form-fit_02e667c3dd977e006cad300867b3db8b'}\n\n```{.r .cell-code}\nlm_fit <- fit(lm_wflow, ames_train)\nlm_fit\n## ══ Workflow [trained] ═══════════════════════════════════════════════════════════════\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Sale_Price ~ Longitude + Latitude\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## \n## Call:\n## stats::lm(formula = ..y ~ ., data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##     -302.97        -2.07         2.71\n```\n:::\n\n\nTambién podemos `predict()` en el flujo de trabajo ajustado:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-form-pred_a8aba96da2edb42f9ca03386a4910116'}\n\n```{.r .cell-code}\npredict(lm_fit, ames_test %>% slice(1:3))\n## # A tibble: 3 × 1\n##   .pred\n##   <dbl>\n## 1  5.22\n## 2  5.21\n## 3  5.28\n```\n:::\n\n\nEl método `predict()` sigue las mismas reglas y convenciones de nomenclatura que describimos para el paquete <span class=\"pkg\">parsnip</span> en @sec-parsnip-predictions.\n\nTanto el modelo como el preprocesador se pueden eliminar o actualizar:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-form-update_54f76802bd71ec872e191eab3462451e'}\n\n```{.r .cell-code}\nlm_fit %>% update_formula(Sale_Price ~ Longitude)\n## ══ Workflow ═════════════════════════════════════════════════════════════════════════\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Sale_Price ~ Longitude\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n```\n:::\n\n\nTenga en cuenta que, en este nuevo objeto, el resultado muestra que el modelo ajustado anterior se eliminó ya que la nueva fórmula es inconsistente con el ajuste del modelo anterior.\n\n## Agregar Variables Sin Procesar Al `workflow()`\n\nHay otra interfaz para pasar datos al modelo, la función `add_variables()`, que usa una sintaxis similar a <span class=\"pkg\">dplyr</span> para elegir variables. La función tiene dos argumentos principales: `outcomes` y `predictors`. Estos utilizan un enfoque de selección similar al backend <span class=\"pkg\">tidyselect</span> de los paquetes <span class=\"pkg\">tidyverse</span> para capturar múltiples selectores usando `c()`.\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-add-variables_ab82d17da791423fb0d6a3b389c62dd2'}\n\n```{.r .cell-code}\nlm_wflow <- \n  lm_wflow %>% \n  remove_formula() %>% \n  add_variables(outcome = Sale_Price, predictors = c(Longitude, Latitude))\nlm_wflow\n## ══ Workflow ═════════════════════════════════════════════════════════════════════════\n## Preprocessor: Variables\n## Model: linear_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Outcomes: Sale_Price\n## Predictors: c(Longitude, Latitude)\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n```\n:::\n\n\nLos predictores también podrían haberse especificado utilizando un selector más general, como\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-selector_88c1d33a58d8f7873ca6ddb1c27718a6'}\n\n```{.r .cell-code}\npredictors = c(ends_with(\"tude\"))\n```\n:::\n\n\nUna ventaja es que cualquier columna de resultados especificada accidentalmente en el argumento de los predictores se eliminará silenciosamente. Esto facilita el uso de:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-selector-all_b17a1ef32b2018c39c806c1b2f2e49d3'}\n\n```{.r .cell-code}\npredictors = everything()\n```\n:::\n\n\nCuando el modelo se ajusta, la especificación reúne estos datos, sin modificar, en un marco de datos y los pasa a la función subyacente:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-add-variables-fit_716fc223b40cd484ca7234a61e8a8cf3'}\n\n```{.r .cell-code}\nfit(lm_wflow, ames_train)\n## ══ Workflow [trained] ═══════════════════════════════════════════════════════════════\n## Preprocessor: Variables\n## Model: linear_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Outcomes: Sale_Price\n## Predictors: c(Longitude, Latitude)\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## \n## Call:\n## stats::lm(formula = ..y ~ ., data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##     -302.97        -2.07         2.71\n```\n:::\n\n\nSi desea que el método de modelado subyacente haga lo que normalmente haría con los datos, `add_variables()` puede ser una interfaz útil. Como veremos en @sec-special-model-formulas, también facilita especificaciones de modelado más complejas. Sin embargo, como mencionamos en la siguiente sección, modelos como `glmnet` y `xgboost` esperan que el usuario cree variables indicadoras a partir de predictores de factores. En estos casos, una interfaz de receta o fórmula suele ser una mejor opción.\n\nEn el próximo capítulo, veremos un preprocesador más potente (llamado *recipe*) que también se puede agregar a un flujo de trabajo.\n\n## ¿Cómo Utiliza Un `workflow()` La Fórmula? {#sec-workflow-encoding}\n\nRecuerde de @sec-formula que el método de fórmula en R tiene múltiples propósitos (lo discutiremos más a fondo en el [Capítulo @sec-recipes]). Uno de ellos es codificar correctamente los datos originales en un formato listo para el análisis. Esto puede implicar la ejecución de transformaciones en línea (por ejemplo, `log(x)`), la creación de columnas de variables ficticias, la creación de interacciones u otras expansiones de columnas, etc. Sin embargo, muchos métodos estadísticos requieren diferentes tipos de codificaciones:\n\n-   La mayoría de los paquetes para modelos basados en árboles utilizan la interfaz de fórmulas pero *no* codifican los predictores categóricos como variables ficticias.\n\n-   Los paquetes pueden utilizar funciones en línea especiales que le indican a la función del modelo cómo tratar el predictor en el análisis. Por ejemplo, en los modelos de análisis de supervivencia, un término de fórmula como `strata(site)` indicaría que la columna `site` es una variable de estratificación. Esto significa que no debe tratarse como un predictor regular y no tiene una estimación de parámetro de ubicación correspondiente en el modelo.\n\n-   Algunos paquetes de R han ampliado la fórmula de manera que las funciones básicas de R no pueden analizar ni ejecutar. En modelos multinivel (por ejemplo, modelos mixtos o modelos bayesianos jerárquicos), un término de modelo como `(semana | sujeto)` indica que la columna `semana` es un efecto aleatorio que tiene diferentes estimaciones de parámetros de pendiente para cada valor de la columna `sujeto`.\n\nUn flujo de trabajo es una interfaz de propósito general. Cuando se utiliza `add_formula()`, ¿cómo debería el flujo de trabajo preprocesar los datos? Dado que el preprocesamiento depende del modelo, <span class=\"pkg\">workflows</span> intenta emular lo que haría el modelo subyacente siempre que sea posible. Si no es posible, el procesamiento de la fórmula no debe afectar las columnas utilizadas en la fórmula. Veamos esto con más detalle.\n\n### Modelos basados en árboles {.unnumbered}\n\nCuando ajustamos un árbol a los datos, el paquete <span class=\"pkg\">parsnip</span> comprende lo que haría la función de modelado. Por ejemplo, si un modelo de bosque aleatorio se ajusta usando los paquetes <span class=\"pkg\">ranger</span> o <span class=\"pkg\">randomForest</span>, el flujo de trabajo sabe que las columnas de predictores que son factores deben dejarse como están.\n\nComo contraejemplo, un árbol potenciado creado con el paquete <span class=\"pkg\">xgboost</span> requiere que el usuario cree variables ficticias a partir de predictores de factores (ya que `xgboost::xgb.train()` no lo hará). Este requisito está integrado en el objeto de especificación del modelo y un flujo de trabajo que utiliza <span class=\"pkg\">xgboost</span> creará las columnas indicadoras para este motor. También tenga en cuenta que un motor diferente para árboles potenciados, C5.0, no requiere variables ficticias, por lo que el flujo de trabajo no crea ninguna.\n\nEsta determinación se realiza para cada combinación de modelo y motor.\n\n### Fórmulas especiales y funciones en línea. {#sec-special-model-formulas}\n\nVarios modelos multinivel se han estandarizado según una especificación de fórmula diseñada en el paquete <span class=\"pkg\">lme4</span>. Por ejemplo, para ajustar un modelo de regresión que tenga efectos aleatorios para los sujetos, usaríamos la siguiente fórmula:\n\n``` r\nlibrary(lme4)\nlmer(distance ~ Sex + (age | Subject), data = Orthodont)\n```\n\nEl efecto de esto es que cada sujeto tendrá un parámetro estimado de intersección y pendiente para la \"edad\".\n\nEl problema es que los métodos estándar de R no pueden procesar adecuadamente esta fórmula:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/unnamed-chunk-3_a9fce1e64db72bb0d93f8f03009c66dd'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-rand-mm_dfd942271beef622af3d8b68634633ed'}\n\n```{.r .cell-code}\nmodel.matrix(distance ~ Sex + (age | Subject), data = Orthodont)\n## Warning in Ops.ordered(age, Subject): '|' is not meaningful for ordered factors\n##      (Intercept) SexFemale age | SubjectTRUE\n## attr(,\"assign\")\n## [1] 0 1 2\n## attr(,\"contrasts\")\n## attr(,\"contrasts\")$Sex\n## [1] \"contr.treatment\"\n## \n## attr(,\"contrasts\")$`age | Subject`\n## [1] \"contr.treatment\"\n```\n:::\n\n\nEl resultado es un marco de datos de cero filas.\n\n::: rmdwarning\nEl problema es que la fórmula especial debe ser procesada por el código del paquete subyacente, no por el enfoque estándar `model.matrix()`.\n:::\n\nIncluso si esta fórmula pudiera usarse con `model.matrix()`, esto aún presentaría un problema ya que la fórmula también especifica los atributos estadísticos del modelo.\n\nLa solución en <span class=\"pkg\">workflows</span> es una fórmula de modelo suplementaria opcional que se puede pasar a `add_model()`. La especificación `add_variables()` proporciona los nombres de las columnas básicas, y luego la fórmula real dada al modelo se establece dentro de `add_model()`:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-special-formula_9b900467dfb6a9cc75f12ba06b9cfb18'}\n\n```{.r .cell-code}\nlibrary(multilevelmod)\n\nmultilevel_spec <- linear_reg() %>% set_engine(\"lmer\")\n\nmultilevel_workflow <- \n  workflow() %>% \n  # Pase los datos tal cual:\n  add_variables(outcome = distance, predictors = c(Sex, age, Subject)) %>% \n  add_model(multilevel_spec, \n            # Esta fórmula se le da al modelo.\n            formula = distance ~ Sex + (age | Subject))\n\nmultilevel_fit <- fit(multilevel_workflow, data = Orthodont)\nmultilevel_fit\n## ══ Workflow [trained] ═══════════════════════════════════════════════════════════════\n## Preprocessor: Variables\n## Model: linear_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Outcomes: distance\n## Predictors: c(Sex, age, Subject)\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## Linear mixed model fit by REML ['lmerMod']\n## Formula: distance ~ Sex + (age | Subject)\n##    Data: data\n## REML criterion at convergence: 471.2\n## Random effects:\n##  Groups   Name        Std.Dev. Corr \n##  Subject  (Intercept) 7.391         \n##           age         0.694    -0.97\n##  Residual             1.310         \n## Number of obs: 108, groups:  Subject, 27\n## Fixed Effects:\n## (Intercept)    SexFemale  \n##       24.52        -2.15\n```\n:::\n\n\nIncluso podemos usar la función `strata()` mencionada anteriormente del paquete <span class=\"pkg\">survival</span> para el análisis de supervivencia:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-strata_358ddf078330698a0340e205db18e085'}\n\n```{.r .cell-code}\nlibrary(censored)\n\nparametric_spec <- survival_reg()\n\nparametric_workflow <- \n  workflow() %>% \n  add_variables(outcome = c(fustat, futime), predictors = c(age, rx)) %>% \n  add_model(parametric_spec, \n            formula = Surv(futime, fustat) ~ age + strata(rx))\n\nparametric_fit <- fit(parametric_workflow, data = ovarian)\nparametric_fit\n## ══ Workflow [trained] ═══════════════════════════════════════════════════════════════\n## Preprocessor: Variables\n## Model: survival_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Outcomes: c(fustat, futime)\n## Predictors: c(age, rx)\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## Call:\n## survival::survreg(formula = Surv(futime, fustat) ~ age + strata(rx), \n##     data = data, model = TRUE)\n## \n## Coefficients:\n## (Intercept)         age \n##     12.8734     -0.1034 \n## \n## Scale:\n##   rx=1   rx=2 \n## 0.7696 0.4704 \n## \n## Loglik(model)= -89.4   Loglik(intercept only)= -97.1\n## \tChisq= 15.36 on 1 degrees of freedom, p= 9e-05 \n## n= 26\n```\n:::\n\n\nObserve cómo en ambas convocatorias se utilizó la fórmula específica del modelo.\n\n## Crear Múltiples Flujos De Trabajo A La Vez {#sec-workflow-sets-intro}\n\nEn algunas situaciones, los datos requieren numerosos intentos para encontrar un modelo apropiado. Por ejemplo:\n\n-   Para los modelos predictivos, es aconsejable evaluar una variedad de tipos de modelos diferentes. Esto requiere que el usuario cree múltiples especificaciones de modelo.\n\n-   Las pruebas secuenciales de modelos suelen comenzar con un conjunto ampliado de predictores. Este \"modelo completo\" se compara con una secuencia del mismo modelo que elimina cada predictor por turno. Utilizando métodos básicos de prueba de hipótesis o validación empírica, se puede aislar y evaluar el efecto de cada predictor.\n\nEn estas situaciones, así como en otras, puede resultar tedioso u oneroso crear muchos flujos de trabajo a partir de diferentes conjuntos de preprocesadores y/o especificaciones de modelo. Para solucionar este problema, el paquete <span class=\"pkg\">workflowset</span> crea combinaciones de componentes de flujo de trabajo. Una lista de preprocesadores (por ejemplo, fórmulas, selectores <span class=\"pkg\">dplyr</span> u objetos de recetas de ingeniería de características que se analizan en el siguiente capítulo) se puede combinar con una lista de especificaciones de modelo, lo que da como resultado un conjunto de flujos de trabajo.\n\nComo ejemplo, digamos que queremos centrarnos en las diferentes formas en que se representa la ubicación de la casa en los datos de Ames. Podemos crear un conjunto de fórmulas que capturen estos predictores:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-location-location-location_4d8aaf71e97ce0f28e1970afd54e4350'}\n\n```{.r .cell-code}\nlocation <- list(\n  longitude = Sale_Price ~ Longitude,\n  latitude = Sale_Price ~ Latitude,\n  coords = Sale_Price ~ Longitude + Latitude,\n  neighborhood = Sale_Price ~ Neighborhood\n)\n```\n:::\n\n\nEstas representaciones se pueden cruzar con uno o más modelos usando la función `workflow_set()`. Simplemente usaremos la especificación del modelo lineal anterior para demostrar:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-set-location_95656d9ffc3f369a5d69cdfa6e4afa2f'}\n\n```{.r .cell-code}\nlibrary(workflowsets)\nlocation_models <- workflow_set(preproc = location, models = list(lm = lm_model))\nlocation_models\n## # A workflow set/tibble: 4 × 4\n##   wflow_id        info             option    result    \n##   <chr>           <list>           <list>    <list>    \n## 1 longitude_lm    <tibble [1 × 4]> <opts[0]> <list [0]>\n## 2 latitude_lm     <tibble [1 × 4]> <opts[0]> <list [0]>\n## 3 coords_lm       <tibble [1 × 4]> <opts[0]> <list [0]>\n## 4 neighborhood_lm <tibble [1 × 4]> <opts[0]> <list [0]>\nlocation_models$info[[1]]\n## # A tibble: 1 × 4\n##   workflow   preproc model      comment\n##   <list>     <chr>   <chr>      <chr>  \n## 1 <workflow> formula linear_reg \"\"\nextract_workflow(location_models, id = \"coords_lm\")\n## ══ Workflow ═════════════════════════════════════════════════════════════════════════\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Sale_Price ~ Longitude + Latitude\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n```\n:::\n\n\nLos conjuntos de flujos de trabajo están diseñados principalmente para funcionar con remuestreo, lo cual se analiza en el [Capítulo @sec-resampling]. Las columnas \"opción\" y \"resultado\" deben completarse con tipos específicos de objetos que resultan del remuestreo. Demostraremos esto con más detalle en los Capítulos [-@sec-compare] y [-@sec-workflow-sets].\n\nMientras tanto, creemos ajustes de modelo para cada fórmula y guárdelos en una nueva columna llamada `fit`. Usaremos las operaciones básicas <span class=\"pkg\">dplyr</span> y <span class=\"pkg\">purrr</span>:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-set-fit_473e443809fe319af3bb3b79c986828a'}\n\n```{.r .cell-code}\nlocation_models <-\n   location_models %>%\n   mutate(fit = map(info, ~ fit(.x$workflow[[1]], ames_train)))\nlocation_models\n## # A workflow set/tibble: 4 × 5\n##   wflow_id        info             option    result     fit       \n##   <chr>           <list>           <list>    <list>     <list>    \n## 1 longitude_lm    <tibble [1 × 4]> <opts[0]> <list [0]> <workflow>\n## 2 latitude_lm     <tibble [1 × 4]> <opts[0]> <list [0]> <workflow>\n## 3 coords_lm       <tibble [1 × 4]> <opts[0]> <list [0]> <workflow>\n## 4 neighborhood_lm <tibble [1 × 4]> <opts[0]> <list [0]> <workflow>\nlocation_models$fit[[1]]\n## ══ Workflow [trained] ═══════════════════════════════════════════════════════════════\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Sale_Price ~ Longitude\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## \n## Call:\n## stats::lm(formula = ..y ~ ., data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude  \n##     -184.40        -2.02\n```\n:::\n\n\nUsamos una función <span class=\"pkg\">purrr</span> aquí para mapear nuestros modelos, pero existe un enfoque mejor y más fácil para ajustar conjuntos de flujo de trabajo que se presentará en @sec-workflow-set.\n\n::: rmdnote\nEn general, ¡hay mucho más en los conjuntos de flujos de trabajo! Si bien hemos cubierto los conceptos básicos aquí, los matices y ventajas de los conjuntos de flujo de trabajo no se ilustrarán hasta el [Capítulo @sec-workflow-sets].\n:::\n\n## Evaluación Del Conjunto De Prueba\n\nDigamos que hemos concluido el desarrollo de nuestro modelo y nos hemos decidido por un modelo final. Hay una función de conveniencia llamada `last_fit()` que *ajustará* el modelo a todo el conjunto de entrenamiento y lo *evaluará* con el conjunto de prueba.\n\nUsando `lm_wflow` como ejemplo, podemos pasar el modelo y la división inicial de entrenamiento/prueba a la función:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/lm-last-fit_5359d8f954e7773413aa9f711565143f'}\n\n```{.r .cell-code}\nfinal_lm_res <- last_fit(lm_wflow, ames_split)\nfinal_lm_res\n## # Resampling results\n## # Manual resampling \n## # A tibble: 1 × 6\n##   splits             id               .metrics .notes   .predictions .workflow \n##   <list>             <chr>            <list>   <list>   <list>       <list>    \n## 1 <split [2342/588]> train/test split <tibble> <tibble> <tibble>     <workflow>\n```\n:::\n\n\n::: rmdnote\nObserve que `last_fit()` toma una división de datos como entrada, no un marco de datos. Esta función utiliza la división para generar los conjuntos de entrenamiento y prueba para el ajuste y la evaluación finales.\n:::\n\nLa columna `.workflow` contiene el flujo de trabajo ajustado y se puede extraer de los resultados usando:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/extract-last-fit_94f1cdaaef0a6bdaad364b3caf02d780'}\n\n```{.r .cell-code}\nfitted_lm_wflow <- extract_workflow(final_lm_res)\n```\n:::\n\n\nDe manera similar, `collect_metrics()` y `collect_predictions()` proporcionan acceso a las métricas de rendimiento y predicciones, respectivamente.\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/collect-last-fit_04eea1081d5d1b715795b7a2cc67035f'}\n\n```{.r .cell-code}\ncollect_metrics(final_lm_res)\ncollect_predictions(final_lm_res) %>% slice(1:5)\n```\n:::\n\n\nVeremos más sobre `last_fit()` en acción y cómo usarlo nuevamente en @sec-bean-models.\n\n::: rmdnote\nCuando se usan conjuntos de validación, `last_fit()` tiene un argumento llamado `add_validation_set` para especificar si debemos entrenar el modelo final únicamente en el conjunto de entrenamiento (el predeterminado) o la combinación de los conjuntos de entrenamiento y validación.\n:::\n\n## Resumen Del capítulo {#sec-workflows-summary}\n\nEn este capítulo, aprendió que el proceso de modelado abarca más que simplemente estimar los parámetros de un algoritmo que conecta los predictores con un resultado. Este proceso también incluye pasos de preprocesamiento y operaciones realizadas después de que se ajusta un modelo. Introdujimos un concepto llamado *flujo de trabajo modelo* que puede capturar los componentes importantes del proceso de modelado. También se pueden crear múltiples flujos de trabajo dentro de un *conjunto de flujos de trabajo*. La función `last_fit()` es conveniente para ajustar un modelo final al conjunto de entrenamiento y evaluar con el conjunto de prueba.\n\nPara los datos de Ames, el código relacionado que veremos usado nuevamente es:\n\n\n::: {.cell layout-align=\"center\" hash='07-the-model-workflow_cache/html/workflows-summary_913d9a1bacea3af7c005d6d1c31eb2ce'}\n\n```{.r .cell-code}\nlibrary(tidymodels)\ndata(ames)\n\names <- mutate(ames, Sale_Price = log10(Sale_Price))\n\nset.seed(502)\names_split <- initial_split(ames, prop = 0.80, strata = Sale_Price)\names_train <- training(ames_split)\names_test  <-  testing(ames_split)\n\nlm_model <- linear_reg() %>% set_engine(\"lm\")\n\nlm_wflow <- \n  workflow() %>% \n  add_model(lm_model) %>% \n  add_variables(outcome = Sale_Price, predictors = c(Longitude, Latitude))\n\nlm_fit <- fit(lm_wflow, ames_train)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}