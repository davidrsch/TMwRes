{
  "hash": "c54a653fb3b800edd34aaac1fa55ea8a",
  "result": {
    "markdown": "\n\n\n# A Model Workflow {#sec-workflows}\n\nIn the previous chapter, we discussed the <span class=\"pkg\">parsnip</span> package, which can be used to define and fit the model. This chapter introduces a new concept called a *model workflow*. The purpose of this concept (and the corresponding tidymodels `workflow()` object) is to encapsulate the major pieces of the modeling process (discussed in @sec-model-phases). The workflow is important in two ways. First, using a workflow concept encourages good methodology since it is a single point of entry to the estimation components of a data analysis. Second, it enables the user to better organize projects. These two points are discussed in the following sections.\n\n## Where Does the Model Begin and End? {#sec-begin-model-end}\n\nSo far, when we have used the term \"the model,\" we have meant a structural equation that relates some predictors to one or more outcomes. Let's consider again linear regression as an example. The outcome data are denoted as $y_i$, where there are $i = 1 \\ldots n$ samples in the training set. Suppose that there are $p$ predictors $x_{i1}, \\ldots, x_{ip}$ that are used in the model. Linear regression produces a model equation of\n\n$$ \\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1x_{i1} + \\ldots + \\hat{\\beta}_px_{ip} $$\n\nWhile this is a linear model, it is linear only in the parameters. The predictors could be nonlinear terms (such as the $\\log(x_i)$).\n\n::: rmdwarning\nThe conventional way of thinking about the modeling process is that it only includes the model fit.\n:::\n\nFor some straightforward data sets, fitting the model itself may be the entire process. However, a variety of choices and additional steps often occur before the model is fit:\n\n-   While our example model has $p$ predictors, it is common to start with more than $p$ candidate predictors. Through exploratory data analysis or using domain knowledge, some of the predictors may be excluded from the analysis. In other cases, a feature selection algorithm may be used to make a data-driven choice for the minimum predictor set for the model.\n-   There are times when the value of an important predictor is missing. Rather than eliminating this sample from the data set, the missing value could be imputed using other values in the data. For example, if $x_1$ were missing but was correlated with predictors $x_2$ and $x_3$, an imputation method could estimate the missing $x_1$ observation from the values of $x_2$ and $x_3$.\n-   It may be beneficial to transform the scale of a predictor. If there is not *a priori* information on what the new scale should be, we can estimate the proper scale using a statistical transformation technique, the existing data, and some optimization criterion. Other transformations, such as PCA, take groups of predictors and transform them into new features that are used as the predictors.\n\nWhile these examples are related to steps that occur before the model fit, there may also be operations that occur after the model is created. When a classification model is created where the outcome is binary (e.g., `event` and `non-event`), it is customary to use a 50% probability cutoff to create a discrete class prediction, also known as a hard prediction. For example, a classification model might estimate that the probability of an event was 62%. Using the typical default, the hard prediction would be `event`. However, the model may need to be more focused on reducing false positive results (i.e., where true nonevents are classified as events). One way to do this is to raise the cutoff from 50% to some greater value. This increases the level of evidence required to call a new sample an event. While this reduces the true positive rate (which is bad), it may have a more dramatic effect on reducing false positives. The choice of the cutoff value should be optimized using data. This is an example of a post-processing step that has a significant effect on how well the model works, even though it is not contained in the model fitting step.\n\nIt is important to focus on the broader *modeling process*, instead of only fitting the specific model used to estimate parameters. This broader process includes any preprocessing steps, the model fit itself, as well as potential post-processing activities. In this book, we will refer to this more comprehensive concept as the *model workflow* and highlight how to handle all its components to produce a final model equation.\n\n::: rmdnote\nIn other software, such as Python or Spark, similar collections of steps are called *pipelines*. In tidymodels, the term \"pipeline\" already connotes a sequence of operations chained together with a pipe operator (such as `%>%` from <span class=\"pkg\">magrittr</span> or the newer native `|>`). Rather than using ambiguous terminology in this context, we call the sequence of computational operations related to modeling *workflows*.\n:::\n\nBinding together the analytical components of data analysis is important for another reason. Future chapters will demonstrate how to accurately measure performance, as well as how to optimize structural parameters (i.e., model tuning). To correctly quantify model performance on the training set, [Chapter @sec-resampling] advocates using resampling methods. To do this properly, no data-driven parts of the analysis should be excluded from validation. To this end, the workflow must include all significant estimation steps.\n\nTo illustrate, consider principal component analysis (PCA) signal extraction. We'll talk about this more in @sec-example-steps as well as [Chapter @sec-dimensionality]; PCA is a way to replace correlated predictors with new artificial features that are uncorrelated and capture most of the information in the original set. The new features could be used as the predictors, and least squares regression could be used to estimate the model parameters.\n\nThere are two ways of thinking about the model workflow. @fig-bad-workflow illustrates the *incorrect* method: to think of the PCA preprocessing step, as *not being part of the modeling workflow*.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Incorrect mental model of where model estimation occurs in the data analysis process](premade/bad-workflow.svg){#fig-bad-workflow fig-align='center' fig-alt='An incorrect mental model of where model estimation occurs in the data analysis process. The data and predictor set are substrates for an initial preprocessing step using PCA. These data are passed to the model fitting algorithm to produce a fitted model. The figure indicates that the model workflow only includes the model fitting process. This implies that the model fit is the only place where estimation occurs.' width=80%}\n:::\n:::\n\n\nThe fallacy here is that, although PCA does significant computations to produce the components, its operations are assumed to have no uncertainty associated with them. The PCA components are treated as *known* and, if not included in the model workflow, the effect of PCA could not be adequately measured.\n\n@fig-good-workflow shows an *appropriate* approach.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![Correct mental model of where model estimation occurs in the data analysis process](premade/proper-workflow.svg){#fig-good-workflow fig-align='center' fig-alt='A correct mental model of where model estimation occurs in the data analysis process. The data and predictor set are substrates for an initial preprocessing step using PCA. These data are passed to the model fitting algorithm to produce a fitted model. The figure indicates that the model workflow includes the model fitting process and the PCA step. This implies that both operations should be considered estimation steps.' width=80%}\n:::\n:::\n\n\nIn this way, the PCA preprocessing is considered part of the modeling process.\n\n## Workflow Basics\n\nThe <span class=\"pkg\">workflows</span> package allows the user to bind modeling and preprocessing objects together. Let's start again with the Ames data and a simple linear model:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidymodels)  # Includes the workflows package\ntidymodels_prefer()\n\nlm_model <- \n  linear_reg() %>% \n  set_engine(\"lm\")\n```\n:::\n\n\nA workflow always requires a <span class=\"pkg\">parsnip</span> model object:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm_wflow <- \n  workflow() %>% \n  add_model(lm_model)\n\nlm_wflow\n## ══ Workflow ═════════════════════════════════════════════════════════════════════════\n## Preprocessor: None\n## Model: linear_reg()\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n```\n:::\n\n\nNotice that we have not yet specified how this workflow should preprocess the data: `Preprocessor: None`.\n\nIf our model is very simple, a standard R formula can be used as a preprocessor:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm_wflow <- \n  lm_wflow %>% \n  add_formula(Sale_Price ~ Longitude + Latitude)\n\nlm_wflow\n## ══ Workflow ═════════════════════════════════════════════════════════════════════════\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Sale_Price ~ Longitude + Latitude\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n```\n:::\n\n\nWorkflows have a `fit()` method that can be used to create the model. Using the objects created in @sec-models-summary:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm_fit <- fit(lm_wflow, ames_train)\nlm_fit\n## ══ Workflow [trained] ═══════════════════════════════════════════════════════════════\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Sale_Price ~ Longitude + Latitude\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## \n## Call:\n## stats::lm(formula = ..y ~ ., data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##     -302.97        -2.07         2.71\n```\n:::\n\n\nWe can also `predict()` on the fitted workflow:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredict(lm_fit, ames_test %>% slice(1:3))\n## # A tibble: 3 × 1\n##   .pred\n##   <dbl>\n## 1  5.22\n## 2  5.21\n## 3  5.28\n```\n:::\n\n\nThe `predict()` method follows all of the same rules and naming conventions that we described for the <span class=\"pkg\">parsnip</span> package in @sec-parsnip-predictions.\n\nBoth the model and preprocessor can be removed or updated:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm_fit %>% update_formula(Sale_Price ~ Longitude)\n## ══ Workflow ═════════════════════════════════════════════════════════════════════════\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Sale_Price ~ Longitude\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n```\n:::\n\n\nNote that, in this new object, the output shows that the previous fitted model was removed since the new formula is inconsistent with the previous model fit.\n\n## Adding Raw Variables to the `workflow()`\n\nThere is another interface for passing data to the model, the `add_variables()` function, which uses a <span class=\"pkg\">dplyr</span>-like syntax for choosing variables. The function has two primary arguments: `outcomes` and `predictors`. These use a selection approach similar to the <span class=\"pkg\">tidyselect</span> backend of <span class=\"pkg\">tidyverse</span> packages to capture multiple selectors using `c()`.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlm_wflow <- \n  lm_wflow %>% \n  remove_formula() %>% \n  add_variables(outcome = Sale_Price, predictors = c(Longitude, Latitude))\nlm_wflow\n## ══ Workflow ═════════════════════════════════════════════════════════════════════════\n## Preprocessor: Variables\n## Model: linear_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Outcomes: Sale_Price\n## Predictors: c(Longitude, Latitude)\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n```\n:::\n\n\nThe predictors could also have been specified using a more general selector, such as\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredictors = c(ends_with(\"tude\"))\n```\n:::\n\n\nOne nicety is that any outcome columns accidentally specified in the predictors argument will be quietly removed. This facilitates the use of:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npredictors = everything()\n```\n:::\n\n\nWhen the model is fit, the specification assembles these data, unaltered, into a data frame and passes it to the underlying function:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfit(lm_wflow, ames_train)\n## ══ Workflow [trained] ═══════════════════════════════════════════════════════════════\n## Preprocessor: Variables\n## Model: linear_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Outcomes: Sale_Price\n## Predictors: c(Longitude, Latitude)\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## \n## Call:\n## stats::lm(formula = ..y ~ ., data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude     Latitude  \n##     -302.97        -2.07         2.71\n```\n:::\n\n\nIf you would like the underlying modeling method to do what it would normally do with the data, `add_variables()` can be a helpful interface. As we will see in @sec-special-model-formulas, it also facilitates more complex modeling specifications. However, as we mention in the next section, models such as `glmnet` and `xgboost` expect the user to make indicator variables from factor predictors. In these cases, a recipe or formula interface will typically be a better choice.\n\nIn the next chapter, we will look at a more powerful preprocessor (called a *recipe*) that can also be added to a workflow.\n\n## How Does a `workflow()` Use the Formula? {sec-#workflow-encoding}\n\nRecall from @sec-formula that the formula method in R has multiple purposes (we will discuss this further in [Chapter @sec-recipes]). One of these is to properly encode the original data into an analysis-ready format. This can involve executing inline transformations (e.g., `log(x)`), creating dummy variable columns, creating interactions or other column expansions, and so on. However, many statistical methods require different types of encodings:\n\n-   Most packages for tree-based models use the formula interface but *do not* encode the categorical predictors as dummy variables.\n\n-   Packages can use special inline functions that tell the model function how to treat the predictor in the analysis. For example, in survival analysis models, a formula term such as `strata(site)` would indicate that the column `site` is a stratification variable. This means it should not be treated as a regular predictor and does not have a corresponding location parameter estimate in the model.\n\n-   A few R packages have extended the formula in ways that base R functions cannot parse or execute. In multilevel models (e.g., mixed models or hierarchical Bayesian models), a model term such as `(week | subject)` indicates that the column `week` is a random effect that has different slope parameter estimates for each value of the `subject` column.\n\nA workflow is a general purpose interface. When `add_formula()` is used, how should the workflow preprocess the data? Since the preprocessing is model dependent, <span class=\"pkg\">workflows</span> attempts to emulate what the underlying model would do whenever possible. If it is not possible, the formula processing should not do anything to the columns used in the formula. Let's look at this in more detail.\n\n### Tree-based models {.unnumbered}\n\nWhen we fit a tree to the data, the <span class=\"pkg\">parsnip</span> package understands what the modeling function would do. For example, if a random forest model is fit using the <span class=\"pkg\">ranger</span> or <span class=\"pkg\">randomForest</span> packages, the workflow knows predictors columns that are factors should be left as is.\n\nAs a counterexample, a boosted tree created with the <span class=\"pkg\">xgboost</span> package requires the user to create dummy variables from factor predictors (since `xgboost::xgb.train()` will not). This requirement is embedded into the model specification object and a workflow using <span class=\"pkg\">xgboost</span> will create the indicator columns for this engine. Also note that a different engine for boosted trees, C5.0, does not require dummy variables so none are made by the workflow.\n\nThis determination is made for each model and engine combination.\n\n### Special formulas and inline functions {#sec-special-model-formulas}\n\nA number of multilevel models have standardized on a formula specification devised in the <span class=\"pkg\">lme4</span> package. For example, to fit a regression model that has random effects for subjects, we would use the following formula:\n\n``` r\nlibrary(lme4)\nlmer(distance ~ Sex + (age | Subject), data = Orthodont)\n```\n\nThe effect of this is that each subject will have an estimated intercept and slope parameter for `age`.\n\nThe problem is that standard R methods can't properly process this formula:\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nmodel.matrix(distance ~ Sex + (age | Subject), data = Orthodont)\n## Warning in Ops.ordered(age, Subject): '|' is not meaningful for ordered factors\n##      (Intercept) SexFemale age | SubjectTRUE\n## attr(,\"assign\")\n## [1] 0 1 2\n## attr(,\"contrasts\")\n## attr(,\"contrasts\")$Sex\n## [1] \"contr.treatment\"\n## \n## attr(,\"contrasts\")$`age | Subject`\n## [1] \"contr.treatment\"\n```\n:::\n\n\nThe result is a zero row data frame.\n\n::: rmdwarning\nThe issue is that the special formula has to be processed by the underlying package code, not the standard `model.matrix()` approach.\n:::\n\nEven if this formula could be used with `model.matrix()`, this would still present a problem since the formula also specifies the statistical attributes of the model.\n\nThe solution in <span class=\"pkg\">workflows</span> is an optional supplementary model formula that can be passed to `add_model()`. The `add_variables()` specification provides the bare column names, and then the actual formula given to the model is set within `add_model()`:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(multilevelmod)\n\nmultilevel_spec <- linear_reg() %>% set_engine(\"lmer\")\n\nmultilevel_workflow <- \n  workflow() %>% \n  # Pass the data along as-is: \n  add_variables(outcome = distance, predictors = c(Sex, age, Subject)) %>% \n  add_model(multilevel_spec, \n            # This formula is given to the model\n            formula = distance ~ Sex + (age | Subject))\n\nmultilevel_fit <- fit(multilevel_workflow, data = Orthodont)\nmultilevel_fit\n## ══ Workflow [trained] ═══════════════════════════════════════════════════════════════\n## Preprocessor: Variables\n## Model: linear_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Outcomes: distance\n## Predictors: c(Sex, age, Subject)\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## Linear mixed model fit by REML ['lmerMod']\n## Formula: distance ~ Sex + (age | Subject)\n##    Data: data\n## REML criterion at convergence: 471.2\n## Random effects:\n##  Groups   Name        Std.Dev. Corr \n##  Subject  (Intercept) 7.391         \n##           age         0.694    -0.97\n##  Residual             1.310         \n## Number of obs: 108, groups:  Subject, 27\n## Fixed Effects:\n## (Intercept)    SexFemale  \n##       24.52        -2.15\n```\n:::\n\n\nWe can even use the previously mentioned `strata()` function from the <span class=\"pkg\">survival</span> package for survival analysis:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(censored)\n\nparametric_spec <- survival_reg()\n\nparametric_workflow <- \n  workflow() %>% \n  add_variables(outcome = c(fustat, futime), predictors = c(age, rx)) %>% \n  add_model(parametric_spec, \n            formula = Surv(futime, fustat) ~ age + strata(rx))\n\nparametric_fit <- fit(parametric_workflow, data = ovarian)\nparametric_fit\n## ══ Workflow [trained] ═══════════════════════════════════════════════════════════════\n## Preprocessor: Variables\n## Model: survival_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Outcomes: c(fustat, futime)\n## Predictors: c(age, rx)\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## Call:\n## survival::survreg(formula = Surv(futime, fustat) ~ age + strata(rx), \n##     data = data, model = TRUE)\n## \n## Coefficients:\n## (Intercept)         age \n##     12.8734     -0.1034 \n## \n## Scale:\n##   rx=1   rx=2 \n## 0.7696 0.4704 \n## \n## Loglik(model)= -89.4   Loglik(intercept only)= -97.1\n## \tChisq= 15.36 on 1 degrees of freedom, p= 9e-05 \n## n= 26\n```\n:::\n\n\nNotice how in both of these calls the model-specific formula was used.\n\n## Creating Multiple Workflows at Once {#sec-workflow-sets-intro}\n\nIn some situations, the data require numerous attempts to find an appropriate model. For example:\n\n-   For predictive models, it is advisable to evaluate a variety of different model types. This requires the user to create multiple model specifications.\n\n-   Sequential testing of models typically starts with an expanded set of predictors. This \"full model\" is compared to a sequence of the same model that removes each predictor in turn. Using basic hypothesis testing methods or empirical validation, the effect of each predictor can be isolated and assessed.\n\nIn these situations, as well as others, it can become tedious or onerous to create a lot of workflows from different sets of preprocessors and/or model specifications. To address this problem, the <span class=\"pkg\">workflowset</span> package creates combinations of workflow components. A list of preprocessors (e.g., formulas, <span class=\"pkg\">dplyr</span> selectors, or feature engineering recipe objects discussed in the next chapter) can be combined with a list of model specifications, resulting in a set of workflows.\n\nAs an example, let's say that we want to focus on the different ways that house location is represented in the Ames data. We can create a set of formulas that capture these predictors:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlocation <- list(\n  longitude = Sale_Price ~ Longitude,\n  latitude = Sale_Price ~ Latitude,\n  coords = Sale_Price ~ Longitude + Latitude,\n  neighborhood = Sale_Price ~ Neighborhood\n)\n```\n:::\n\n\nThese representations can be crossed with one or more models using the `workflow_set()` function. We'll just use the previous linear model specification to demonstrate:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(workflowsets)\nlocation_models <- workflow_set(preproc = location, models = list(lm = lm_model))\nlocation_models\n## # A workflow set/tibble: 4 × 4\n##   wflow_id        info             option    result    \n##   <chr>           <list>           <list>    <list>    \n## 1 longitude_lm    <tibble [1 × 4]> <opts[0]> <list [0]>\n## 2 latitude_lm     <tibble [1 × 4]> <opts[0]> <list [0]>\n## 3 coords_lm       <tibble [1 × 4]> <opts[0]> <list [0]>\n## 4 neighborhood_lm <tibble [1 × 4]> <opts[0]> <list [0]>\nlocation_models$info[[1]]\n## # A tibble: 1 × 4\n##   workflow   preproc model      comment\n##   <list>     <chr>   <chr>      <chr>  \n## 1 <workflow> formula linear_reg \"\"\nextract_workflow(location_models, id = \"coords_lm\")\n## ══ Workflow ═════════════════════════════════════════════════════════════════════════\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Sale_Price ~ Longitude + Latitude\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## Linear Regression Model Specification (regression)\n## \n## Computational engine: lm\n```\n:::\n\n\nWorkflow sets are mostly designed to work with resampling, which is discussed in [Chapter @sec-resampling]. The columns `option` and `result` must be populated with specific types of objects that result from resampling. We will demonstrate this in more detail in Chapters [-@sec-compare] and [-@sec-workflow-sets].\n\nIn the meantime, let's create model fits for each formula and save them in a new column called `fit`. We'll use basic <span class=\"pkg\">dplyr</span> and <span class=\"pkg\">purrr</span> operations:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlocation_models <-\n   location_models %>%\n   mutate(fit = map(info, ~ fit(.x$workflow[[1]], ames_train)))\nlocation_models\n## # A workflow set/tibble: 4 × 5\n##   wflow_id        info             option    result     fit       \n##   <chr>           <list>           <list>    <list>     <list>    \n## 1 longitude_lm    <tibble [1 × 4]> <opts[0]> <list [0]> <workflow>\n## 2 latitude_lm     <tibble [1 × 4]> <opts[0]> <list [0]> <workflow>\n## 3 coords_lm       <tibble [1 × 4]> <opts[0]> <list [0]> <workflow>\n## 4 neighborhood_lm <tibble [1 × 4]> <opts[0]> <list [0]> <workflow>\nlocation_models$fit[[1]]\n## ══ Workflow [trained] ═══════════════════════════════════════════════════════════════\n## Preprocessor: Formula\n## Model: linear_reg()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## Sale_Price ~ Longitude\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## \n## Call:\n## stats::lm(formula = ..y ~ ., data = data)\n## \n## Coefficients:\n## (Intercept)    Longitude  \n##     -184.40        -2.02\n```\n:::\n\n\nWe use a <span class=\"pkg\">purrr</span> function here to map through our models, but there is an easier, better approach to fit workflow sets that will be introduced in @sec-workflow-set.\n\n::: rmdnote\nIn general, there's a lot more to workflow sets! While we've covered the basics here, the nuances and advantages of workflow sets won't be illustrated until [Chapter @sec-workflow-sets].\n:::\n\n## Evaluating the Test Set\n\nLet's say that we've concluded our model development and have settled on a final model. There is a convenience function called `last_fit()` that will *fit* the model to the entire training set and *evaluate* it with the testing set.\n\nUsing `lm_wflow` as an example, we can pass the model and the initial training/testing split to the function:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfinal_lm_res <- last_fit(lm_wflow, ames_split)\nfinal_lm_res\n## # Resampling results\n## # Manual resampling \n## # A tibble: 1 × 6\n##   splits             id               .metrics .notes   .predictions .workflow \n##   <list>             <chr>            <list>   <list>   <list>       <list>    \n## 1 <split [2342/588]> train/test split <tibble> <tibble> <tibble>     <workflow>\n```\n:::\n\n\n::: rmdnote\nNotice that `last_fit()` takes a data split as an input, not a dataframe. This function uses the split to generate the training and test sets for the final fitting and evaluation.\n:::\n\nThe `.workflow` column contains the fitted workflow and can be pulled out of the results using:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nfitted_lm_wflow <- extract_workflow(final_lm_res)\n```\n:::\n\n\nSimilarly, `collect_metrics()` and `collect_predictions()` provide access to the performance metrics and predictions, respectively.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ncollect_metrics(final_lm_res)\ncollect_predictions(final_lm_res) %>% slice(1:5)\n```\n:::\n\n\nWe'll see more about `last_fit()` in action and how to use it again in @sec-bean-models.\n\n::: rmdnote\nWhen using validation sets, `last_fit()` has an argument called `add_validation_set` to specify if we should train the final model solely on the training set (the default) or the combination of the training and validation sets.\n:::\n\n## Chapter Summary {#sec-workflows-summary}\n\nIn this chapter, you learned that the modeling process encompasses more than just estimating the parameters of an algorithm that connects predictors to an outcome. This process also includes preprocessing steps and operations taken after a model is fit. We introduced a concept called a *model workflow* that can capture the important components of the modeling process. Multiple workflows can also be created inside of a *workflow set*. The `last_fit()` function is convenient for fitting a final model to the training set and evaluating with the test set.\n\nFor the Ames data, the related code that we'll see used again is:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(tidymodels)\ndata(ames)\n\names <- mutate(ames, Sale_Price = log10(Sale_Price))\n\nset.seed(502)\names_split <- initial_split(ames, prop = 0.80, strata = Sale_Price)\names_train <- training(ames_split)\names_test  <-  testing(ames_split)\n\nlm_model <- linear_reg() %>% set_engine(\"lm\")\n\nlm_wflow <- \n  workflow() %>% \n  add_model(lm_model) %>% \n  add_variables(outcome = Sale_Price, predictors = c(Longitude, Latitude))\n\nlm_fit <- fit(lm_wflow, ames_train)\n```\n:::\n",
    "supporting": [
      "07-the-model-workflow_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}