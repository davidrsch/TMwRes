{
  "hash": "d4fff77ee6b68f9938f53c62f2763a4a",
  "result": {
    "markdown": "\n\n\n# Conjuntos De Modelos {#sec-ensembles}\n\nUn conjunto de modelos, donde las predicciones de varios alumnos individuales se agregan para hacer una predicción, puede producir un modelo final de alto rendimiento. Los métodos más populares para crear modelos de conjunto son el embolsado [@breiman1996bagging], el bosque aleatorio [@ho1995random; @breiman2001random] e impulsando [@freund1997decision]. Cada uno de estos métodos combina las predicciones de múltiples versiones del mismo tipo de modelo (por ejemplo, árboles de clasificación). Sin embargo, uno de los primeros métodos para crear conjuntos es *apilamiento de modelos* [@wolpert1992stacked; @breiman1996stacked].\n\n::: rmdnote\nEl apilamiento de modelos combina las predicciones de múltiples modelos de cualquier tipo. Por ejemplo, en un conjunto de apilamiento se pueden incluir una regresión logística, un árbol de clasificación y una máquina de vectores de soporte.\n:::\n\nEste capítulo muestra cómo apilar modelos predictivos usando el paquete <span class=\"pkg\">stacks</span>. Reutilizaremos los resultados del [Capítulo @sec-workflow-sets] donde se evaluaron múltiples modelos para predecir la resistencia a la compresión de las mezclas de concreto.\n\nEl proceso de construcción de un conjunto apilado es:\n\n1.  Ensamble el conjunto de entrenamiento de predicciones de reserva (producidas mediante remuestreo).\n2.  Cree un modelo para combinar estas predicciones.\n3.  Para cada miembro del conjunto, ajuste el modelo en el conjunto de entrenamiento original.\n\nEn secciones siguientes, describiremos este proceso. Sin embargo, antes de continuar, aclararemos algunas nomenclaturas para las variaciones de lo que puede significar \"el modelo\". ¡Esto puede convertirse rápidamente en un término sobrecargado cuando trabajamos en un análisis de modelado complejo! Consideremos el modelo de perceptrón multicapa (MLP) (también conocido como red neuronal) creado en el [Capítulo @sec-workflow-sets].\n\nEn general, hablaremos de un modelo MLP como el *tipo* de modelo. Otros tipos de modelos son las máquinas de regresión lineal y de vectores de soporte.\n\nLos parámetros de ajuste son un aspecto importante de un modelo. En el [Capítulo @sec-workflow-sets], el modelo MLP se ajustó en más de 25 valores de parámetros de ajuste. En los capítulos anteriores, hemos llamado a estos valores de *parámetros de ajuste candidatos* o *configuraciones de modelo*. En la literatura sobre ensamblaje, estos también se denominan modelos base.\n\n::: rmdnote\nUsaremos el término *miembros candidatos* para describir las posibles configuraciones del modelo (de todos los tipos de modelos) que podrían incluirse en el conjunto de apilamiento.\n:::\n\nEsto significa que un modelo de apilamiento puede incluir diferentes tipos de modelos (por ejemplo, árboles y redes neuronales), así como diferentes configuraciones del mismo modelo (por ejemplo, árboles con diferentes profundidades).\n\n## Crear El Conjunto De Entrenamiento Para Apilar {#sec-data-stack}\n\nEl primer paso para construir un conjunto apilado se basa en las predicciones del conjunto de evaluación a partir de un esquema de remuestreo con múltiples divisiones. Para cada punto de datos en el conjunto de entrenamiento, el apilamiento requiere algún tipo de predicción fuera de la muestra. Para los modelos de regresión, este es el resultado previsto. Para los modelos de clasificación, las clases o probabilidades predichas están disponibles para su uso, aunque estas últimas contienen más información que las predicciones de clases estrictas. Para un conjunto de modelos, se ensambla un conjunto de datos donde las filas son las muestras del conjunto de entrenamiento y las columnas son las predicciones fuera de la muestra del conjunto de múltiples modelos.\n\nEn el [Capítulo @sec-workflow-sets], utilizamos cinco repeticiones de validación cruzada 10 veces para volver a muestrear los datos. Este esquema de remuestreo genera cinco predicciones de conjuntos de evaluación para cada muestra de conjunto de entrenamiento. Pueden ocurrir múltiples predicciones fuera de la muestra en varias otras técnicas de remuestreo (por ejemplo, arranque). A los efectos del apilamiento, cualquier predicción replicada para un punto de datos en el conjunto de entrenamiento se promedia de modo que haya una única predicción por muestra del conjunto de entrenamiento por miembro candidato.\n\n::: rmdnote\nTambién se pueden utilizar conjuntos de validación simples con el apilamiento, ya que tidymodels considera que se trata de un remuestreo único.\n:::\n\nPara el ejemplo concreto, el conjunto de entrenamiento utilizado para el apilamiento de modelos tiene columnas para todos los resultados de los parámetros de ajuste candidatos. @tbl-ensemble-candidate-preds presenta las primeras seis filas y columnas seleccionadas.\n\n\n::: {#tbl-ensemble-candidate-preds .cell layout-align=\"center\" tbl-cap='Predicciones a partir de configuraciones de parámetros de ajuste candidatos.' hash='20-ensemble-models_cache/html/tbl-ensemble-candidate-preds_bdc110aad9046bd121050485a166e15a'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"7\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Predicciones Candidatas Apiladas</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:center;text-align: center;\"> Muestra # </th>\n   <th style=\"text-align:center;text-align: center;\"> Bagged Tree </th>\n   <th style=\"text-align:center;text-align: center;\"> MARS 1 </th>\n   <th style=\"text-align:center;text-align: center;\"> MARS 2 </th>\n   <th style=\"text-align:center;text-align: center;\"> Cubist 1 </th>\n   <th style=\"text-align:center;text-align: center;\"> ... </th>\n   <th style=\"text-align:center;text-align: center;\"> Cubist 25 </th>\n   <th style=\"text-align:center;text-align: center;\"> ... </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 25.18 </td>\n   <td style=\"text-align:center;\"> 17.92 </td>\n   <td style=\"text-align:center;\"> 17.15 </td>\n   <td style=\"text-align:center;\"> 17.79 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> 17.82 </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 2 </td>\n   <td style=\"text-align:center;\"> 5.18 </td>\n   <td style=\"text-align:center;\"> -1.77 </td>\n   <td style=\"text-align:center;\"> -0.73 </td>\n   <td style=\"text-align:center;\"> 2.83 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> 3.87 </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 3 </td>\n   <td style=\"text-align:center;\"> 9.71 </td>\n   <td style=\"text-align:center;\"> 7.26 </td>\n   <td style=\"text-align:center;\"> 5.91 </td>\n   <td style=\"text-align:center;\"> 6.31 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> 8.60 </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 4 </td>\n   <td style=\"text-align:center;\"> 25.21 </td>\n   <td style=\"text-align:center;\"> 20.93 </td>\n   <td style=\"text-align:center;\"> 21.52 </td>\n   <td style=\"text-align:center;\"> 23.72 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> 21.61 </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 5 </td>\n   <td style=\"text-align:center;\"> 6.33 </td>\n   <td style=\"text-align:center;\"> 1.53 </td>\n   <td style=\"text-align:center;\"> 0.15 </td>\n   <td style=\"text-align:center;\"> 3.60 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> 4.57 </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 6 </td>\n   <td style=\"text-align:center;\"> 7.88 </td>\n   <td style=\"text-align:center;\"> 4.88 </td>\n   <td style=\"text-align:center;\"> 1.74 </td>\n   <td style=\"text-align:center;\"> 7.69 </td>\n   <td style=\"text-align:center;\">  </td>\n   <td style=\"text-align:center;\"> 7.55 </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nHay una sola columna para el modelo de árbol en bolsas ya que no tiene parámetros de ajuste. Además, recuerde que MARS se sintonizó en función de un único parámetro (el grado del producto) con dos configuraciones posibles, por lo que este modelo está representado por dos columnas. La mayoría de los otros modelos tienen 25 columnas correspondientes, como se muestra para Cubist en este ejemplo.\n\n::: rmdwarning\nPara los modelos de clasificación, las columnas de predicción candidatas serían probabilidades de clase predichas. Dado que estas columnas suman una para cada modelo, las probabilidades de una de las clases pueden omitirse.\n:::\n\nPara resumir dónde nos encontramos hasta ahora, el primer paso para el apilamiento es ensamblar las predicciones del conjunto de evaluación para el conjunto de entrenamiento de cada modelo candidato. Podemos utilizar estas predicciones de conjuntos de evaluación para avanzar y construir un conjunto apilado.\n\nPara comenzar a ensamblar con el paquete <span class=\"pkg\">stacks</span>, cree una pila de datos vacía usando la función `stacks()` y luego agregue modelos candidatos. Recuerde que utilizamos conjuntos de flujos de trabajo para ajustar una amplia variedad de modelos a estos datos. Usaremos los resultados de las carreras:\n\n\n::: {.cell layout-align=\"center\" hash='20-ensemble-models_cache/html/ensembles-race_b69b3c5476a1ceb17a67e7f46d359df6'}\n\n```{.r .cell-code}\nrace_results\n## # A workflow set/tibble: 12 × 4\n##   wflow_id    info             option    result   \n##   <chr>       <list>           <list>    <list>   \n## 1 MARS        <tibble [1 × 4]> <opts[3]> <race[+]>\n## 2 CART        <tibble [1 × 4]> <opts[3]> <race[+]>\n## 3 CART_bagged <tibble [1 × 4]> <opts[3]> <rsmp[+]>\n## 4 RF          <tibble [1 × 4]> <opts[3]> <race[+]>\n## 5 boosting    <tibble [1 × 4]> <opts[3]> <race[+]>\n## 6 Cubist      <tibble [1 × 4]> <opts[3]> <race[+]>\n## # ℹ 6 more rows\n```\n:::\n\n\nEn este caso, nuestra sintaxis es:\n\n\n::: {.cell layout-align=\"center\" hash='20-ensemble-models_cache/html/ensembles-data-stack_954077dca446878af024ec52e09fda68'}\n\n```{.r .cell-code}\nlibrary(tidymodels)\nlibrary(stacks)\ntidymodels_prefer()\n\nconcrete_stack <- \n  stacks() %>% \n  add_candidates(race_results)\n\nconcrete_stack\n## # A data stack with 12 model definitions and 18 candidate members:\n## #   MARS: 1 model configuration\n## #   CART: 1 model configuration\n## #   CART_bagged: 1 model configuration\n## #   RF: 1 model configuration\n## #   boosting: 1 model configuration\n## #   Cubist: 1 model configuration\n## #   SVM_radial: 1 model configuration\n## #   SVM_poly: 1 model configuration\n## #   KNN: 3 model configurations\n## #   neural_network: 1 model configuration\n## #   full_quad_linear_reg: 5 model configurations\n## #   full_quad_KNN: 1 model configuration\n## # Outcome: compressive_strength (numeric)\n```\n:::\n\n\nRecuerde que los métodos de carrera (@sec-racing) son más eficientes ya que es posible que no evalúen todas las configuraciones en todos los remuestreos. El apilamiento requiere que todos los miembros candidatos tengan el conjunto completo de remuestras. `add_candidates()` incluye solo las configuraciones del modelo que tienen resultados completos.\n\n::: rmdnote\n¿Por qué utilizar los resultados de las carreras en lugar del conjunto completo de modelos candidatos contenidos en `grid_results`? Se puede utilizar cualquiera de los dos. Encontramos un mejor rendimiento para estos datos utilizando los resultados de las carreras. Esto podría deberse a que el método de carrera preselecciona los mejores modelos de la parrilla más grande.\n:::\n\nSi no hubiéramos usado el paquete <span class=\"pkg\">workflowsets</span>, los objetos de <span class=\"pkg\">tune</span> y <span class=\"pkg\">finetune</span> también podrían pasarse a `add_candidates()`. Esto puede incluir objetos de búsqueda iterativos y de cuadrícula.\n\n## Combina Las Predicciones {#sec-blend-predictions}\n\nLas predicciones del conjunto de entrenamiento y los datos de resultados observados correspondientes se utilizan para crear un *modelo de metaaprendizaje* donde las predicciones del conjunto de evaluación son los predictores de los datos de resultados observados. El metaaprendizaje se puede lograr utilizando cualquier modelo. El modelo más utilizado es un modelo lineal generalizado regularizado, que abarca modelos lineales, logísticos y multinomiales. Específicamente, la regularización mediante la penalización de lazo [@lasso], que utiliza la contracción para atraer puntos hacia un valor central, tiene varias ventajas:\n\n-   El uso de la penalización de lazo puede eliminar candidatos (y, a veces, tipos de modelos completos) del conjunto.\n-   La correlación entre los candidatos a conjuntos tiende a ser muy alta y la regularización ayuda a aliviar este problema.\n\n@breiman1996stacked también sugirió que, cuando se utiliza un modelo lineal para combinar las predicciones, podría ser útil restringir los coeficientes de combinación para que no sean negativos. En general, hemos encontrado que este es un buen consejo y es el valor predeterminado para el paquete <span class=\"pkg\">stacks</span> (pero se puede cambiar mediante un argumento opcional).\n\nDado que nuestro resultado es numérico, se utiliza la regresión lineal para el metamodelo. Ajustar el metamodelo es tan sencillo como usar:\n\n\n::: {.cell layout-align=\"center\" hash='20-ensemble-models_cache/html/ensembles-initial-blend_7e4d13223ca59ac9aaca0c8b70961179'}\n\n```{.r .cell-code}\nset.seed(2001)\nens <- blend_predictions(concrete_stack)\n```\n:::\n\n\nEsto evalúa el modelo de metaaprendizaje sobre una cuadrícula predefinida de valores de penalización de lazo y utiliza un método de remuestreo interno para determinar el mejor valor. El método `autoplot()`, que se muestra en @fig-stacking-autoplot, nos ayuda a comprender si el método de penalización predeterminado fue suficiente:\n\n\n::: {.cell layout-align=\"center\" hash='20-ensemble-models_cache/html/ensembles-initial-blend-plot_c61ba53afcecd4bfab9dabb8e719c8aa'}\n\n```{.r .cell-code}\nautoplot(ens)\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='20-ensemble-models_cache/html/fig-stacking-autoplot_436fd9a8be38f8ca0feac88a159fe2df'}\n::: {.cell-output-display}\n![Resultados del uso del método `autoplot()` en el objeto de pilas combinadas](20-ensemble-models_files/figure-html/fig-stacking-autoplot-1.png){#fig-stacking-autoplot fig-align='center' fig-alt='Resultados del uso del método `autoplot()` en el objeto de pilas combinadas.' width=672}\n:::\n:::\n\n\nEl panel superior de @fig-stacking-autoplot muestra el número promedio de miembros candidatos del conjunto retenidos por el modelo de metaaprendizaje. Podemos ver que el número de miembros es bastante constante y, a medida que aumenta, el RMSE también aumenta.\n\nEs posible que el rango predeterminado no nos haya servido bien aquí. Para evaluar el modelo de metaaprendizaje con penalizaciones mayores, pasemos una opción adicional:\n\n\n::: {.cell layout-align=\"center\" hash='20-ensemble-models_cache/html/ensembles-second-blend_43416a686b925c7a6cdb1a1c587e5c85'}\n\n```{.r .cell-code}\nset.seed(2002)\nens <- blend_predictions(concrete_stack, penalty = 10^seq(-2, -0.5, length = 20))\n```\n:::\n\n\nAhora, en @fig-stacking-autoplot-redo, vemos un rango en el que el modelo de conjunto se vuelve peor que con nuestra primera combinación (pero no mucho). Los valores de $R^2$ aumentan con más miembros y sanciones mayores.\n\n\n::: {.cell layout-align=\"center\" hash='20-ensemble-models_cache/html/ensembles-autoplot-calc_ee9a2e8c837e8ae68ed79b26bc84fbd9'}\n\n```{.r .cell-code}\nautoplot(ens)\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='20-ensemble-models_cache/html/fig-stacking-autoplot-redo_429884ee300fa2a4653813143e4a9604'}\n::: {.cell-output-display}\n![Los resultados del uso del método `autoplot()` en el objeto de pilas combinadas actualizado](20-ensemble-models_files/figure-html/fig-stacking-autoplot-redo-1.png){#fig-stacking-autoplot-redo fig-align='center' fig-alt='Los resultados del uso del método `autoplot()` en el objeto de pilas combinadas actualizado.' width=672}\n:::\n:::\n\n\nAl combinar predicciones utilizando un modelo de regresión, es común restringir los parámetros de combinación para que no sean negativos. Para estos datos, esta restricción tiene el efecto de eliminar muchos de los miembros potenciales del conjunto; Incluso con sanciones bastante bajas, el conjunto se limita a una fracción de los dieciocho originales.\n\nEl valor de penalización asociado con el RMSE más pequeño fue 0.01. Imprimir el objeto muestra los detalles del modelo de metaaprendizaje:\n\n\n::: {.cell layout-align=\"center\" hash='20-ensemble-models_cache/html/ensembles-second-blend-print_25fa89ad9d8ff9c218f9a038e15a3ac3'}\n\n```{.r .cell-code}\nens\n## ── A stacked ensemble model ─────────────────────────────────────\n## \n## \n## Out of 18 possible candidate members, the ensemble retained 5.\n## \n## Penalty: 0.01.\n## \n## Mixture: 1.\n## \n## \n## The 5 highest weighted members are:\n## # A tibble: 5 × 3\n##   member                    type           weight\n##   <chr>                     <chr>           <dbl>\n## 1 boosting_1_16             boost_tree    0.712  \n## 2 neural_network_1_17       mlp           0.208  \n## 3 Cubist_1_25               cubist_rules  0.0759 \n## 4 full_quad_linear_reg_1_16 linear_reg    0.0161 \n## 5 CART_1_05                 decision_tree 0.00476\n## \n## Members have not yet been fitted with `fit_members()`.\n```\n:::\n\n\n\n\nEl modelo de metaaprendizaje de regresión lineal regularizado contenía coeficientes de combinación five entre tipos de modelos five. El método `autoplot()` se puede utilizar nuevamente para mostrar las contribuciones de cada tipo de modelo, para producir @fig-blending-weights.\n\n\n::: {.cell layout-align=\"center\" hash='20-ensemble-models_cache/html/ensembles-blending-weights_e28c16cf638ce2f666e2f932e29c9772'}\n\n```{.r .cell-code}\nautoplot(ens, \"weights\") +\n  geom_text(aes(x = weight + 0.01, label = model), hjust = 0) + \n  theme(legend.position = \"none\") +\n  lims(x = c(-0.01, 0.8))\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='20-ensemble-models_cache/html/fig-blending-weights_0b70ebc3dba42b46319b0ffdbbd7078f'}\n::: {.cell-output-display}\n![Coeficientes de mezcla para el conjunto de apilamiento.](20-ensemble-models_files/figure-html/fig-blending-weights-1.png){#fig-blending-weights fig-align='center' fig-alt='blending_alt' width=672}\n:::\n:::\n\n\nLos modelos boosted tree and neural network tienen las mayores contribuciones al conjunto. Para este conjunto, el resultado se predice con la ecuación:\n\n\n::: {.cell layout-align=\"center\" hash='20-ensemble-models_cache/html/ensembles-equation_30060f5a9dc4938afe50c2c42a688fc0'}\n\n\\begin{align}\n \\text{ensemble prediction} &=-0.62 \\\\\n\t+&0.71 \\times \\text{boost tree prediction} \\notag \\\\\n\t+&0.21 \\times \\text{mlp prediction} \\notag \\\\\n\t+&0.076 \\times \\text{cubist rules prediction} \\notag \\\\\n\t+&0.016 \\times \\text{linear reg prediction} \\notag \\\\\n\t+&0.0048 \\times \\text{decision tree prediction} \\notag\n\\end{align}\n:::\n\n\ndonde los predictores en la ecuación son los valores de resistencia a la compresión pronosticados a partir de esos modelos.\n\n## Ajustar Los Modelos Miembros {#sec-fit-members}\n\nEl conjunto contiene miembros candidatos five y ahora sabemos cómo se pueden combinar sus predicciones en una predicción final para el conjunto. Sin embargo, estos ajustes de modelos individuales aún no se han creado. Para poder utilizar el modelo de apilamiento, se requieren ajustes de modelo adicionales five. Estos utilizan todo el conjunto de entrenamiento con los predictores originales.\n\nLos modelos five a ajustar son:\n\n\n::: {.cell layout-align=\"center\" hash='20-ensemble-models_cache/html/ensembles-show-members_e58167a95049fa46aef82a237853de5d'}\n- boosting: number of trees = 1800, minimal node size = 25, tree depth = 4, learning rate = 0.109, minimum loss reduction = 9.84e-10, and proportion of observations sampled = 0.85\n\n- Cubist: number of committees = 98 and number of nearest neighbors = 2\n\n- CART: cost-complexity parameter = 5e-08 and minimal node size = 3\n\n- linear regression (quadratic features): amount of regularization = 6.28e-09 and proportion of lasso penalty = 0.636\n\n- neural network: number of hidden units = 26, amount of regularization = 0.0149, and number of epochs = 203\n:::\n\n\nEl paquete <span class=\"pkg\">stacks</span> tiene una función, `fit_members()`, que entrena y devuelve estos modelos:\n\n\n::: {.cell layout-align=\"center\" hash='20-ensemble-models_cache/html/ensembles-fit-members_2714c93d9fab59933c8d181256c0446e'}\n\n```{.r .cell-code}\nens <- fit_members(ens)\n```\n:::\n\n\nEsto actualiza el objeto de apilamiento con los objetos de flujo de trabajo ajustados para cada miembro. En este punto, el modelo de apilamiento se puede utilizar para la predicción.\n\n## Resultados Del Conjunto De Pruebas\n\nDado que el proceso de combinación utilizó remuestreo, podemos estimar que el conjunto con miembros five tenía un RMSE estimado de 4.09. Recuerde del [Capítulo @sec-workflow-sets] que el árbol mejor impulsado tenía un conjunto de prueba RMSE de 3.46. ¿Cómo se comparará el modelo de conjunto en el conjunto de prueba? Podemos usar `predecit()` para averiguarlo:\n\n\n::: {.cell layout-align=\"center\" hash='20-ensemble-models_cache/html/ensembles-test-set_7669246b644b1f3439327f86657dab75'}\n\n```{.r .cell-code}\nreg_metrics <- metric_set(rmse, rsq)\nens_test_pred <- \n  predict(ens, concrete_test) %>% \n  bind_cols(concrete_test)\n\nens_test_pred %>% \n  reg_metrics(compressive_strength, .pred)\n## # A tibble: 2 × 3\n##   .metric .estimator .estimate\n##   <chr>   <chr>          <dbl>\n## 1 rmse    standard       3.37 \n## 2 rsq     standard       0.956\n```\n:::\n\n\nEsto es moderadamente mejor que nuestro mejor modelo individual. Es bastante común que el apilamiento produzca beneficios incrementales en comparación con el mejor modelo individual.\n\n## Resumen Del Capítulo {#sec-ensembles-summary}\n\nEste capítulo demostró cómo combinar diferentes modelos en un conjunto para obtener un mejor rendimiento predictivo. El proceso de creación del conjunto puede eliminar automáticamente los modelos candidatos para encontrar un pequeño subconjunto que mejore el rendimiento. El paquete <span class=\"pkg\">stacks</span> tiene una interfaz fluida para combinar resultados de remuestreo y ajuste en un metamodelo.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}