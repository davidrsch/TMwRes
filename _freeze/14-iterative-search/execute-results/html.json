{
  "hash": "85133087723ab835f99735c240e5dec2",
  "result": {
    "markdown": "\n\n\n# Búsqueda Iterativa {#sec-iterative-search}\n\nEl [Capítulo @sec-grid-search] demostró cómo la búsqueda en cuadrícula toma un conjunto predefinido de valores candidatos, los evalúa y luego elige la mejor configuración. Los métodos de búsqueda iterativos siguen una estrategia diferente. Durante el proceso de búsqueda, predicen qué valores probar a continuación.\n\n::: rmdnote\nCuando la búsqueda en cuadrícula no es factible o ineficiente, los métodos iterativos son un enfoque sensato para optimizar los parámetros de ajuste.\n:::\n\nEste capítulo describe dos métodos de búsqueda. Primero, analizamos la *optimización bayesiana*, que utiliza un modelo estadístico para predecir mejores configuraciones de parámetros. Después de eso, el capítulo describe un método de búsqueda global llamado *recocido simulado*.\n\nUsamos los mismos datos sobre las características de las células que en el capítulo anterior a modo de ilustración, pero cambiamos el modelo. Este capítulo utiliza un modelo de máquina de vectores de soporte porque proporciona bonitas visualizaciones bidimensionales de los procesos de búsqueda.\n\n## Un Modelo De Máquina De Vectores De Soporte {#sec-svm}\n\nUna vez más utilizamos los datos de segmentación de celdas, descritos en @sec-evaluating-grid, para modelar, con un modelo de máquina de vectores de soporte (SVM) para demostrar métodos de ajuste secuencial. Consulte @apm para obtener más información sobre este modelo. Los dos parámetros de ajuste a optimizar son el valor del costo de SVM y el parámetro del núcleo de la función de base radial $\\sigma$. Ambos parámetros pueden tener un efecto profundo en la complejidad y el rendimiento del modelo.\n\nEl modelo SVM utiliza un producto escalar y, por este motivo, es necesario centrar y escalar los predictores. Al igual que el modelo de perceptrón multicapa, este modelo se beneficiaría del uso de la extracción de características PCA. Sin embargo, no utilizaremos este tercer parámetro de ajuste en este capítulo para que podamos visualizar el proceso de búsqueda en dos dimensiones.\n\nJunto con los objetos utilizados anteriormente (que se muestran en @sec-grid-summary), los objetos tidymodels `svm_rec`, `svm_spec` y `svm_wflow` definen el proceso del modelo:\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/iterative-svm-defs_194c09ab5e342e41def84d09c6b9b464'}\n\n```{.r .cell-code}\nlibrary(tidymodels)\ntidymodels_prefer()\n\nsvm_rec <- \n  recipe(class ~ ., data = cells) %>%\n  step_YeoJohnson(all_numeric_predictors()) %>%\n  step_normalize(all_numeric_predictors())\n\nsvm_spec <- \n  svm_rbf(cost = tune(), rbf_sigma = tune()) %>% \n  set_engine(\"kernlab\") %>% \n  set_mode(\"classification\")\n\nsvm_wflow <- \n  workflow() %>% \n  add_model(svm_spec) %>% \n  add_recipe(svm_rec)\n```\n:::\n\n\nLos rangos de parámetros predeterminados para los dos parámetros de ajuste `cost` y `rbf_sigma` son:\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/iterative-svm-param_6254da240304e3e25a0332877fc7e7a7'}\n\n```{.r .cell-code}\ncost()\n## Cost (quantitative)\n## Transformer: log-2 [1e-100, Inf]\n## Range (transformed scale): [-10, 5]\nrbf_sigma()\n## Radial Basis Function sigma (quantitative)\n## Transformer: log-10 [1e-100, Inf]\n## Range (transformed scale): [-10, 0]\n```\n:::\n\n\nA modo de ilustración, cambiemos ligeramente el rango de parámetros del kernel para mejorar las visualizaciones de la búsqueda:\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/iterative-svm-param-set_e1ce746fb693f88aefd1c3b38a719600'}\n\n```{.r .cell-code}\nsvm_param <- \n  svm_wflow %>% \n  extract_parameter_set_dials() %>% \n  Matrix::update(rbf_sigma = rbf_sigma(c(-7, -1)))\n```\n:::\n\n\nAntes de analizar detalles específicos sobre la búsqueda iterativa y cómo funciona, exploremos la relación entre los dos parámetros de ajuste de SVM y el área bajo la curva ROC para este conjunto de datos específico. Construimos una cuadrícula regular muy grande, compuesta por 2500 valores candidatos, y evaluamos la cuadrícula mediante remuestreo. Obviamente, esto es poco práctico en el análisis de datos regular y tremendamente ineficiente. Sin embargo, aclara el camino que debe tomar el proceso de búsqueda y dónde ocurren los valores numéricamente óptimos.\n\n@fig-roc-surface muestra los resultados de la evaluación de esta cuadrícula, donde el color más claro corresponde a un mayor (mejor) rendimiento del modelo. Hay una gran franja en la diagonal inferior del espacio de parámetros que es relativamente plana con un rendimiento deficiente. En la parte superior derecha del espacio se produce una cresta de mejor rendimiento. El punto negro indica la mejor configuración. La transición desde la meseta de los malos resultados a la cima del mejor desempeño es muy pronunciada. También hay una fuerte caída en el área bajo la curva ROC justo a la derecha de la cresta.\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/fig-roc-surface_027d1ac938e76d80e748991c26be5050'}\n::: {.cell-output-display}\n![Mapa de calor del área media bajo la curva ROC para una cuadrícula de alta densidad de valores de parámetros de ajuste. El mejor punto es un punto sólido en la esquina superior derecha.](premade/roc_surface.png){#fig-roc-surface fig-align='center' fig-alt='Un mapa de calor del área media bajo la curva ROC para una cuadrícula de alta densidad de valores de parámetros de ajuste. El mejor punto es un punto sólido en la esquina superior derecha. La superficie tiene una cresta de alto rendimiento que se desplaza hacia la parte inferior derecha. ' width=80%}\n:::\n:::\n\n\nLos siguientes procedimientos de búsqueda requieren al menos algunas estadísticas de rendimiento remuestreadas antes de continuar. Para ello, el siguiente código crea una pequeña cuadrícula regular que reside en la parte plana del espacio de parámetros. La función `tune_grid()` vuelve a muestrear esta cuadrícula:\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/iterative-svm-initial_a15233508557e4223de11ffcc86465a7'}\n\n```{.r .cell-code}\nset.seed(1401)\nstart_grid <- \n  svm_param %>% \n  Matrix::update(\n    cost = cost(c(-6, 1)),\n    rbf_sigma = rbf_sigma(c(-6, -4))\n  ) %>% \n  grid_regular(levels = 2)\n\nset.seed(1402)\nsvm_initial <- \n  svm_wflow %>% \n  tune_grid(resamples = cell_folds, grid = start_grid, metrics = roc_res)\n\ncollect_metrics(svm_initial)\n## # A tibble: 4 × 8\n##     cost rbf_sigma .metric .estimator  mean     n std_err .config             \n##    <dbl>     <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n## 1 0.0156  0.000001 roc_auc binary     0.864    10 0.00864 Preprocessor1_Model1\n## 2 2       0.000001 roc_auc binary     0.863    10 0.00867 Preprocessor1_Model2\n## 3 0.0156  0.0001   roc_auc binary     0.863    10 0.00862 Preprocessor1_Model3\n## 4 2       0.0001   roc_auc binary     0.866    10 0.00855 Preprocessor1_Model4\n```\n:::\n\n\nEsta cuadrícula inicial muestra resultados bastante equivalentes, sin que ningún punto individual sea mucho mejor que los demás. Estos resultados pueden ser absorbidos por las funciones de ajuste iterativas analizadas en las siguientes secciones para usarse como valores iniciales.\n\n## Optimización Bayesiana\n\nLas técnicas de optimización bayesiana analizan los resultados del remuestreo actual y crean un modelo predictivo para sugerir valores de parámetros de ajuste que aún no se han evaluado. A continuación se vuelve a muestrear la combinación de parámetros sugerida. Estos resultados luego se utilizan en otro modelo predictivo que recomienda más valores candidatos para realizar pruebas, y así sucesivamente. El proceso continúa durante un número determinado de iteraciones o hasta que no se produzcan más mejoras. @Shahriari y @frazier2018tutorial son buenas introducciones a la optimización bayesiana.\n\nCuando se utiliza la optimización bayesiana, las principales preocupaciones son cómo crear el modelo y cómo seleccionar los parámetros recomendados por ese modelo. Primero, consideremos la técnica más comúnmente utilizada para la optimización bayesiana, el modelo de proceso gaussiano.\n\n### Un modelo de proceso gaussiano\n\nLos modelos de proceso gaussiano (GP) [@SCHULZ20181] son técnicas estadísticas bien conocidas que tienen una historia en la estadística espacial (bajo el nombre de *métodos de kriging*). Se pueden derivar de múltiples formas, incluso como modelo bayesiano; consulte @RaWi06 para obtener una excelente referencia.\n\nMatemáticamente, un GP es una colección de variables aleatorias cuya distribución de probabilidad conjunta es gaussiana multivariada. En el contexto de nuestra aplicación, esta es la colección de métricas de rendimiento para los valores candidatos de los parámetros de ajuste. Para la cuadrícula inicial anterior de cuatro muestras, la realización de estas cuatro variables aleatorias fue 0.8639, 0.8625, 0.8627, and 0.8659. Se supone que están distribuidos como gaussianos multivariados. Las entradas que definen las variables/predictores independientes para el modelo GP son los valores de los parámetros de ajuste correspondientes (que se muestran en @tbl-initial-gp-data).\n\n\n::: {#tbl-initial-gp-data .cell layout-align=\"center\" tbl-cap='Estadísticas de remuestreo utilizadas como sustrato inicial del modelo de proceso gaussiano.' hash='14-iterative-search_cache/html/tbl-initial-gp-data_66a247c7438706e5f7dda68c22e743b1'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n<tr>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"1\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">outcome</div></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"2\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">predictors</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:left;\"> ROC </th>\n   <th style=\"text-align:left;\"> cost </th>\n   <th style=\"text-align:left;\"> rbf_sigma </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 0.8639 </td>\n   <td style=\"text-align:left;\"> 0.01562 </td>\n   <td style=\"text-align:left;\"> 0.000001 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 0.8625 </td>\n   <td style=\"text-align:left;\"> 2.00000 </td>\n   <td style=\"text-align:left;\"> 0.000001 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 0.8627 </td>\n   <td style=\"text-align:left;\"> 0.01562 </td>\n   <td style=\"text-align:left;\"> 0.000100 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 0.8659 </td>\n   <td style=\"text-align:left;\"> 2.00000 </td>\n   <td style=\"text-align:left;\"> 0.000100 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nLos modelos de procesos gaussianos se especifican por sus funciones de media y covarianza, aunque esta última tiene el mayor efecto sobre la naturaleza del modelo GP. La función de covarianza a menudo se parametriza en términos de los valores de entrada (denotados como $x$). Como ejemplo, una función de covarianza comúnmente utilizada es la función exponencial al cuadrado[^14-iterative-search-1]:\n\n[^14-iterative-search-1]: Esta ecuación también es la misma que la *función de base radial* utilizada en los métodos del núcleo, como el modelo SVM que se utiliza actualmente. Esto es una coincidencia; esta función de covarianza no está relacionada con el parámetro de ajuste SVM que estamos usando.\n\n$$\\operatorname{cov}(\\boldsymbol{x}_i, \\boldsymbol{x}_j) = \\exp\\left(-\\frac{1}{2}|\\boldsymbol{x}_i - \\boldsymbol{x}_j|^2\\right) + \\sigma^2_{ij}$$\n\ndonde $\\sigma^2_{ij}$ es un término de varianza de error constante que es cero cuando $i=j$. Esta ecuación se traduce en:\n\n> A medida que aumenta la distancia entre dos combinaciones de parámetros de ajuste, la covarianza entre las métricas de rendimiento aumenta exponencialmente.\n\nLa naturaleza de la ecuación también implica que la variación de la métrica del resultado se minimiza en los puntos que ya se han observado (es decir, cuando $|\\boldsymbol{x}_i - \\boldsymbol{x}_j|^2$ es cero) .\n\nLa naturaleza de esta función de covarianza permite que el proceso gaussiano represente relaciones altamente no lineales entre el rendimiento del modelo y los parámetros de ajuste incluso cuando sólo existe una pequeña cantidad de datos.\n\n::: rmdwarning\nSin embargo, ajustar estos modelos puede resultar difícil en algunos casos y el modelo se vuelve más costoso computacionalmente a medida que aumenta el número de combinaciones de parámetros de ajuste.\n:::\n\nUna virtud importante de este modelo es que, dado que se especifica un modelo de probabilidad total, las predicciones de nuevos insumos pueden reflejar la distribución completa del resultado. En otras palabras, se pueden predecir nuevas estadísticas de desempeño tanto en términos de media como de varianza.\n\nSupongamos que se estuvieran considerando dos nuevos parámetros de ajuste. En @tbl-tuning-candidates, el candidato *A* tiene un valor ROC medio ligeramente mejor que el candidato *B* (el mejor actual es 0.8659). Sin embargo, su varianza es cuatro veces mayor que *B*. ¿Esto es bueno o malo? Elegir la opción *A* es más riesgoso pero tiene un rendimiento potencialmente mayor. El aumento en la varianza también refleja que este nuevo valor está más alejado de los datos existentes que *B*. La siguiente sección considera con más detalle estos aspectos de las predicciones de GP para la optimización bayesiana.\n\n\n::: {#tbl-tuning-candidates .cell layout-align=\"center\" result='asis' tbl-cap='Dos ejemplos de parámetros de ajuste considerados para un muestreo posterior.' hash='14-iterative-search_cache/html/tbl-tuning-candidates_667b4ab7e33c517e91f6f39ead8b0ec6'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"2\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Predicción GP de ROC AUC</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:left;\"> candidate </th>\n   <th style=\"text-align:left;\"> mean </th>\n   <th style=\"text-align:left;\"> variance </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> A </td>\n   <td style=\"text-align:left;\"> 0.90 </td>\n   <td style=\"text-align:left;\"> 0.000400 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> B </td>\n   <td style=\"text-align:left;\"> 0.89 </td>\n   <td style=\"text-align:left;\"> 0.000025 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n::: rmdnote\nLa optimización bayesiana es un proceso iterativo.\n:::\n\nCon base en la cuadrícula inicial de cuatro resultados, se ajusta el modelo GP, se predicen los candidatos y se selecciona una quinta combinación de parámetros de ajuste. Calculamos estimaciones de rendimiento para la nueva configuración, el GP se reajusta con los cinco resultados existentes (y así sucesivamente).\n\n### Funciones de adquisición\n\nUna vez que el proceso gaussiano se ajusta a los datos actuales, ¿cómo se utiliza? Nuestro objetivo es elegir la siguiente combinación de parámetros de ajuste que tenga más probabilidades de tener \"mejores resultados\" que los mejores actuales. Un enfoque para hacer esto es crear un gran conjunto de candidatos (quizás usando un diseño que llene el espacio) y luego hacer predicciones de media y varianza para cada uno. Utilizando esta información, elegimos el valor del parámetro de ajuste más ventajoso.\n\nUna clase de funciones objetivo, llamadas *funciones de adquisición*, facilitan el equilibrio entre media y varianza. Recuerde que la varianza prevista de los modelos GP depende principalmente de qué tan lejos están de los datos existentes. El equilibrio entre la media y la varianza previstas para nuevos candidatos se ve frecuentemente a través del lente de la exploración y la explotación:\n\n-   La *Exploración* sesga la selección hacia regiones donde hay menos (si es que hay alguno) modelos candidatos observados. Esto tiende a dar más peso a los candidatos con mayor variación y se centra en encontrar nuevos resultados.\n\n-   La *explotación* se basa principalmente en la predicción media para encontrar el mejor valor (medio). Se centra en los resultados existentes.\n\n\n\n\n\nPara demostrarlo, veamos un ejemplo de juguete con un único parámetro que tiene valores entre \\[0, 1\\] y la métrica de rendimiento es $R^2$. La función verdadera se muestra en @fig-performance-profile, junto con los valores candidatos five que tienen resultados existentes como puntos.\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/fig-performance-profile_30bae347289ecca3d73cf5e1cb2a74fe'}\n::: {.cell-output-display}\n![Perfil de rendimiento real hipotético sobre un parámetro de ajuste arbitrario, con cinco puntos estimados](figures/fig-performance-profile-1.png){#fig-performance-profile fig-align='center' fig-alt='Un perfil de rendimiento real hipotético sobre un parámetro de ajuste arbitrario. También se muestran cinco puntos estimados. El perfil es altamente no lineal con un pico entre dos de los puntos observados.' width=672}\n:::\n:::\n\n\nPara estos datos, el ajuste del modelo GP se muestra en @fig-estimated-profile. La región sombreada indica el error estándar medio $\\pm$ 1. Las dos líneas verticales indican dos puntos candidatos que se examinan con más detalle más adelante.\n\nLa región de confianza sombreada demuestra la función de varianza exponencial al cuadrado; se vuelve muy grande entre puntos y converge a cero en los puntos de datos existentes.\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/fig-estimated-profile_e5f36d403482763c41b8b21064309917'}\n::: {.cell-output-display}\n![Perfil de rendimiento estimado generado por el modelo de proceso gaussiano. La región sombreada muestra límites de error estándar.](figures/fig-estimated-profile-1.png){#fig-estimated-profile fig-align='center' fig-alt='El perfil de rendimiento estimado generado por el modelo de proceso gaussiano. La región sombreada muestra límites de error estándar. Dos líneas verticales muestran puntos potenciales que se muestrearán en la siguiente iteración.' width=672}\n:::\n:::\n\n\nEsta tendencia no lineal pasa por cada punto observado, pero el modelo no es perfecto. No se observan puntos cercanos al verdadero ajuste óptimo y, en esta región, el ajuste podría ser mucho mejor. A pesar de esto, el modelo GP puede orientarnos efectivamente en la dirección correcta.\n\nDesde un punto de vista puramente de explotación, la mejor opción sería seleccionar el valor del parámetro que tenga la mejor predicción media. Aquí, esto sería un valor de 0.106, justo a la derecha del punto mejor observado existente en 0,09.\n\nComo forma de fomentar la exploración, un enfoque simple (pero no utilizado con frecuencia) es encontrar el parámetro de ajuste asociado con el intervalo de confianza más grande. Por ejemplo, al usar una única desviación estándar para el límite de confianza $R^2$, el siguiente punto a muestrear sería 0.236. Esto es un poco más en la región sin resultados observados. Aumentar el número de desviaciones estándar utilizadas en el límite superior empujaría la selección hacia regiones vacías.\n\nUna de las funciones de adquisición más utilizadas es *mejora esperada*. La noción de mejora requiere un valor para los mejores resultados actuales (a diferencia del enfoque de confianza). Dado que el médico de cabecera puede describir un nuevo punto candidato utilizando una distribución, podemos ponderar las partes de la distribución que muestran una mejora utilizando la probabilidad de que se produzca la mejora.\n\nPor ejemplo, considere dos valores de parámetros candidatos de 0,10 y 0,25 (indicados por las líneas verticales en @fig-estimated-profile). Utilizando el modelo GP ajustado, sus distribuciones $R^2$ previstas se muestran en @fig-two-candidates junto con una línea de referencia para los mejores resultados actuales.\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/fig-two-candidates_c07d4c3ecad86e7f41e9a5480325261b'}\n::: {.cell-output-display}\n![Distribuciones de rendimiento previstas para dos valores de parámetros de ajuste muestreados](figures/fig-two-candidates-1.png){#fig-two-candidates fig-align='center' fig-alt='Distribuciones de rendimiento previstas para dos valores de parámetros de ajuste muestreados. Por un lado, la distribución es ligeramente mejor que el valor actual con un pequeño diferencial. El otro valor del parámetro es ligeramente peor pero tiene una distribución muy amplia.' width=80%}\n:::\n:::\n\n\nCuando solo se considera la predicción media de $R^2$, un valor de parámetro de 0,10 es la mejor opción (consulte @tbl-two-exp-improve). Se prevé, en promedio, que la recomendación del parámetro de ajuste de 0,25 será peor que el mejor nivel actual. Sin embargo, dado que tiene una mayor varianza, tiene más área de probabilidad general por encima del mejor nivel actual. Como resultado, tiene una mejora esperada mayor:\n\n\n::: {#tbl-two-exp-improve .cell layout-align=\"center\" tbl-cap='Mejora esperada para los dos parámetros de ajuste candidatos.' hash='14-iterative-search_cache/html/tbl-two-exp-improve_19c9f96b4dce2cb9e67eb0955089ae73'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"width: auto !important; margin-left: auto; margin-right: auto;\">\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"3\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Predicciones</div></th>\n</tr>\n  <tr>\n   <th style=\"text-align:left;\"> Parameter Value </th>\n   <th style=\"text-align:left;\"> Mean </th>\n   <th style=\"text-align:left;\"> Std Dev </th>\n   <th style=\"text-align:left;\"> Expected Improvment </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> 0.10 </td>\n   <td style=\"text-align:left;\"> 0.8679 </td>\n   <td style=\"text-align:left;\"> 0.0004317 </td>\n   <td style=\"text-align:left;\"> 0.000190 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> 0.25 </td>\n   <td style=\"text-align:left;\"> 0.8671 </td>\n   <td style=\"text-align:left;\"> 0.0039301 </td>\n   <td style=\"text-align:left;\"> 0.001216 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nCuando la mejora esperada se calcula en todo el rango del parámetro de ajuste, el punto de muestreo recomendado está mucho más cerca de 0,25 que de 0,10, como se muestra en @fig-expected-improvement.\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/fig-expected-improvement_57ca1a53b10b39cc1beb8df107f9de7d'}\n::: {.cell-output-display}\n![El perfil de rendimiento estimado generado por el modelo de proceso gaussiano (panel superior) y la mejora esperada (panel inferior). La línea vertical indica el punto de máxima mejora.](figures/fig-expected-improvement-1.png){#fig-expected-improvement fig-align='center' fig-alt='El perfil de rendimiento estimado generado por el modelo de proceso gaussiano (panel superior) y la mejora esperada (panel inferior). La línea vertical indica el punto de máxima mejora donde el rendimiento estimado es alto y la variación prevista también es grande.' width=672}\n:::\n:::\n\n\nSe han propuesto y discutido numerosas funciones de adquisición; en tidymodels, la mejora esperada es la predeterminada.\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/iterative-cells-bo-calcs_975f61ec0f09a45d515ff0c3e6865ad9'}\n\n:::\n\n\n### La función `tune_bayes()` {#sec-tune-bayes}\n\nPara implementar la búsqueda iterativa mediante optimización bayesiana, utilice la función `tune_bayes()`. Su sintaxis es muy similar a `tune_grid()` pero con varios argumentos adicionales:\n\n-   `iter` es el número máximo de iteraciones de búsqueda.\n\n-   `initial` Puede ser un número entero, un objeto producido usando `tune_grid()` o una de las funciones de carrera. El uso de un número entero especifica el tamaño de un diseño de relleno de espacio que se muestrea antes del primer modelo GP.\n\n-   `objective` es un argumento para qué función de adquisición se debe utilizar. El paquete <span class=\"pkg\">tune</span> contiene funciones para pasar aquí, como `exp_improve()` o `conf_bound()`.\n\n-   El argumento `param_info`, en este caso, especifica el rango de los parámetros así como cualquier transformación que se utilice. Se utilizan para definir el espacio de búsqueda. En situaciones en las que los objetos de parámetros predeterminados son insuficientes, se utiliza `param_info` para anular los valores predeterminados.\n\nEl argumento `control` ahora usa los resultados de `control_bayes()`. Algunos argumentos útiles son:\n\n-   `no_improve` es un número entero que detendrá la búsqueda si no se descubren parámetros mejorados dentro de las iteraciones `no_improve`.\n\n-   `uncertain` también es un número entero (o `Inf`) que tomará una *muestra de incertidumbre* si no hay mejora dentro de las iteraciones `inciertas`. Esto seleccionará al siguiente candidato que tenga una gran variación. Tiene el efecto de exploración pura ya que no considera la predicción media.\n\n-   `verbose` es un método lógico que imprimirá información de registro a medida que avanza la búsqueda.\n\nUsemos los primeros resultados de SVM de @sec-svm como sustrato inicial para el modelo de proceso gaussiano. Recuerde que, para esta aplicación, queremos maximizar el área bajo la curva ROC. Nuestro código es:\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/iterative-cells-bo_1566af054d0ac7cee78cb0a5ccbbb2db'}\n\n```{.r .cell-code}\nctrl <- control_bayes(verbose = TRUE)\n\nset.seed(1403)\nsvm_bo <-\n  svm_wflow %>%\n  tune_bayes(\n    resamples = cell_folds,\n    metrics = roc_res,\n    initial = svm_initial,\n    param_info = svm_param,\n    iter = 25,\n    control = ctrl\n  )\n```\n:::\n\n\n\n\nEl proceso de búsqueda comienza con un mejor valor inicial de 0.8659 para el área bajo la curva ROC. Un modelo de proceso gaussiano utiliza estas estadísticas four para crear un modelo. El gran conjunto de candidatos se genera y califica automáticamente utilizando la función de adquisición de mejora esperada. La primera iteración no logró mejorar el resultado con un valor ROC de 0.86315. Después de ajustar otro modelo de proceso gaussiano con el nuevo valor de resultado, la segunda iteración tampoco logró producir una mejora.\n\nEl registro de las dos primeras iteraciones, generado por la opción \"detallado\", fue:\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/iterative-cells-bo-print-first_116fc1621a60eac798886276e1bb6ec5'}\n\n:::\n\n\nLa búsqueda continúa. Hubo un total de 9 mejoras en el resultado a lo largo del camino en las iteraciones 3, 4, 5, 6, 8, 13, 22, 23, and 24. El mejor resultado se produjo en la iteración 24 con un área bajo la curva ROC de 0.8986.\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/iterative-cells-bo-print-impr_bcea90ccc9d96d81085847d98fdbc2ca'}\n\n:::\n\n\nEl último paso fue:\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/iterative-cells-bo-print-last_a6684c7e018fa0b67073c1252895c18e'}\n\n:::\n\n\nLas funciones que se utilizan para interrogar los resultados son las mismas que se utilizan para la búsqueda en cuadrícula (por ejemplo, `collect_metrics()`, etc.). Por ejemplo:\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/iterative-bo-best_bdc9a8d02374ed858a2a8948ca42260f'}\n\n```{.r .cell-code}\nshow_best(svm_bo)\n## # A tibble: 5 × 9\n##    cost rbf_sigma .metric .estimator  mean     n std_err .config .iter\n##   <dbl>     <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>   <int>\n## 1  31.8   0.00160 roc_auc binary     0.899    10 0.00785 Iter24     24\n## 2  30.8   0.00191 roc_auc binary     0.899    10 0.00791 Iter23     23\n## 3  31.4   0.00166 roc_auc binary     0.899    10 0.00784 Iter22     22\n## 4  31.8   0.00153 roc_auc binary     0.899    10 0.00783 Iter13     13\n## 5  30.8   0.00163 roc_auc binary     0.899    10 0.00782 Iter15     15\n```\n:::\n\n\nLa función `autoplot()` tiene varias opciones para métodos de búsqueda iterativos. @fig-progress-plot muestra cómo cambió el resultado durante la búsqueda usando `autoplot(svm_bo, type = \"performance\")`.\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/fig-progress-plot_e54bb51e82e4aae83b436d3e3ef15994'}\n::: {.cell-output-display}\n![El progreso de la optimización bayesiana producido cuando se utiliza el método `autoplot()` con `type = \"performance\"`](figures/fig-progress-plot-1.png){#fig-progress-plot fig-align='center' fig-alt='El progreso de la optimización bayesiana se produce cuando se utiliza el método `autoplot()` con `type = \\'performance\\'`. El gráfico muestra el rendimiento estimado en el eje y frente al número de iteraciones en el eje x. Se muestran intervalos de confianza para los puntos.' width=672}\n:::\n:::\n\n\nUn tipo adicional de gráfico utiliza `type = \"parameters\"` que muestra los valores de los parámetros en iteraciones.\n\nLa siguiente animación visualiza los resultados de la búsqueda. Los valores negros $\\times$ muestran los valores iniciales contenidos en `svm_initial`. El panel azul superior izquierdo muestra el valor medio previsto del área bajo la curva ROC. El panel rojo en la parte superior derecha muestra la variación prevista en los valores de ROC, mientras que el gráfico inferior visualiza la mejora esperada. En cada panel, los colores más oscuros indican valores menos atractivos (por ejemplo, valores medios pequeños, variación grande y mejoras pequeñas).\n\n\n\n\n\n<video width=\"720\" height=\"720\" controls>\n\n<source src=\"bo_search.mp4\" type=\"video/mp4\">\n\n</video>\n\nLa superficie de la superficie media prevista es muy inexacta en las primeras iteraciones de la búsqueda. A pesar de esto, ayuda a guiar el proceso hacia la región de buen desempeño. En otras palabras, el modelo del proceso gaussiano es incorrecto pero resulta muy útil. Dentro de las primeras diez iteraciones, la búsqueda realiza un muestreo cerca de la ubicación óptima.\n\nSi bien la mejor combinación de parámetros de ajuste se encuentra en el límite del espacio de parámetros, la optimización bayesiana a menudo elegirá nuevos puntos en otros lados del límite. Si bien podemos ajustar la proporción de exploración y explotación, la búsqueda tiende a muestrear puntos fronterizos desde el principio.\n\n::: rmdnote\nSi la búsqueda se basa en una cuadrícula inicial, un diseño que llene el espacio probablemente sería una mejor opción que un diseño normal. Muestra valores más únicos del espacio de parámetros y mejoraría las predicciones de la desviación estándar en las primeras iteraciones.\n:::\n\nFinalmente, si el usuario interrumpe los cálculos de `tune_bayes()`, la función devuelve los resultados actuales (en lugar de generar un error).\n\n## Recocido Simulado\n\n*Recocido simulado* (SA) [@kirkpatrick1983optimization; @van1987simulated] es una rutina de búsqueda no lineal general inspirada en el proceso en el que se enfría el metal. Es un método de búsqueda global que puede navegar eficazmente por muchos tipos diferentes de entornos de búsqueda, incluidas funciones discontinuas. A diferencia de la mayoría de las rutinas de optimización basadas en gradientes, el recocido simulado puede reevaluar soluciones anteriores.\n\n### Proceso de búsqueda de recocido simulado\n\nEl proceso de uso del recocido simulado comienza con un valor inicial y se embarca en un recorrido aleatorio controlado a través del espacio de parámetros. Cada nuevo valor de parámetro candidato es una pequeña perturbación del valor anterior que mantiene el nuevo punto dentro de una vecindad local.\n\nEl punto candidato se vuelve a muestrear para obtener su valor de rendimiento correspondiente. Si con este se logran mejores resultados que los parámetros anteriores, se acepta como el nuevo mejor y el proceso continúa. Si los resultados son peores que el valor anterior, el procedimiento de búsqueda aún puede usar este parámetro para definir pasos adicionales. Esto depende de dos factores. Primero, la probabilidad de aceptar un mal resultado disminuye a medida que el desempeño empeora. En otras palabras, un resultado ligeramente peor tiene más posibilidades de aceptación que uno con una gran caída en el rendimiento. El otro factor es el número de iteraciones de búsqueda. El recocido simulado quiere aceptar menos valores subóptimos a medida que avanza la búsqueda. A partir de estos dos factores, la *probabilidad de aceptación* de un mal resultado puede formalizarse como:\n\n$$\\operatorname{Pr}[\\text{accept suboptimal parameters at iteration } i] = \\exp(c\\times D_i \\times i)$$\n\ndonde $i$ es el número de iteración, $c$ es una constante especificada por el usuario y $D_i$ es la diferencia porcentual entre los valores antiguos y nuevos (donde los valores negativos implican peores resultados). Para un mal resultado, determinamos la probabilidad de aceptación y la comparamos con un número uniforme aleatorio. Si el número aleatorio es mayor que el valor de probabilidad, la búsqueda descarta los parámetros actuales y la siguiente iteración crea su valor candidato en la vecindad del valor anterior. De lo contrario, la siguiente iteración forma el siguiente conjunto de parámetros en función de los valores actuales (subóptimos).\n\n::: rmdnote\nLas probabilidades de aceptación del recocido simulado permiten que la búsqueda avance en la dirección equivocada, al menos a corto plazo, con el potencial de encontrar una región mucho mejor del espacio de parámetros a largo plazo.\n:::\n\n¿Cómo se ven influenciadas las probabilidades de aceptación? El mapa de calor en @fig-acceptance-prob muestra cómo la probabilidad de aceptación puede cambiar a lo largo de las iteraciones, el rendimiento y el coeficiente especificado por el usuario.\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/fig-acceptance-prob_ede50ca9a0bdb1b773227521b3c9c89b'}\n::: {.cell-output-display}\n![Mapa de calor de las probabilidades de aceptación del recocido simuladas para diferentes valores de coeficientes](figures/fig-acceptance-prob-1.png){#fig-acceptance-prob fig-align='center' fig-alt='Un mapa de calor de las probabilidades de aceptación de recocido simuladas para diferentes valores de coeficientes. Las probabilidades se ven afectadas tanto por el número de iteraciones como por la distancia entre el rendimiento y el mejor nivel actual.' width=80%}\n:::\n:::\n\n\nEl usuario puede ajustar los coeficientes para encontrar un perfil de probabilidad que se adapte a sus necesidades. En `finetune::control_sim_anneal()`, el valor predeterminado para este argumento `cooling_coef` es 0.02. Disminuir este coeficiente fomentará que la búsqueda sea más indulgente con los malos resultados.\n\nEste proceso continúa durante una cantidad determinada de iteraciones, pero puede detenerse si no se obtienen los mejores resultados globales dentro de un número predeterminado de iteraciones. Sin embargo, puede resultar muy útil establecer un *umbral de reinicio*. Si hay una serie de fallas, esta función revisa la última configuración de parámetros globalmente mejor y comienza de nuevo.\n\nEl principal detalle importante es definir cómo perturbar los parámetros de ajuste de una iteración a otra. Hay una variedad de métodos en la literatura para esto. Seguimos el método dado en @gsa llamado *recocido simulado generalizado*. Para parámetros de ajuste continuo, definimos un radio pequeño para especificar el \"vecindario\" local. Por ejemplo, supongamos que hay dos parámetros de ajuste y cada uno está limitado por cero y uno. El proceso de recocido simulado genera valores aleatorios en el radio circundante y elige aleatoriamente uno como valor candidato actual.\n\nEn nuestra implementación, la vecindad se determina escalando el candidato actual para que esté entre cero y uno según el rango del objeto de parámetro, por lo que los valores de radio entre 0,05 y 0,15 parecen razonables. Para estos valores, lo más rápido que puede ir la búsqueda de un lado al otro del espacio de parámetros es de aproximadamente 10 iteraciones. El tamaño del radio controla la rapidez con la que la búsqueda explora el espacio de parámetros. En nuestra implementación, se especifica un rango de radios para que diferentes magnitudes de \"local\" definan los nuevos valores candidatos.\n\nPara ilustrar, usaremos los dos parámetros de ajuste principales <span class=\"pkg\">glmnet</span>:\n\n-   El importe de la regularización total (`penalty`). El rango predeterminado para este parámetro es $10^{-10}$ a $10^{0}$. Es típico utilizar una transformación logarítmica (base-10) para este parámetro.\n\n-   La proporción de la pena de lazo (`mixture`). Esto está acotado en cero y uno sin transformación.\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/iterative-neighborhood-calcs_0fa58822cdda23fda0f2d3809a2e369f'}\n\n:::\n\n\nEl proceso comienza con valores iniciales de `penalty = 0,025` y `mixture = 0,050`. Utilizando un radio que fluctúa aleatoriamente entre 0,050 y 0,015, los datos se escalan adecuadamente, se generan valores aleatorios en los radios alrededor del punto inicial y luego se elige uno al azar como candidato. A modo de ilustración, asumiremos que todos los valores candidatos son mejoras. Utilizando el nuevo valor, se genera un conjunto de nuevos vecinos aleatorios, se elige uno, y así sucesivamente. @fig-iterative-neighborhood muestra six iteraciones a medida que la búsqueda avanza hacia la esquina superior izquierda.\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/fig-iterative-neighborhood_0b98648723866b2b5394e56f70248797'}\n::: {.cell-output-display}\n![Una ilustración de cómo el recocido simulado determina cuál es la vecindad local para dos parámetros de ajuste numéricos. Las nubes de puntos muestran posibles siguientes valores donde se seleccionaría uno al azar. ](figures/fig-iterative-neighborhood-1.png){#fig-iterative-neighborhood fig-align='center' fig-alt='Una ilustración de cómo el recocido simulado determina cuál es la vecindad local para dos parámetros de ajuste numéricos. Las nubes de puntos muestran posibles siguientes valores donde se seleccionaría uno al azar. Los puntos candidatos son pequeñas nubes circulares que rodean el mejor punto actual.' width=80%}\n:::\n:::\n\n\nTenga en cuenta que, durante algunas iteraciones, los conjuntos candidatos a lo largo del radio excluyen puntos fuera de los límites del parámetro. Además, nuestra implementación desvía la elección de las siguientes configuraciones de parámetros de ajuste *lejos* de nuevos valores que son muy similares a las configuraciones anteriores.\n\nPara parámetros no numéricos, asignamos una probabilidad de con qué frecuencia cambia el valor del parámetro.\n\n### La función `tune_sim_anneal()` {#sec-tune-sim-anneal}\n\nPara implementar la búsqueda iterativa mediante recocido simulado, utilice la función `tune_sim_anneal()`. La sintaxis de esta función es casi idéntica a `tune_bayes()`. No hay opciones para funciones de adquisición o muestreo de incertidumbre. La función `control_sim_anneal()` tiene algunos detalles que definen la vecindad local y el programa de enfriamiento:\n\n-   `no_improve`, para recocido simulado, es un número entero que detendrá la búsqueda si no se descubren resultados globales mejores o mejorados dentro de las iteraciones `no_improve`. Los parámetros subóptimos aceptados o descartados cuentan como \"sin mejora\".\n\n-   `restart` es el número de iteraciones sin nuevos mejores resultados antes de comenzar con los mejores resultados anteriores.\n\n-   `radius` es un vector numérico en (0, 1) que define el radio mínimo y máximo de la vecindad local alrededor del punto inicial.\n\n-   `flip` es un valor de probabilidad que define las posibilidades de alterar el valor de parámetros categóricos o enteros.\n\n-   `cooling_coef` es el coeficiente $c$ en $\\exp(c\\times D_i \\times i)$ que modula la rapidez con la que la probabilidad de aceptación disminuye a lo largo de las iteraciones. Los valores más grandes de `cooling_coef` disminuyen la probabilidad de aceptar una configuración de parámetro subóptima.\n\nPara los datos de segmentación de celdas, la sintaxis es muy consistente con las funciones utilizadas anteriormente:\n\n\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/iterative-cells-sa_f6247b84f53082feafb20d5757b47e32'}\n\n```{.r .cell-code}\nctrl_sa <- control_sim_anneal(verbose = TRUE, no_improve = 10L)\n\nset.seed(1404)\nsvm_sa <-\n  svm_wflow %>%\n  tune_sim_anneal(\n    resamples = cell_folds,\n    metrics = roc_res,\n    initial = svm_initial,\n    param_info = svm_param,\n    iter = 50,\n    control = ctrl_sa\n  )\n```\n:::\n\n\n\n\nEl proceso de recocido simulado descubrió nuevos óptimos globales en 0 diferentes iteraciones. Había 4 se reinicia en iteraciones 13, 26, 34, and 45.\n\nLa opción `verbose` imprime detalles del proceso de búsqueda. El resultado de las primeras cinco iteraciones fue:\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/iterative-cells-sa-print-start_db5b3692f3190a2e53d98cc2eb6f011a'}\n\n:::\n\n\nEl resultado de las últimas diez iteraciones fue:\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/iterative-cells-sa-print-end_e0d9388163112f07f19f3a5acf36f395'}\n\n```\n## 40 + better suboptimal  roc_auc=0.89285 (+/-0.008806)\n## \n## i Fold01: preprocessor 1/1\n## \n## ✓ Fold01: preprocessor 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1\n## \n## ✓ Fold01: preprocessor 1/1, model 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold01: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold02: preprocessor 1/1\n## \n## ✓ Fold02: preprocessor 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1\n## \n## ✓ Fold02: preprocessor 1/1, model 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold02: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold03: preprocessor 1/1\n## \n## ✓ Fold03: preprocessor 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1\n## \n## ✓ Fold03: preprocessor 1/1, model 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold03: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold04: preprocessor 1/1\n## \n## ✓ Fold04: preprocessor 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1\n## \n## ✓ Fold04: preprocessor 1/1, model 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold04: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold05: preprocessor 1/1\n## \n## ✓ Fold05: preprocessor 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1\n## \n## ✓ Fold05: preprocessor 1/1, model 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold05: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold06: preprocessor 1/1\n## \n## ✓ Fold06: preprocessor 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1\n## \n## ✓ Fold06: preprocessor 1/1, model 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold06: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold07: preprocessor 1/1\n## \n## ✓ Fold07: preprocessor 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1\n## \n## ✓ Fold07: preprocessor 1/1, model 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold07: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold08: preprocessor 1/1\n## \n## ✓ Fold08: preprocessor 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1\n## \n## ✓ Fold08: preprocessor 1/1, model 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold08: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold09: preprocessor 1/1\n## \n## ✓ Fold09: preprocessor 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1\n## \n## ✓ Fold09: preprocessor 1/1, model 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold09: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold10: preprocessor 1/1\n## \n## ✓ Fold10: preprocessor 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1\n## \n## ✓ Fold10: preprocessor 1/1, model 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold10: preprocessor 1/1, model 1/1 (predictions)\n## \n## 41 + better suboptimal  roc_auc=0.89419 (+/-0.008628)\n## \n## i Fold01: preprocessor 1/1\n## \n## ✓ Fold01: preprocessor 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1\n## \n## ✓ Fold01: preprocessor 1/1, model 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold01: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold02: preprocessor 1/1\n## \n## ✓ Fold02: preprocessor 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1\n## \n## ✓ Fold02: preprocessor 1/1, model 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold02: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold03: preprocessor 1/1\n## \n## ✓ Fold03: preprocessor 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1\n## \n## ✓ Fold03: preprocessor 1/1, model 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold03: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold04: preprocessor 1/1\n## \n## ✓ Fold04: preprocessor 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1\n## \n## ✓ Fold04: preprocessor 1/1, model 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold04: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold05: preprocessor 1/1\n## \n## ✓ Fold05: preprocessor 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1\n## \n## ✓ Fold05: preprocessor 1/1, model 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold05: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold06: preprocessor 1/1\n## \n## ✓ Fold06: preprocessor 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1\n## \n## ✓ Fold06: preprocessor 1/1, model 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold06: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold07: preprocessor 1/1\n## \n## ✓ Fold07: preprocessor 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1\n## \n## ✓ Fold07: preprocessor 1/1, model 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold07: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold08: preprocessor 1/1\n## \n## ✓ Fold08: preprocessor 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1\n## \n## ✓ Fold08: preprocessor 1/1, model 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold08: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold09: preprocessor 1/1\n## \n## ✓ Fold09: preprocessor 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1\n## \n## ✓ Fold09: preprocessor 1/1, model 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold09: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold10: preprocessor 1/1\n## \n## ✓ Fold10: preprocessor 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1\n## \n## ✓ Fold10: preprocessor 1/1, model 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold10: preprocessor 1/1, model 1/1 (predictions)\n## \n## 42 + better suboptimal  roc_auc=0.8979 (+/-0.007741)\n## \n## i Fold01: preprocessor 1/1\n## \n## ✓ Fold01: preprocessor 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1\n## \n## ✓ Fold01: preprocessor 1/1, model 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold01: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold02: preprocessor 1/1\n## \n## ✓ Fold02: preprocessor 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1\n## \n## ✓ Fold02: preprocessor 1/1, model 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold02: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold03: preprocessor 1/1\n## \n## ✓ Fold03: preprocessor 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1\n## \n## ✓ Fold03: preprocessor 1/1, model 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold03: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold04: preprocessor 1/1\n## \n## ✓ Fold04: preprocessor 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1\n## \n## ✓ Fold04: preprocessor 1/1, model 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold04: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold05: preprocessor 1/1\n## \n## ✓ Fold05: preprocessor 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1\n## \n## ✓ Fold05: preprocessor 1/1, model 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold05: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold06: preprocessor 1/1\n## \n## ✓ Fold06: preprocessor 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1\n## \n## ✓ Fold06: preprocessor 1/1, model 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold06: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold07: preprocessor 1/1\n## \n## ✓ Fold07: preprocessor 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1\n## \n## ✓ Fold07: preprocessor 1/1, model 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold07: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold08: preprocessor 1/1\n## \n## ✓ Fold08: preprocessor 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1\n## \n## ✓ Fold08: preprocessor 1/1, model 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold08: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold09: preprocessor 1/1\n## \n## ✓ Fold09: preprocessor 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1\n## \n## ✓ Fold09: preprocessor 1/1, model 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold09: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold10: preprocessor 1/1\n## \n## ✓ Fold10: preprocessor 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1\n## \n## ✓ Fold10: preprocessor 1/1, model 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold10: preprocessor 1/1, model 1/1 (predictions)\n## \n## 43 ─ discard suboptimal roc_auc=0.86412 (+/-0.009579)\n## \n## i Fold01: preprocessor 1/1\n## \n## ✓ Fold01: preprocessor 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1\n## \n## ✓ Fold01: preprocessor 1/1, model 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold01: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold02: preprocessor 1/1\n## \n## ✓ Fold02: preprocessor 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1\n## \n## ✓ Fold02: preprocessor 1/1, model 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold02: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold03: preprocessor 1/1\n## \n## ✓ Fold03: preprocessor 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1\n## \n## ✓ Fold03: preprocessor 1/1, model 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold03: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold04: preprocessor 1/1\n## \n## ✓ Fold04: preprocessor 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1\n## \n## ✓ Fold04: preprocessor 1/1, model 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold04: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold05: preprocessor 1/1\n## \n## ✓ Fold05: preprocessor 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1\n## \n## ✓ Fold05: preprocessor 1/1, model 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold05: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold06: preprocessor 1/1\n## \n## ✓ Fold06: preprocessor 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1\n## \n## ✓ Fold06: preprocessor 1/1, model 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold06: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold07: preprocessor 1/1\n## \n## ✓ Fold07: preprocessor 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1\n## \n## ✓ Fold07: preprocessor 1/1, model 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold07: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold08: preprocessor 1/1\n## \n## ✓ Fold08: preprocessor 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1\n## \n## ✓ Fold08: preprocessor 1/1, model 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold08: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold09: preprocessor 1/1\n## \n## ✓ Fold09: preprocessor 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1\n## \n## ✓ Fold09: preprocessor 1/1, model 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold09: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold10: preprocessor 1/1\n## \n## ✓ Fold10: preprocessor 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1\n## \n## ✓ Fold10: preprocessor 1/1, model 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold10: preprocessor 1/1, model 1/1 (predictions)\n## \n## 44 ◯ accept suboptimal  roc_auc=0.89119 (+/-0.008697)\n## \n## i Fold01: preprocessor 1/1\n## \n## ✓ Fold01: preprocessor 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1\n## \n## ✓ Fold01: preprocessor 1/1, model 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold01: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold02: preprocessor 1/1\n## \n## ✓ Fold02: preprocessor 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1\n## \n## ✓ Fold02: preprocessor 1/1, model 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold02: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold03: preprocessor 1/1\n## \n## ✓ Fold03: preprocessor 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1\n## \n## ✓ Fold03: preprocessor 1/1, model 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold03: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold04: preprocessor 1/1\n## \n## ✓ Fold04: preprocessor 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1\n## \n## ✓ Fold04: preprocessor 1/1, model 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold04: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold05: preprocessor 1/1\n## \n## ✓ Fold05: preprocessor 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1\n## \n## ✓ Fold05: preprocessor 1/1, model 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold05: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold06: preprocessor 1/1\n## \n## ✓ Fold06: preprocessor 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1\n## \n## ✓ Fold06: preprocessor 1/1, model 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold06: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold07: preprocessor 1/1\n## \n## ✓ Fold07: preprocessor 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1\n## \n## ✓ Fold07: preprocessor 1/1, model 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold07: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold08: preprocessor 1/1\n## \n## ✓ Fold08: preprocessor 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1\n## \n## ✓ Fold08: preprocessor 1/1, model 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold08: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold09: preprocessor 1/1\n## \n## ✓ Fold09: preprocessor 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1\n## \n## ✓ Fold09: preprocessor 1/1, model 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold09: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold10: preprocessor 1/1\n## \n## ✓ Fold10: preprocessor 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1\n## \n## ✓ Fold10: preprocessor 1/1, model 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold10: preprocessor 1/1, model 1/1 (predictions)\n## \n## 45 ✖ restart from best  roc_auc=0.8921 (+/-0.00885)\n## \n## i Fold01: preprocessor 1/1\n## \n## ✓ Fold01: preprocessor 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1\n## \n## ✓ Fold01: preprocessor 1/1, model 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold01: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold02: preprocessor 1/1\n## \n## ✓ Fold02: preprocessor 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1\n## \n## ✓ Fold02: preprocessor 1/1, model 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold02: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold03: preprocessor 1/1\n## \n## ✓ Fold03: preprocessor 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1\n## \n## ✓ Fold03: preprocessor 1/1, model 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold03: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold04: preprocessor 1/1\n## \n## ✓ Fold04: preprocessor 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1\n## \n## ✓ Fold04: preprocessor 1/1, model 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold04: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold05: preprocessor 1/1\n## \n## ✓ Fold05: preprocessor 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1\n## \n## ✓ Fold05: preprocessor 1/1, model 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold05: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold06: preprocessor 1/1\n## \n## ✓ Fold06: preprocessor 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1\n## \n## ✓ Fold06: preprocessor 1/1, model 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold06: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold07: preprocessor 1/1\n## \n## ✓ Fold07: preprocessor 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1\n## \n## ✓ Fold07: preprocessor 1/1, model 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold07: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold08: preprocessor 1/1\n## \n## ✓ Fold08: preprocessor 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1\n## \n## ✓ Fold08: preprocessor 1/1, model 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold08: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold09: preprocessor 1/1\n## \n## ✓ Fold09: preprocessor 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1\n## \n## ✓ Fold09: preprocessor 1/1, model 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold09: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold10: preprocessor 1/1\n## \n## ✓ Fold10: preprocessor 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1\n## \n## ✓ Fold10: preprocessor 1/1, model 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold10: preprocessor 1/1, model 1/1 (predictions)\n## \n## 46 ◯ accept suboptimal  roc_auc=0.89657 (+/-0.008539)\n## \n## i Fold01: preprocessor 1/1\n## \n## ✓ Fold01: preprocessor 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1\n## \n## ✓ Fold01: preprocessor 1/1, model 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold01: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold02: preprocessor 1/1\n## \n## ✓ Fold02: preprocessor 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1\n## \n## ✓ Fold02: preprocessor 1/1, model 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold02: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold03: preprocessor 1/1\n## \n## ✓ Fold03: preprocessor 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1\n## \n## ✓ Fold03: preprocessor 1/1, model 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold03: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold04: preprocessor 1/1\n## \n## ✓ Fold04: preprocessor 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1\n## \n## ✓ Fold04: preprocessor 1/1, model 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold04: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold05: preprocessor 1/1\n## \n## ✓ Fold05: preprocessor 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1\n## \n## ✓ Fold05: preprocessor 1/1, model 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold05: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold06: preprocessor 1/1\n## \n## ✓ Fold06: preprocessor 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1\n## \n## ✓ Fold06: preprocessor 1/1, model 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold06: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold07: preprocessor 1/1\n## \n## ✓ Fold07: preprocessor 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1\n## \n## ✓ Fold07: preprocessor 1/1, model 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold07: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold08: preprocessor 1/1\n## \n## ✓ Fold08: preprocessor 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1\n## \n## ✓ Fold08: preprocessor 1/1, model 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold08: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold09: preprocessor 1/1\n## \n## ✓ Fold09: preprocessor 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1\n## \n## ✓ Fold09: preprocessor 1/1, model 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold09: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold10: preprocessor 1/1\n## \n## ✓ Fold10: preprocessor 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1\n## \n## ✓ Fold10: preprocessor 1/1, model 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold10: preprocessor 1/1, model 1/1 (predictions)\n## \n## 47 ◯ accept suboptimal  roc_auc=0.88647 (+/-0.008694)\n## \n## i Fold01: preprocessor 1/1\n## \n## ✓ Fold01: preprocessor 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1\n## \n## ✓ Fold01: preprocessor 1/1, model 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold01: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold02: preprocessor 1/1\n## \n## ✓ Fold02: preprocessor 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1\n## \n## ✓ Fold02: preprocessor 1/1, model 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold02: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold03: preprocessor 1/1\n## \n## ✓ Fold03: preprocessor 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1\n## \n## ✓ Fold03: preprocessor 1/1, model 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold03: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold04: preprocessor 1/1\n## \n## ✓ Fold04: preprocessor 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1\n## \n## ✓ Fold04: preprocessor 1/1, model 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold04: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold05: preprocessor 1/1\n## \n## ✓ Fold05: preprocessor 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1\n## \n## ✓ Fold05: preprocessor 1/1, model 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold05: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold06: preprocessor 1/1\n## \n## ✓ Fold06: preprocessor 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1\n## \n## ✓ Fold06: preprocessor 1/1, model 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold06: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold07: preprocessor 1/1\n## \n## ✓ Fold07: preprocessor 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1\n## \n## ✓ Fold07: preprocessor 1/1, model 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold07: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold08: preprocessor 1/1\n## \n## ✓ Fold08: preprocessor 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1\n## \n## ✓ Fold08: preprocessor 1/1, model 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold08: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold09: preprocessor 1/1\n## \n## ✓ Fold09: preprocessor 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1\n## \n## ✓ Fold09: preprocessor 1/1, model 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold09: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold10: preprocessor 1/1\n## \n## ✓ Fold10: preprocessor 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1\n## \n## ✓ Fold10: preprocessor 1/1, model 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold10: preprocessor 1/1, model 1/1 (predictions)\n## \n## 48 + better suboptimal  roc_auc=0.89035 (+/-0.008894)\n## \n## i Fold01: preprocessor 1/1\n## \n## ✓ Fold01: preprocessor 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1\n## \n## ✓ Fold01: preprocessor 1/1, model 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold01: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold02: preprocessor 1/1\n## \n## ✓ Fold02: preprocessor 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1\n## \n## ✓ Fold02: preprocessor 1/1, model 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold02: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold03: preprocessor 1/1\n## \n## ✓ Fold03: preprocessor 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1\n## \n## ✓ Fold03: preprocessor 1/1, model 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold03: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold04: preprocessor 1/1\n## \n## ✓ Fold04: preprocessor 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1\n## \n## ✓ Fold04: preprocessor 1/1, model 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold04: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold05: preprocessor 1/1\n## \n## ✓ Fold05: preprocessor 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1\n## \n## ✓ Fold05: preprocessor 1/1, model 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold05: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold06: preprocessor 1/1\n## \n## ✓ Fold06: preprocessor 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1\n## \n## ✓ Fold06: preprocessor 1/1, model 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold06: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold07: preprocessor 1/1\n## \n## ✓ Fold07: preprocessor 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1\n## \n## ✓ Fold07: preprocessor 1/1, model 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold07: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold08: preprocessor 1/1\n## \n## ✓ Fold08: preprocessor 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1\n## \n## ✓ Fold08: preprocessor 1/1, model 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold08: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold09: preprocessor 1/1\n## \n## ✓ Fold09: preprocessor 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1\n## \n## ✓ Fold09: preprocessor 1/1, model 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold09: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold10: preprocessor 1/1\n## \n## ✓ Fold10: preprocessor 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1\n## \n## ✓ Fold10: preprocessor 1/1, model 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold10: preprocessor 1/1, model 1/1 (predictions)\n## \n## 49 + better suboptimal  roc_auc=0.8977 (+/-0.007898)\n## \n## i Fold01: preprocessor 1/1\n## \n## ✓ Fold01: preprocessor 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1\n## \n## ✓ Fold01: preprocessor 1/1, model 1/1\n## \n## i Fold01: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold01: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold02: preprocessor 1/1\n## \n## ✓ Fold02: preprocessor 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1\n## \n## ✓ Fold02: preprocessor 1/1, model 1/1\n## \n## i Fold02: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold02: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold03: preprocessor 1/1\n## \n## ✓ Fold03: preprocessor 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1\n## \n## ✓ Fold03: preprocessor 1/1, model 1/1\n## \n## i Fold03: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold03: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold04: preprocessor 1/1\n## \n## ✓ Fold04: preprocessor 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1\n## \n## ✓ Fold04: preprocessor 1/1, model 1/1\n## \n## i Fold04: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold04: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold05: preprocessor 1/1\n## \n## ✓ Fold05: preprocessor 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1\n## \n## ✓ Fold05: preprocessor 1/1, model 1/1\n## \n## i Fold05: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold05: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold06: preprocessor 1/1\n## \n## ✓ Fold06: preprocessor 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1\n## \n## ✓ Fold06: preprocessor 1/1, model 1/1\n## \n## i Fold06: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold06: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold07: preprocessor 1/1\n## \n## ✓ Fold07: preprocessor 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1\n## \n## ✓ Fold07: preprocessor 1/1, model 1/1\n## \n## i Fold07: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold07: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold08: preprocessor 1/1\n## \n## ✓ Fold08: preprocessor 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1\n## \n## ✓ Fold08: preprocessor 1/1, model 1/1\n## \n## i Fold08: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold08: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold09: preprocessor 1/1\n## \n## ✓ Fold09: preprocessor 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1\n## \n## ✓ Fold09: preprocessor 1/1, model 1/1\n## \n## i Fold09: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold09: preprocessor 1/1, model 1/1 (predictions)\n## \n## i Fold10: preprocessor 1/1\n## \n## ✓ Fold10: preprocessor 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1\n## \n## ✓ Fold10: preprocessor 1/1, model 1/1\n## \n## i Fold10: preprocessor 1/1, model 1/1 (extracts)\n## \n## i Fold10: preprocessor 1/1, model 1/1 (predictions)\n## \n## 50 ─ discard suboptimal roc_auc=0.86146 (+/-0.009902)\n```\n:::\n\n\nAl igual que con las otras funciones `tune_*()`, la función `autoplot()` correspondiente produce evaluaciones visuales de los resultados. El uso de `autoplot(svm_sa, type = \"performance\")` muestra el rendimiento en iteraciones (@fig-sa-iterations) mientras que `autoplot(svm_sa, type = \"parameters\")` traza el rendimiento versus valores de parámetros de ajuste específicos (@fig-sa-parameters).\n\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/fig-sa-iterations_f52ab00909e16cbb32c5044aacf368e9'}\n::: {.cell-output-display}\n![El progreso del proceso de recocido simulado se muestra cuando se usa el método `autoplot()` con `type = \"performance\"`](figures/fig-sa-iterations-1.png){#fig-sa-iterations fig-align='center' fig-alt='El progreso del proceso de recocido simulado se muestra cuando se usa el método `autoplot()` con `type = \\'performance\\'`. El gráfico muestra el rendimiento estimado en el eje y frente al número de iteraciones en el eje x. Se muestran intervalos de confianza para los puntos.' width=672}\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='14-iterative-search_cache/html/fig-sa-parameters_cea4a92f2f1b81a77c12975dcde5db47'}\n::: {.cell-output-display}\n![Rendimiento versus valores de parámetros de ajuste cuando el método `autoplot()` se usa con `type = \"parameters\"`.](figures/fig-sa-parameters-1.png){#fig-sa-parameters fig-align='center' fig-alt='Una visualización del rendimiento frente a los valores de los parámetros de ajuste cuando se utiliza el método `autoplot()` con `type = \\'parameters\\'`. El gráfico muestra diferentes paneles para cada parámetro de sintonización en sus unidades transformadas.' width=672}\n:::\n:::\n\n\nUna visualización de la ruta de búsqueda ayuda a comprender dónde funcionó bien el proceso de búsqueda y dónde se extravió:\n\n\n\n\n\n<video width=\"720\" height=\"720\" controls>\n\n<source src=\"sa_search.mp4\" type=\"video/mp4\">\n\n</video>\n\nAl igual que `tune_bayes()`, detener manualmente la ejecución devolverá las iteraciones completadas.\n\n## Resumen Del Capítulo {#sec-iterative-summary}\n\nEste capítulo describió dos métodos de búsqueda iterativos para optimizar los parámetros de ajuste. La optimización de Bayes utiliza un modelo predictivo entrenado en los resultados de remuestreo existentes para sugerir valores de parámetros de ajuste, mientras que el recocido simulado recorre el espacio de hiperparámetros para encontrar buenos valores. Ambos pueden ser eficaces para encontrar buenos valores por sí solos o como método de seguimiento utilizado después de una búsqueda inicial en la cuadrícula para mejorar el rendimiento de <span class=\"pkg\">finetune</span>.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"site_libs/kePrint-0.0.1/kePrint.js\"></script>\r\n<link href=\"site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}