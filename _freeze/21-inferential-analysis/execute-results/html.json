{
  "hash": "c1a74fd6b2252b45d8cb4e1a52c21b37",
  "result": {
    "markdown": "\n\n\n# Análisis Inferencial {#sec-inferential}\n\n::: rmdnote\nEn @sec-model-types, describimos una taxonomía de modelos y dijimos que la mayoría de los modelos pueden clasificarse como descriptivos, inferenciales y/o predictivos.\n:::\n\nLa mayoría de los capítulos de este libro se han centrado en los modelos desde la perspectiva de la precisión de los valores predichos, una cualidad importante de los modelos para todos los propósitos, pero más relevante para los modelos predictivos. Los modelos inferenciales generalmente se crean no solo para sus predicciones, sino también para hacer inferencias o juicios sobre algún componente del modelo, como un valor de coeficiente u otro parámetro. Estos resultados se utilizan a menudo para responder algunas (con suerte) preguntas o hipótesis predefinidas. En los modelos predictivos, las predicciones sobre datos reservados se utilizan para validar o caracterizar la calidad del modelo. Los métodos inferenciales se centran en validar los supuestos probabilísticos o estructurales que se hacen antes de ajustar el modelo.\n\nPor ejemplo, en la regresión lineal ordinaria, la suposición común es que los valores residuales son independientes y siguen una distribución gaussiana con una varianza constante. Si bien es posible que tenga conocimientos científicos o de dominio para dar credibilidad a este supuesto para el análisis de su modelo, los residuos del modelo ajustado generalmente se examinan para determinar si el supuesto fue una buena idea. Como resultado, los métodos para determinar si se han cumplido los supuestos del modelo no son tan simples como observar las predicciones de reserva, aunque eso también puede ser muy útil.\n\nUsaremos valores p en este capítulo. Sin embargo, el marco de tidymodels tiende a promover intervalos de confianza sobre los valores p como método para cuantificar la evidencia de una hipótesis alternativa. Como se mostró anteriormente en @sec-tidyposterior, los métodos bayesianos suelen ser superiores tanto a los valores p como a los intervalos de confianza en términos de facilidad de interpretación (pero pueden ser más costosos desde el punto de vista computacional).\n\n::: rmdwarning\nEn los últimos años ha habido un impulso para alejarse de los valores p en favor de otros métodos [@pvalue]. Consulte el Volumen 73 de [*The American Statistician*](https://www.tandfonline.com/toc/utas20/73/) para obtener más información y discusión.\n:::\n\nEn este capítulo, describimos cómo usar <span class=\"pkg\">tidymodels</span> para ajustar y evaluar modelos inferenciales. En algunos casos, el marco tidymodels puede ayudar a los usuarios a trabajar con los objetos producidos por sus modelos. En otros, puede ayudar a evaluar la calidad de un modelo determinado.\n\n## Inferencia Para Datos De Recuento\n\nPara comprender cómo se pueden utilizar los paquetes tidymodels para el modelado inferencial, centrémonos en un ejemplo con datos de recuento. Usaremos datos de publicaciones de bioquímica del paquete <span class=\"pkg\">pscl</span>. Estos datos consisten en información sobre 915 Ph.D. se gradúan en bioquímica e intenta explicar los factores que impactan su productividad académica (medida a través del número o recuento de artículos publicados en tres años). Los predictores incluyen el género del graduado, su estado civil, el número de hijos del graduado que tengan al menos cinco años, el prestigio de su departamento y el número de artículos producidos por su mentor en el mismo período de tiempo. Los datos reflejan doctorados en bioquímica que terminaron su educación entre 1956 y 1963. Los datos son una muestra algo sesgada de todos los doctorados en bioquímica otorgados durante este período (basado en la integridad de la información).\n\n::: rmdnote\nRecuerde que en el [Capítulo @sec-trust] hicimos la pregunta \"¿Es nuestro modelo aplicable para predecir un punto de datos específico?\" Es muy importante definir a qué poblaciones se aplica un análisis inferencial. Para estos datos, los resultados probablemente se aplicarían a los doctorados en bioquímica dados aproximadamente en el período en que se recopilaron los datos. ¿Se aplica también a otros tipos de doctorado en química (por ejemplo, química medicinal, etc.)? Éstas son preguntas importantes que se deben abordar (y documentar) al realizar análisis inferenciales.\n:::\n\nUn gráfico de los datos mostrados en @fig-counts indica que muchos graduados no publicaron ningún artículo durante este tiempo y que el resultado sigue una distribución sesgada a la derecha:\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inferential-count-dist_4a95922da522114b18aa99c1d4a5d656'}\n\n```{.r .cell-code}\nlibrary(tidymodels)\ntidymodels_prefer()\n\ndata(\"bioChemists\", package = \"pscl\")\n\nggplot(bioChemists, aes(x = art)) + \n  geom_histogram(binwidth = 1, color = \"white\") + \n  labs(x = \"Número de artículos dentro de los 3 años posteriores a la graduación\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/fig-counts_89ed7fb037d3990866127d0eb2e9f208'}\n::: {.cell-output-display}\n![Distribución del número de artículos escritos dentro de los 3 años posteriores a la graduación.](figures/fig-counts-1.png){#fig-counts fig-align='center' fig-alt='La distribución del número de artículos escritos dentro de los 3 años posteriores a la graduación. La distribución está sesgada a la derecha y la mayoría de los datos tienen recuentos de cero o uno.' width=80%}\n:::\n:::\n\n\nDado que los datos de los resultados son recuentos, la suposición de distribución más común es que el resultado tiene una distribución de Poisson. En este capítulo se utilizarán estos datos para varios tipos de análisis.\n\n## Comparaciones Con Pruebas De Dos Muestras\n\nPodemos comenzar con la prueba de hipótesis. El objetivo del autor original con este conjunto de datos sobre publicaciones de bioquímica era determinar si existe una diferencia en las publicaciones entre hombres y mujeres [@Long1992]. Los datos del estudio muestran:\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inferential-counts_c50233afcff5f0b1466cdde474dd9d5d'}\n\n```{.r .cell-code}\nbioChemists %>% \n  group_by(fem) %>% \n  summarize(counts = sum(art), n = length(art))\n## # A tibble: 2 × 3\n##   fem   counts     n\n##   <fct>  <int> <int>\n## 1 Men      930   494\n## 2 Women    619   421\n```\n:::\n\n\nHabía muchas más publicaciones de hombres, aunque también había más hombres en los datos. El enfoque más simple para analizar estos datos sería hacer una comparación de dos muestras usando la función `poisson.test()` en el paquete <span class=\"pkg\">stats</span>. Requiere los conteos para uno o dos grupos.\n\nPara nuestra aplicación, las hipótesis para comparar los dos sexos son:\n\n\n```{=tex}\n\\begin{align}\nH_0&: \\lambda_m = \\lambda_f \\notag \\\\\nH_a&: \\lambda_m \\ne \\lambda_f \\notag\n\\end{align}\n```\n\ndonde los valores $\\lambda$ son las tasas de publicaciones (durante el mismo período de tiempo).\n\nUna aplicación básica de la prueba es:Una aplicación básica de la prueba es:[^21-inferential-analysis-1]\n\n[^21-inferential-analysis-1]: El argumento `T` nos permite dar cuenta del tiempo en que se contaron los eventos (publicaciones), que fue de tres años tanto para hombres como para mujeres. Hay más hombres que mujeres en estos datos, pero `poisson.test()` tiene una funcionalidad limitada, por lo que se pueden utilizar análisis más sofisticados para explicar esta diferencia.\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inferential-test-basic_ffaca8a897762e3bad1953ae5cfa9b58'}\n\n```{.r .cell-code}\npoisson.test(c(930, 619), T = 3)\n## \n## \tComparison of Poisson rates\n## \n## data:  c(930, 619) time base: 3\n## count1 = 930, expected count1 = 774, p-value = 3e-15\n## alternative hypothesis: true rate ratio is not equal to 1\n## 95 percent confidence interval:\n##  1.356 1.666\n## sample estimates:\n## rate ratio \n##      1.502\n```\n:::\n\n\nLa función informa un valor p así como un intervalo de confianza para la relación de las tasas de publicación. Los resultados indican que la diferencia observada es mayor que el ruido experiencial y favorece a $H_a$.\n\nUn problema con el uso de esta función es que los resultados regresan como un objeto \"htest\". Si bien este tipo de objeto tiene una estructura bien definida, puede resultar difícil consumirlo para operaciones posteriores, como informes o visualizaciones. La herramienta más impactante que ofrece tidymodels para modelos inferenciales son las funciones `tidy()` en el paquete <span class=\"pkg\">broom</span>. Como se vio anteriormente, esta función crea un tibble bien formado y con un nombre predecible a partir del objeto. Podemos `tidy()` los resultados de nuestra prueba de comparación de dos muestras:\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inferential-test-tidy_45b81b9fbb34d01df1e8e8fdbc9ba0f8'}\n\n```{.r .cell-code}\npoisson.test(c(930, 619)) %>% \n  tidy()\n## # A tibble: 1 × 8\n##   estimate statistic  p.value parameter conf.low conf.high method        alternative\n##      <dbl>     <dbl>    <dbl>     <dbl>    <dbl>     <dbl> <chr>         <chr>      \n## 1     1.50       930 2.73e-15      774.     1.36      1.67 Comparison o… two.sided\n```\n:::\n\n\n::: rmdnote\nEntre [<span class=\"pkg\">broom</span>](https://broom.tidymodels.org/) y [<span class=\"pkg\">broom.mixed</span>](https://CRAN.R-project.org/package=%20broom.mixed), existen métodos `tidy()` para más de 150 modelos.\n:::\n\nSi bien la distribución de Poisson es razonable, es posible que también deseemos evaluarla utilizando menos supuestos distributivos. Dos métodos que podrían resultar útiles son las pruebas de arranque y de permutación [@davison1997bootstrap].\n\nEl paquete <span class=\"pkg\">infer</span>, parte del marco tidymodels, es una herramienta poderosa e intuitiva para probar hipótesis [@ModernDive]. Su sintaxis es concisa y está diseñada para no estadísticos.\n\nPrimero, `specify()` que usaremos la diferencia en el número medio de artículos entre los sexos y luego `calculate()` la estadística a partir de los datos. Recuerde que el estimador de máxima verosimilitud para la media de Poisson es la media muestral. Las hipótesis probadas aquí son las mismas que las de la prueba anterior (pero se llevan a cabo mediante un procedimiento de prueba diferente).\n\nCon <span class=\"pkg\">infer</span>, especificamos el resultado y la covariable, luego indicamos la estadística de interés:\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inferential-mean-diff-obs_d9b68cb1545f93afc6980ff32c445f23'}\n\n```{.r .cell-code}\nlibrary(infer)\n\nobserved <- \n  bioChemists %>%\n  specify(art ~ fem) %>%\n  calculate(stat = \"diff in means\", order = c(\"Men\", \"Women\"))\nobserved\n## Response: art (numeric)\n## Explanatory: fem (factor)\n## # A tibble: 1 × 1\n##    stat\n##   <dbl>\n## 1 0.412\n```\n:::\n\n\nA partir de aquí, calculamos un intervalo de confianza para esta media creando la distribución de arranque mediante `generate()`; se calcula la misma estadística para cada versión remuestreada de los datos:\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inferential-mean-diff-boot-gen_fbd0a872a32a60fdad605106804de46a'}\n\n```{.r .cell-code}\nset.seed(2101)\nbootstrapped <- \n  bioChemists %>%\n  specify(art ~ fem)  %>%\n  generate(reps = 2000, type = \"bootstrap\") %>%\n  calculate(stat = \"diff in means\", order = c(\"Men\", \"Women\"))\nbootstrapped\n## Response: art (numeric)\n## Explanatory: fem (factor)\n## # A tibble: 2,000 × 2\n##   replicate  stat\n##       <int> <dbl>\n## 1         1 0.467\n## 2         2 0.107\n## 3         3 0.467\n## 4         4 0.308\n## 5         5 0.369\n## 6         6 0.428\n## # ℹ 1,994 more rows\n```\n:::\n\n\nUn intervalo percentil se calcula usando:\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inferential-mean-diff-boot-ci_42d001998c77e2bc491baf87d05fb1e8'}\n\n```{.r .cell-code}\npercentile_ci <- get_ci(bootstrapped)\npercentile_ci\n## # A tibble: 1 × 2\n##   lower_ci upper_ci\n##      <dbl>    <dbl>\n## 1    0.158    0.653\n```\n:::\n\n\nEl paquete <span class=\"pkg\">infer</span> tiene una API de alto nivel para mostrar los resultados del análisis, como se muestra en @fig-bootstrapped-mean.\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inferential-mean-diff-boot_f86d91a37f81a8ad9ad7648eb894623c'}\n\n```{.r .cell-code}\nvisualize(bootstrapped) +\n    shade_confidence_interval(endpoints = percentile_ci)\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/fig-bootstrapped-mean_5862774527060b78e540aaa6f3545e88'}\n::: {.cell-output-display}\n![La distribución bootstrap de la diferencia de medias. La región resaltada es el intervalo de confianza.](figures/fig-bootstrapped-mean-1.png){#fig-bootstrapped-mean fig-align='center' fig-alt='La distribución bootstrap de la diferencia de medias. La región resaltada es el intervalo de confianza, que no incluye un valor de cero.' width=80%}\n:::\n:::\n\n\nDado que el intervalo visualizado en @fig-bootstrapped-mean no incluye cero, estos resultados indican que los hombres han publicado más artículos que las mujeres.\n\nSi requerimos un valor p, el paquete <span class=\"pkg\">infer</span> puede calcular el valor mediante una prueba de permutación, que se muestra en el siguiente código. La sintaxis es muy similar al código de arranque que usamos anteriormente. Agregamos un verbo `hypothesize()` para indicar el tipo de suposición a probar y la llamada `generate()` contiene una opción para mezclar los datos.\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inferential-mean-diff-perm-gen_3726d271437e7640a90e4a728ff27f94'}\n\n```{.r .cell-code}\nset.seed(2102)\npermuted <- \n  bioChemists %>%\n  specify(art ~ fem)  %>%\n  hypothesize(null = \"independence\") %>%\n  generate(reps = 2000, type = \"permute\") %>%\n  calculate(stat = \"diff in means\", order = c(\"Men\", \"Women\"))\npermuted\n## Response: art (numeric)\n## Explanatory: fem (factor)\n## Null Hypothesis: independence\n## # A tibble: 2,000 × 2\n##   replicate     stat\n##       <int>    <dbl>\n## 1         1  0.201  \n## 2         2 -0.133  \n## 3         3  0.109  \n## 4         4 -0.195  \n## 5         5 -0.00128\n## 6         6 -0.102  \n## # ℹ 1,994 more rows\n```\n:::\n\n\nEl siguiente código de visualización también es muy similar al enfoque de arranque. Este código genera @fig-permutation-dist donde la línea vertical indica el valor observado:\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inferential-mean-diff-perm_f6c935ad51b986374dfd7f5b75318e29'}\n\n```{.r .cell-code}\nvisualize(permuted) +\n    shade_p_value(obs_stat = observed, direction = \"two-sided\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/fig-permutation-dist_5089018507423bdc64cbafc06b1169e2'}\n::: {.cell-output-display}\n![Distribución empírica del estadístico de prueba bajo la hipótesis nula. La línea vertical indica la estadística de prueba observada.](figures/fig-permutation-dist-1.png){#fig-permutation-dist fig-align='center' fig-alt='La distribución empírica del estadístico de prueba bajo la hipótesis nula. La línea vertical indica la estadística de prueba observada y está muy alejada de la corriente principal de la distribución.' width=80%}\n:::\n:::\n\n\nThe actual p-value is:\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inferential-mean-diff-perm-pvalue_ebb6a6e0f81d01dcc62ee9035f163793'}\n\n```{.r .cell-code}\npermuted %>%\n  get_p_value(obs_stat = observed, direction = \"two-sided\")\n## # A tibble: 1 × 1\n##   p_value\n##     <dbl>\n## 1   0.002\n```\n:::\n\n\nLa línea vertical que representa la hipótesis nula en @fig-permutation-dist está muy lejos de la distribución de permutación. Esto significa que, si de hecho la hipótesis nula fuera cierta, la probabilidad de observar datos al menos tan extremos como los que tenemos a mano es extremadamente pequeña.\n\nLas pruebas de dos muestras que se muestran en esta sección probablemente no sean óptimas porque no tienen en cuenta otros factores que podrían explicar la relación observada entre la tasa de publicación y el sexo. Pasemos a un modelo más complejo que pueda considerar covariables adicionales.\n\n## Modelos log-lineales\n\nEl resto de este capítulo se centrará en un modelo lineal generalizado [@Dobson99] donde asumimos que los recuentos siguen una distribución de Poisson. Para este modelo, las covariables/predictores ingresan al modelo de forma log-lineal:\n\n$$\n\\log(\\lambda) = \\beta_0 + \\beta_1x_1 + \\ldots + \\beta_px_p\n$$\n\ndonde $\\lambda$ es el valor esperado de los recuentos.\n\nAjustemos un modelo simple que contenga todas las columnas predictoras. El paquete <span class=\"pkg\">poissonreg</span>, un paquete de extensión <span class=\"pkg\">parsnip</span> en tidymodels, se ajustará a esta especificación de modelo:\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inferential-glm_1bbde3d8c0aed96099455ba432327cdf'}\n\n```{.r .cell-code}\nlibrary(poissonreg)\n\n# El motor predeterminado es 'glm'\nlog_lin_spec <- poisson_reg()\n\nlog_lin_fit <- \n  log_lin_spec %>% \n  fit(art ~ ., data = bioChemists)\nlog_lin_fit\n## parsnip model object\n## \n## \n## Call:  stats::glm(formula = art ~ ., family = stats::poisson, data = data)\n## \n## Coefficients:\n## (Intercept)     femWomen   marMarried         kid5          phd         ment  \n##      0.3046      -0.2246       0.1552      -0.1849       0.0128       0.0255  \n## \n## Degrees of Freedom: 914 Total (i.e. Null);  909 Residual\n## Null Deviance:\t    1820 \n## Residual Deviance: 1630 \tAIC: 3310\n```\n:::\n\n\nEl método `tidy()` resume sucintamente los coeficientes del modelo (junto con intervalos de confianza del 90%):\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inferential-glm-tidy_0e87de384d688125a6c53078c1045d39'}\n\n```{.r .cell-code}\ntidy(log_lin_fit, conf.int = TRUE, conf.level = 0.90)\n## # A tibble: 6 × 7\n##   term        estimate std.error statistic  p.value conf.low conf.high\n##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n## 1 (Intercept)   0.305    0.103       2.96  3.10e- 3   0.134     0.473 \n## 2 femWomen     -0.225    0.0546     -4.11  3.92e- 5  -0.315    -0.135 \n## 3 marMarried    0.155    0.0614      2.53  1.14e- 2   0.0545    0.256 \n## 4 kid5         -0.185    0.0401     -4.61  4.08e- 6  -0.251    -0.119 \n## 5 phd           0.0128   0.0264      0.486 6.27e- 1  -0.0305    0.0563\n## 6 ment          0.0255   0.00201    12.7   3.89e-37   0.0222    0.0288\n```\n:::\n\n\nEn este resultado, los valores p corresponden a pruebas de hipótesis separadas para cada parámetro:\n\n\n```{=tex}\n\\begin{align}\nH_0&: \\beta_j = 0 \\notag \\\\\nH_a&: \\beta_j \\ne 0 \\notag\n\\end{align}\n```\n\npara cada uno de los parámetros del modelo. Al observar estos resultados, es posible que el `phd` (el prestigio de su departamento) no tenga ninguna relación con el resultado.\n\nSi bien la distribución de Poisson es el supuesto habitual para datos como estos, puede resultar beneficioso realizar una verificación aproximada de los supuestos del modelo ajustando los modelos sin utilizar la probabilidad de Poisson para calcular los intervalos de confianza. El paquete <span class=\"pkg\">rsample</span> tiene una función conveniente para calcular intervalos de confianza de arranque para los modelos `lm()` y `glm()`. Podemos usar esta función, mientras declaramos explícitamente `family = poisson`, para calcular una gran cantidad de ajustes del modelo. De forma predeterminada, calculamos un intervalo bootstrap-t de confianza del 90% (los intervalos percentiles también están disponibles):\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inferential-glm-ci_7a4e8f09445f7875187504b4ab1b5a45'}\n\n```{.r .cell-code}\nset.seed(2103)\nglm_boot <- \n  reg_intervals(art ~ ., data = bioChemists, model_fn = \"glm\", family = poisson)\nglm_boot\n## # A tibble: 5 × 6\n##   term          .lower .estimate  .upper .alpha .method  \n##   <chr>          <dbl>     <dbl>   <dbl>  <dbl> <chr>    \n## 1 femWomen   -0.358      -0.226  -0.0856   0.05 student-t\n## 2 kid5       -0.298      -0.184  -0.0789   0.05 student-t\n## 3 marMarried  0.000264    0.155   0.317    0.05 student-t\n## 4 ment        0.0182      0.0256  0.0322   0.05 student-t\n## 5 phd        -0.0707      0.0130  0.102    0.05 student-t\n```\n:::\n\n\n::: rmdwarning\nCuando comparamos estos resultados (en @fig-glm-intervals) con los resultados puramente paramétricos de `glm()`, los intervalos de arranque son algo más amplios. Si los datos fueran verdaderamente de Poisson, estos intervalos tendrían anchos más similares.\n:::\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/fig-glm-intervals_404b10772a557e07fd8d8af41ba701c0'}\n::: {.cell-output-display}\n![Dos tipos de intervalos de confianza para el modelo de regresión de Poisson](figures/fig-glm-intervals-1.png){#fig-glm-intervals fig-align='center' fig-alt='Dos tipos de intervalos de confianza para el modelo de regresión de Poisson. el intervalo para el modelo PhD es el único intervalo que se superpone a cero. Los intervalos paramétricos tienden a ser más amplios que los intervalos de arranque.' width=672}\n:::\n:::\n\n\nDeterminar qué predictores incluir en el modelo es un problema difícil. Un enfoque consiste en realizar pruebas de índice de verosimilitud (LRT) [@McCullaghNelder89] entre modelos anidados. Según los intervalos de confianza, tenemos evidencia de que un modelo más simple sin `phd` puede ser suficiente. Ajustemos un modelo más pequeño y luego realicemos una prueba estadística:\n\n\n```{=tex}\n\\begin{align}\nH_0&: \\beta_{phd} = 0 \\notag \\\\\nH_a&: \\beta_{phd} \\ne 0 \\notag\n\\end{align}\n```\n\nEsta hipótesis se probó previamente cuando mostramos los resultados ordenados de `log_lin_fit`. Ese enfoque particular utilizó resultados de un ajuste de modelo único mediante una estadística de Wald (es decir, el parámetro dividido por su error estándar). Para ese enfoque, el valor p era 0.63. Podemos ordenar los resultados del LRT para obtener el valor p:\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inferential-reduced_00bdb23aec2c02d86909e70a49eb71ac'}\n\n```{.r .cell-code}\nlog_lin_reduced <- \n  log_lin_spec %>% \n  fit(art ~ ment + kid5 + fem + mar, data = bioChemists)\n\nanova(\n  extract_fit_engine(log_lin_reduced),\n  extract_fit_engine(log_lin_fit),\n  test = \"LRT\"\n) %>%\n  tidy()\n## # A tibble: 2 × 6\n##   term                          df.residual residual.deviance    df deviance p.value\n##   <chr>                               <dbl>             <dbl> <dbl>    <dbl>   <dbl>\n## 1 art ~ ment + kid5 + fem + mar         910             1635.    NA   NA      NA    \n## 2 art ~ fem + mar + kid5 + phd…         909             1634.     1    0.236   0.627\n```\n:::\n\n\nLos resultados son los mismos y, en base a estos y al intervalo de confianza para este parámetro, excluiremos `phd` de análisis adicionales ya que no parece estar asociado con el resultado.\n\n## Un Modelo Más Complejo\n\nPodemos pasar a modelos aún más complejos dentro de nuestro enfoque de tidymodels. Para los datos de recuento, hay ocasiones en las que el número de recuentos de ceros es mayor de lo que prescribiría una distribución de Poisson simple. Un modelo más complejo apropiado para esta situación es el modelo de Poisson (ZIP) con inflación cero; consulte @Mullahy, @Lambert1992 y @JSSv027i08. Aquí, hay dos conjuntos de covariables: uno para los datos de recuento y otros que afectan la probabilidad (indicada como $\\pi$) de ceros. La ecuación para la media $\\lambda$ es:\n\n$$\\lambda = 0 \\pi + (1 - \\pi) \\lambda_{nz}$$\n\ndonde\n\n\n```{=tex}\n\\begin{align}\n\\log(\\lambda_{nz}) &= \\beta_0 + \\beta_1x_1 + \\ldots + \\beta_px_p \\notag \\\\\n\\log\\left(\\frac{\\pi}{1-\\pi}\\right) &= \\gamma_0 + \\gamma_1z_1 + \\ldots + \\gamma_qz_q \\notag \n\\end{align}\n```\n\ny las covariables $x$ afectan los valores de recuento, mientras que las covariables $z$ influyen en la probabilidad de un cero. No es necesario que los dos conjuntos de predictores sean mutuamente excluyentes.\n\nAjustaremos un modelo con un conjunto completo de covariables $z$:\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inference-zip-model_18322dd55c37732a384ae508af22d888'}\n\n```{.r .cell-code}\nzero_inflated_spec <- poisson_reg() %>% set_engine(\"zeroinfl\")\n\nzero_inflated_fit <- \n  zero_inflated_spec %>% \n  fit(art ~ fem + mar + kid5 + ment | fem + mar + kid5 + phd + ment,\n      data = bioChemists)\n\nzero_inflated_fit\n## parsnip model object\n## \n## \n## Call:\n## pscl::zeroinfl(formula = art ~ fem + mar + kid5 + ment | fem + mar + kid5 + \n##     phd + ment, data = data)\n## \n## Count model coefficients (poisson with log link):\n## (Intercept)     femWomen   marMarried         kid5         ment  \n##       0.621       -0.209        0.105       -0.143        0.018  \n## \n## Zero-inflation model coefficients (binomial with logit link):\n## (Intercept)     femWomen   marMarried         kid5          phd         ment  \n##     -0.6086       0.1093      -0.3529       0.2195       0.0124      -0.1351\n```\n:::\n\n\nDado que los coeficientes de este modelo también se estiman utilizando la máxima verosimilitud, intentemos utilizar otra prueba de razón de verosimilitud para comprender si los términos del nuevo modelo son útiles. *Simultáneamente* probaremos que:\n\n\n```{=tex}\n\\begin{align}\nH_0&: \\gamma_1 = 0, \\gamma_2 = 0, \\cdots, \\gamma_5 = 0 \\notag \\\\\nH_a&: \\text{at least one } \\gamma \\ne 0  \\notag\n\\end{align}\n```\n\nProbemos ANOVA nuevamente:\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inference-zip-anova_866eb70fcbb5117398ff60bf53537c59'}\n\n```{.r .cell-code}\nanova(\n  extract_fit_engine(zero_inflated_fit),\n  extract_fit_engine(log_lin_reduced),\n  test = \"LRT\"\n) %>%\n  tidy()\n## Error in UseMethod(\"anova\"): no applicable method for 'anova' applied to an object of class \"zeroinfl\"\n```\n:::\n\n\n¡No se implementa un método `anova()` para objetos `zeroinfl`!\n\nUna alternativa es utilizar una *estadística de criterio de información*, como el criterio de información de Akaike (AIC) [@claeskens2016statistical]. Esto calcula la probabilidad logarítmica (del conjunto de entrenamiento) y penaliza ese valor según el tamaño del conjunto de entrenamiento y la cantidad de parámetros del modelo. En la parametrización de R, los valores AIC más pequeños son mejores. En este caso, no estamos realizando una prueba estadística formal sino *estimando* la capacidad de los datos para ajustarse a los datos.\n\nLos resultados indican que el modelo ZIP es preferible:\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inference-zip-aic_ba9d4fdcff8b703258aa8598ad1762fb'}\n\n```{.r .cell-code}\nzero_inflated_fit %>% extract_fit_engine() %>% AIC()\n## [1] 3232\nlog_lin_reduced   %>% extract_fit_engine() %>% AIC()\n## [1] 3312\n```\n:::\n\n\nSin embargo, es difícil contextualizar este par de valores individuales y evaluar *cuán* diferentes son en realidad. Para resolver este problema, volveremos a muestrear una gran cantidad de cada uno de estos dos modelos. A partir de estos, podemos calcular los valores AIC para cada uno y determinar con qué frecuencia los resultados favorecen el modelo ZIP. Básicamente, caracterizaremos la incertidumbre de las estadísticas del AIC para medir su diferencia en relación con el ruido en los datos.\n\nTambién calcularemos más intervalos de confianza de arranque para los parámetros en un momento, por lo que especificamos la opción `apparent = TRUE` al crear las muestras de arranque. Esto es necesario para algunos tipos de intervalos.\n\nPrimero, creamos los 4000 ajustes del modelo:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nzip_form <- art ~ fem + mar + kid5 + ment | fem + mar + kid5 + phd + ment\nglm_form <- art ~ fem + mar + kid5 + ment\n\nset.seed(2104)\nbootstrap_models <-\n  bootstraps(bioChemists, times = 2000, apparent = TRUE) %>%\n  mutate(\n    glm = map(splits, ~ fit(log_lin_spec,       glm_form, data = analysis(.x))),\n    zip = map(splits, ~ fit(zero_inflated_spec, zip_form, data = analysis(.x)))\n  )\nbootstrap_models\n## # Bootstrap sampling with apparent sample \n## # A tibble: 2,001 × 4\n##   splits            id            glm      zip     \n##   <list>            <chr>         <list>   <list>  \n## 1 <split [915/355]> Bootstrap0001 <fit[+]> <fit[+]>\n## 2 <split [915/333]> Bootstrap0002 <fit[+]> <fit[+]>\n## 3 <split [915/337]> Bootstrap0003 <fit[+]> <fit[+]>\n## 4 <split [915/344]> Bootstrap0004 <fit[+]> <fit[+]>\n## 5 <split [915/351]> Bootstrap0005 <fit[+]> <fit[+]>\n## 6 <split [915/354]> Bootstrap0006 <fit[+]> <fit[+]>\n## # ℹ 1,995 more rows\n```\n:::\n\n\nAhora podemos extraer los ajustes del modelo y sus correspondientes valores AIC:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbootstrap_models <-\n  bootstrap_models %>%\n  mutate(\n    glm_aic = map_dbl(glm, ~ extract_fit_engine(.x) %>% AIC()),\n    zip_aic = map_dbl(zip, ~ extract_fit_engine(.x) %>% AIC())\n  )\nmean(bootstrap_models$zip_aic < bootstrap_models$glm_aic)\n## [1] 1\n```\n:::\n\n\nA partir de estos resultados, parece definitivo que tener en cuenta el número excesivo de conteos de cero es una buena idea.\n\n::: rmdnote\nPodríamos haber usado `fit_resamples()` o un conjunto de flujo de trabajo para realizar estos cálculos. En esta sección, usamos `mutate()` y `map()` para calcular los modelos y demostrar cómo se pueden usar las herramientas tidymodels para modelos que no son compatibles con uno de los paquetes <span class=\"pkg\">parsnip</span>.\n:::\n\nDado que hemos calculado los ajustes del modelo remuestreado, creemos intervalos de arranque para los coeficientes del modelo de probabilidad cero (es decir, $\\gamma_j$). Podemos extraerlos con el método `tidy()` y usar la opción `type = \"zero\"` para obtener estas estimaciones:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nbootstrap_models <-\n  bootstrap_models %>%\n  mutate(zero_coefs  = map(zip, ~ tidy(.x, type = \"zero\")))\n\n# One example:\nbootstrap_models$zero_coefs[[1]]\n## # A tibble: 6 × 6\n##   term        type  estimate std.error statistic   p.value\n##   <chr>       <chr>    <dbl>     <dbl>     <dbl>     <dbl>\n## 1 (Intercept) zero   -0.128     0.497     -0.257 0.797    \n## 2 femWomen    zero   -0.0764    0.319     -0.240 0.811    \n## 3 marMarried  zero   -0.112     0.365     -0.307 0.759    \n## 4 kid5        zero    0.270     0.186      1.45  0.147    \n## 5 phd         zero   -0.178     0.132     -1.35  0.177    \n## 6 ment        zero   -0.123     0.0315    -3.91  0.0000935\n```\n:::\n\n\nEs una buena idea visualizar las distribuciones de arranque de los coeficientes, como en @fig-zip-bootstrap.\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inference-zip-bootstrap_22a1f42e2b7b466d18b74e2d9ed28b4b'}\n\n```{.r .cell-code}\nbootstrap_models %>% \n  unnest(zero_coefs) %>% \n  ggplot(aes(x = estimate)) +\n  geom_histogram(bins = 25, color = \"white\") + \n  facet_wrap(~ term, scales = \"free_x\") + \n  geom_vline(xintercept = 0, lty = 2, color = \"gray70\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/fig-zip-bootstrap_bcf43db96235624411f1ff75092530a9'}\n::: {.cell-output-display}\n![Distribuciones bootstrap de los coeficientes del modelo ZIP. Las líneas verticales indican las estimaciones observadas.](figures/fig-zip-bootstrap-1.png){#fig-zip-bootstrap fig-align='center' fig-alt='Distribuciones bootstrap de los coeficientes del modelo ZIP. Las líneas verticales indican las estimaciones observadas. El predictor de mención que parece ser importante para el modelo.' width=672}\n:::\n:::\n\n\nUna de las covariables (`ment`) que parece ser importante tiene una distribución muy sesgada. El espacio extra en algunas de las facetas indica que hay algunos valores atípicos en las estimaciones. Esto *podría* ocurrir cuando los modelos no convergieran; esos resultados probablemente deberían excluirse de las nuevas muestras. Para los resultados visualizados en @fig-zip-bootstrap, los valores atípicos se deben únicamente a estimaciones extremas de parámetros; todos los modelos convergieron.\n\nEl paquete <span class=\"pkg\">rsample</span> contiene un conjunto de funciones denominadas `int_*()` que calculan diferentes tipos de intervalos de arranque. Dado que el método `tidy()` contiene estimaciones de error estándar, se pueden calcular los intervalos bootstrap-t. También calcularemos los intervalos percentiles estándar. De forma predeterminada, se calculan intervalos de confianza del 90%.\n\n\n::: {.cell layout-align=\"center\" hash='21-inferential-analysis_cache/html/inference-zip-intervals_93b3cfd7d8eef688e9da2bb906fdee28'}\n\n```{.r .cell-code}\nbootstrap_models %>% int_pctl(zero_coefs)\n## # A tibble: 6 × 6\n##   term        .lower .estimate  .upper .alpha .method   \n##   <chr>        <dbl>     <dbl>   <dbl>  <dbl> <chr>     \n## 1 (Intercept) -1.75    -0.621   0.423    0.05 percentile\n## 2 femWomen    -0.521    0.115   0.818    0.05 percentile\n## 3 kid5        -0.327    0.218   0.677    0.05 percentile\n## 4 marMarried  -1.20    -0.381   0.362    0.05 percentile\n## 5 ment        -0.401   -0.162  -0.0513   0.05 percentile\n## 6 phd         -0.276    0.0220  0.327    0.05 percentile\nbootstrap_models %>% int_t(zero_coefs)\n## # A tibble: 6 × 6\n##   term        .lower .estimate  .upper .alpha .method  \n##   <chr>        <dbl>     <dbl>   <dbl>  <dbl> <chr>    \n## 1 (Intercept) -1.61    -0.621   0.321    0.05 student-t\n## 2 femWomen    -0.482    0.115   0.671    0.05 student-t\n## 3 kid5        -0.211    0.218   0.599    0.05 student-t\n## 4 marMarried  -0.988   -0.381   0.290    0.05 student-t\n## 5 ment        -0.324   -0.162  -0.0275   0.05 student-t\n## 6 phd         -0.274    0.0220  0.291    0.05 student-t\n```\n:::\n\n\nA partir de estos resultados, podemos tener una buena idea de qué predictores incluir en el modelo de probabilidad de conteo cero. Puede ser sensato reajustar un modelo más pequeño para evaluar si la distribución de arranque para \"ment\" todavía está sesgada.\n\n## Más Análisis Inferencial {#sec-inference-options}\n\nEste capítulo demostró solo un pequeño subconjunto de lo que está disponible para el análisis inferencial en modelos tidy y se ha centrado en los métodos frecuentistas y de remuestreo. Podría decirse que el análisis bayesiano es un enfoque de inferencia muy eficaz y, a menudo, superior. Hay una variedad de modelos bayesianos disponibles a través de <span class=\"pkg\">parsnip</span>. Además, el paquete <span class=\"pkg\">multilevelmod</span> permite a los usuarios ajustarse a modelos jerárquicos bayesianos y no bayesianos (por ejemplo, modelos mixtos). Los paquetes <span class=\"pkg\">broom.mixed</span> y <span class=\"pkg\">tidybayes</span> son excelentes herramientas para extraer datos para gráficos y resúmenes. Finalmente, para conjuntos de datos con una única jerarquía, como datos de medidas longitudinales o repetidas simples, la función `group_vfold_cv()` de <span class=\"pkg\">rsample</span> facilita caracterizaciones directas fuera de la muestra del rendimiento del modelo.\n\n## Resumen Del Capítulo {#sec-inference-summary}\n\nEl marco tidymodels sirve para algo más que el modelado predictivo. Los paquetes y funciones de tidymodels se pueden utilizar para probar hipótesis, así como para ajustar y evaluar modelos inferenciales. El marco tidymodels brinda soporte para trabajar con modelos R que no son tidymodels y puede ayudar a evaluar las cualidades estadísticas de sus modelos.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}