{
  "hash": "39e6dfd40481739d1ad109f714e83da8",
  "result": {
    "markdown": "\n\n\n# Probando Muchos Modelos {#sec-workflow-sets}\n\nPresentamos conjuntos de flujos de trabajo en el [Capítulo @sec-workflows] y demostramos cómo usarlos con conjuntos de datos remuestreados en el [Capítulo @sec-compare]. En este capítulo, analizamos estos conjuntos de múltiples flujos de trabajo de modelado con más detalle y describimos un caso de uso en el que pueden resultar útiles.\n\nPara proyectos con nuevos conjuntos de datos que aún no se han comprendido bien, es posible que un profesional de datos necesite examinar muchas combinaciones de modelos y preprocesadores. Es común tener poco o ningún conocimiento *a priori* sobre qué método funcionará mejor con un conjunto de datos novedoso.\n\n::: rmdnote\nUna buena estrategia es dedicar un esfuerzo inicial a probar una variedad de enfoques de modelado, determinar qué funciona mejor y luego invertir tiempo adicional ajustando/optimizando un pequeño conjunto de modelos.\n:::\n\nLos conjuntos de flujos de trabajo proporcionan una interfaz de usuario para crear y gestionar este proceso. También demostraremos cómo evaluar estos modelos de manera eficiente utilizando los métodos de carrera discutidos en @sec-racing-example.\n\n## Modelado De La Resistencia De Una Mezcla De Hormigón\n\nPara demostrar cómo filtrar múltiples flujos de trabajo de modelos, usaremos los datos de mezcla de concreto de *Applied Predictive Modeling* [@apm] como ejemplo. El capítulo 10 de ese libro demostró modelos para predecir la resistencia a la compresión de mezclas de concreto utilizando los ingredientes como predictores. Se evaluó una amplia variedad de modelos con diferentes conjuntos de predictores y necesidades de preprocesamiento. ¿Cómo pueden los conjuntos de flujos de trabajo facilitar este proceso de pruebas de modelos a gran escala?\n\nPrimero, definamos los esquemas de división y remuestreo de datos.\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-data_6e8c2bb8e2bcf90028ab97040120f47f'}\n\n```{.r .cell-code}\nlibrary(tidymodels)\ntidymodels_prefer()\ndata(concrete, package = \"modeldata\")\nglimpse(concrete)\n## Rows: 1,030\n## Columns: 9\n## $ cement               <dbl> 540.0, 540.0, 332.5, 332.5, 198.6, 266.0, 380.0, 380.…\n## $ blast_furnace_slag   <dbl> 0.0, 0.0, 142.5, 142.5, 132.4, 114.0, 95.0, 95.0, 114…\n## $ fly_ash              <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n## $ water                <dbl> 162, 162, 228, 228, 192, 228, 228, 228, 228, 228, 192…\n## $ superplasticizer     <dbl> 2.5, 2.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0…\n## $ coarse_aggregate     <dbl> 1040.0, 1055.0, 932.0, 932.0, 978.4, 932.0, 932.0, 93…\n## $ fine_aggregate       <dbl> 676.0, 676.0, 594.0, 594.0, 825.5, 670.0, 594.0, 594.…\n## $ age                  <int> 28, 28, 270, 365, 360, 90, 365, 28, 28, 28, 90, 28, 2…\n## $ compressive_strength <dbl> 79.99, 61.89, 40.27, 41.05, 44.30, 47.03, 43.70, 36.4…\n```\n:::\n\n\nLa columna `compression_strength` es el resultado. El predictor de \"edad\" nos dice la edad de la muestra de concreto en la prueba en días (el concreto se fortalece con el tiempo) y el resto de los predictores como \"cemento\" y \"agua\" son componentes de concreto en unidades de kilogramos por metro cúbico.\n\n::: rmdwarning\nEn algunos casos de este conjunto de datos, la misma fórmula concreta se probó varias veces. Preferimos no incluir estas mezclas replicadas como puntos de datos individuales, ya que podrían distribuirse tanto en el conjunto de entrenamiento como en el de prueba. Hacerlo podría inflar artificialmente nuestras estimaciones de desempeño.\n:::\n\nPara abordar esto, utilizaremos la resistencia a la compresión media por mezcla de concreto para modelar:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-means_3c1aca3c965cf4d80562e29c3084b5ce'}\n\n```{.r .cell-code}\nconcrete <- \n   concrete %>% \n   group_by(across(-compressive_strength)) %>% \n   summarize(compressive_strength = mean(compressive_strength),\n             .groups = \"drop\")\nnrow(concrete)\n## [1] 992\n```\n:::\n\n\nDividamos los datos usando la proporción predeterminada de 3:1 de entrenamiento a prueba y volvamos a muestrear el conjunto de entrenamiento usando cinco repeticiones de validación cruzada de 10 veces:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-splitting_58ef28139ed618d56002989dc7f66ea6'}\n\n```{.r .cell-code}\nset.seed(1501)\nconcrete_split <- initial_split(concrete, strata = compressive_strength)\nconcrete_train <- training(concrete_split)\nconcrete_test  <- testing(concrete_split)\n\nset.seed(1502)\nconcrete_folds <- \n   vfold_cv(concrete_train, strata = compressive_strength, repeats = 5)\n```\n:::\n\n\nAlgunos modelos (en particular, redes neuronales, KNN y máquinas de vectores de soporte) requieren predictores centrados y escalados, por lo que algunos flujos de trabajo de modelos requerirán recetas con estos pasos de preprocesamiento. Para otros modelos, una expansión del modelo de diseño de superficie de respuesta tradicional (es decir, interacciones cuadráticas y bidireccionales) es una buena idea. Para estos fines, creamos dos recetas:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-recipes_8cef633806e92e9ddff4e1eeaf6dfa52'}\n\n```{.r .cell-code}\nnormalized_rec <- \n   recipe(compressive_strength ~ ., data = concrete_train) %>% \n   step_normalize(all_predictors()) \n\npoly_recipe <- \n   normalized_rec %>% \n   step_poly(all_predictors()) %>% \n   step_interact(~ all_predictors():all_predictors())\n```\n:::\n\n\nPara los modelos, utilizamos el complemento <span class=\"pkg\">parsnip</span> para crear un conjunto de especificaciones de modelo:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-models_6b7387e44993d520c75efbf1dc6d553e'}\n\n```{.r .cell-code}\nlibrary(rules)\nlibrary(baguette)\n\nlinear_reg_spec <- \n   linear_reg(penalty = tune(), mixture = tune()) %>% \n   set_engine(\"glmnet\")\n\nnnet_spec <- \n   mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% \n   set_engine(\"nnet\", MaxNWts = 2600) %>% \n   set_mode(\"regression\")\n\nmars_spec <- \n   mars(prod_degree = tune()) %>%  #<- use GCV to choose terms\n   set_engine(\"earth\") %>% \n   set_mode(\"regression\")\n\nsvm_r_spec <- \n   svm_rbf(cost = tune(), rbf_sigma = tune()) %>% \n   set_engine(\"kernlab\") %>% \n   set_mode(\"regression\")\n\nsvm_p_spec <- \n   svm_poly(cost = tune(), degree = tune()) %>% \n   set_engine(\"kernlab\") %>% \n   set_mode(\"regression\")\n\nknn_spec <- \n   nearest_neighbor(neighbors = tune(), dist_power = tune(), weight_func = tune()) %>% \n   set_engine(\"kknn\") %>% \n   set_mode(\"regression\")\n\ncart_spec <- \n   decision_tree(cost_complexity = tune(), min_n = tune()) %>% \n   set_engine(\"rpart\") %>% \n   set_mode(\"regression\")\n\nbag_cart_spec <- \n   bag_tree() %>% \n   set_engine(\"rpart\", times = 50L) %>% \n   set_mode(\"regression\")\n\nrf_spec <- \n   rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>% \n   set_engine(\"ranger\") %>% \n   set_mode(\"regression\")\n\nxgb_spec <- \n   boost_tree(tree_depth = tune(), learn_rate = tune(), loss_reduction = tune(), \n              min_n = tune(), sample_size = tune(), trees = tune()) %>% \n   set_engine(\"xgboost\") %>% \n   set_mode(\"regression\")\n\ncubist_spec <- \n   cubist_rules(committees = tune(), neighbors = tune()) %>% \n   set_engine(\"Cubist\") \n```\n:::\n\n\nEl análisis en @apm especifica que la red neuronal debe tener hasta 27 unidades ocultas en la capa. La función `extract_parameter_set_dials()` extrae el conjunto de parámetros, que modificamos para tener el rango de parámetros correcto:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-param_1e9634f7232e38f0d2de9dbae8221be1'}\n\n```{.r .cell-code}\nnnet_param <- \n   nnet_spec %>% \n   extract_parameter_set_dials() %>% \n   update(hidden_units = hidden_units(c(1, 27)))\n```\n:::\n\n\n¿Cómo podemos hacer coincidir estos modelos con sus recetas, ajustarlos y luego evaluar su desempeño de manera eficiente? Un conjunto de flujo de trabajo ofrece una solución.\n\n## Crear El Conjunto De Flujo De Trabajo\n\nLos conjuntos de flujos de trabajo toman listas con nombres de preprocesadores y especificaciones de modelos y las combinan en un objeto que contiene múltiples flujos de trabajo. Hay tres tipos posibles de preprocesadores:\n\n-   Una fórmula R estándar\n-   Un objeto de receta (antes de la estimación/preparación)\n-   Un selector estilo <span class=\"pkg\">dplyr</span> para elegir el resultado y los predictores.\n\nComo primer ejemplo de conjunto de flujo de trabajo, combinemos la receta que solo estandariza los predictores con los modelos no lineales que requieren que los predictores estén en las mismas unidades:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-normalized_06860c4461b46ff1bfca197a1334355a'}\n\n```{.r .cell-code}\nnormalized <- \n   workflow_set(\n      preproc = list(normalized = normalized_rec), \n      models = list(SVM_radial = svm_r_spec, SVM_poly = svm_p_spec, \n                    KNN = knn_spec, neural_network = nnet_spec)\n   )\nnormalized\n## # A workflow set/tibble: 4 × 4\n##   wflow_id                  info             option    result    \n##   <chr>                     <list>           <list>    <list>    \n## 1 normalized_SVM_radial     <tibble [1 × 4]> <opts[0]> <list [0]>\n## 2 normalized_SVM_poly       <tibble [1 × 4]> <opts[0]> <list [0]>\n## 3 normalized_KNN            <tibble [1 × 4]> <opts[0]> <list [0]>\n## 4 normalized_neural_network <tibble [1 × 4]> <opts[0]> <list [0]>\n```\n:::\n\n\nDado que solo hay un preprocesador, esta función crea un conjunto de flujos de trabajo con este valor. Si el preprocesador contuviera más de una entrada, la función crearía todas las combinaciones de preprocesadores y modelos.\n\nLa columna `wflow_id` se crea automáticamente pero se puede modificar usando una llamada a `mutate()`. La columna `info` contiene un tibble con algunos identificadores y el objeto de flujo de trabajo. El flujo de trabajo se puede extraer:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-get-workflow_b1fecf24ac800679789bd71b923fdcb2'}\n\n```{.r .cell-code}\nnormalized %>% extract_workflow(id = \"normalized_KNN\")\n## ══ Workflow ═════════════════════════════════════════════════════════════════════════\n## Preprocessor: Recipe\n## Model: nearest_neighbor()\n## \n## ── Preprocessor ─────────────────────────────────────────────────────────────────────\n## 1 Recipe Step\n## \n## • step_normalize()\n## \n## ── Model ────────────────────────────────────────────────────────────────────────────\n## K-Nearest Neighbor Model Specification (regression)\n## \n## Main Arguments:\n##   neighbors = tune()\n##   weight_func = tune()\n##   dist_power = tune()\n## \n## Computational engine: kknn\n```\n:::\n\n\nLa columna `option` es un marcador de posición para cualquier argumento que se utilice cuando evaluamos el flujo de trabajo. Por ejemplo, para agregar el objeto de parámetro de red neuronal:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-info-update_c4d77fdaf21b4d3d8707f6f4de4891ad'}\n\n```{.r .cell-code}\nnormalized <- \n   normalized %>% \n   option_add(param_info = nnet_param, id = \"normalized_neural_network\")\nnormalized\n## # A workflow set/tibble: 4 × 4\n##   wflow_id                  info             option    result    \n##   <chr>                     <list>           <list>    <list>    \n## 1 normalized_SVM_radial     <tibble [1 × 4]> <opts[0]> <list [0]>\n## 2 normalized_SVM_poly       <tibble [1 × 4]> <opts[0]> <list [0]>\n## 3 normalized_KNN            <tibble [1 × 4]> <opts[0]> <list [0]>\n## 4 normalized_neural_network <tibble [1 × 4]> <opts[1]> <list [0]>\n```\n:::\n\n\nCuando se usa una función del paquete <span class=\"pkg\">tune</span> o <span class=\"pkg\">finetune</span> para ajustar (o volver a muestrear) el flujo de trabajo, se usará este argumento.\n\nLa columna `result` es un marcador de posición para la salida de las funciones de ajuste o remuestreo.\n\nPara los otros modelos no lineales, creemos otro conjunto de flujo de trabajo que use selectores <span class=\"pkg\">dplyr</span> para el resultado y los predictores:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-selectors_4bf354c3ab12574c7b3b5bd977cdec36'}\n\n```{.r .cell-code}\nmodel_vars <- \n   workflow_variables(outcomes = compressive_strength, \n                      predictors = everything())\n\nno_pre_proc <- \n   workflow_set(\n      preproc = list(simple = model_vars), \n      models = list(MARS = mars_spec, CART = cart_spec, CART_bagged = bag_cart_spec,\n                    RF = rf_spec, boosting = xgb_spec, Cubist = cubist_spec)\n   )\nno_pre_proc\n## # A workflow set/tibble: 6 × 4\n##   wflow_id           info             option    result    \n##   <chr>              <list>           <list>    <list>    \n## 1 simple_MARS        <tibble [1 × 4]> <opts[0]> <list [0]>\n## 2 simple_CART        <tibble [1 × 4]> <opts[0]> <list [0]>\n## 3 simple_CART_bagged <tibble [1 × 4]> <opts[0]> <list [0]>\n## 4 simple_RF          <tibble [1 × 4]> <opts[0]> <list [0]>\n## 5 simple_boosting    <tibble [1 × 4]> <opts[0]> <list [0]>\n## 6 simple_Cubist      <tibble [1 × 4]> <opts[0]> <list [0]>\n```\n:::\n\n\nFinalmente, ensamblamos el conjunto que utiliza términos no lineales e interacciones con los modelos apropiados:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-quad_6e413524df73d4d1d85a4f1fb00cfb33'}\n\n```{.r .cell-code}\nwith_features <- \n   workflow_set(\n      preproc = list(full_quad = poly_recipe), \n      models = list(linear_reg = linear_reg_spec, KNN = knn_spec)\n   )\n```\n:::\n\n\nEstos objetos son tibbles con la clase adicional `workflow_set`. La vinculación de filas no afecta el estado de los conjuntos y el resultado es en sí mismo un conjunto de flujo de trabajo:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-complete_f3c6eba40f17cf4d8e27def3e6f8e414'}\n\n```{.r .cell-code}\nall_workflows <- \n   bind_rows(no_pre_proc, normalized, with_features) %>% \n   # Haga que los ID del flujo de trabajo sean un poco más simples:\n   mutate(wflow_id = gsub(\"(simple_)|(normalized_)\", \"\", wflow_id))\nall_workflows\n## # A workflow set/tibble: 12 × 4\n##   wflow_id    info             option    result    \n##   <chr>       <list>           <list>    <list>    \n## 1 MARS        <tibble [1 × 4]> <opts[0]> <list [0]>\n## 2 CART        <tibble [1 × 4]> <opts[0]> <list [0]>\n## 3 CART_bagged <tibble [1 × 4]> <opts[0]> <list [0]>\n## 4 RF          <tibble [1 × 4]> <opts[0]> <list [0]>\n## 5 boosting    <tibble [1 × 4]> <opts[0]> <list [0]>\n## 6 Cubist      <tibble [1 × 4]> <opts[0]> <list [0]>\n## # ℹ 6 more rows\n```\n:::\n\n\n## Ajuste Y Evaluación De Los Modelos\n\nCasi todos los miembros de `all_workflows` contienen parámetros de ajuste. Para evaluar su rendimiento, podemos utilizar las funciones estándar de ajuste o remuestreo (por ejemplo, `tune_grid()`, etc.). La función `workflow_map()` aplicará la misma función a todos los flujos de trabajo del conjunto; el valor predeterminado es `tune_grid()`.\n\nPara este ejemplo, la búsqueda de cuadrícula se aplica a cada flujo de trabajo utilizando hasta 25 candidatos de parámetros diferentes. Hay un conjunto de opciones comunes para usar con cada ejecución de `tune_grid()`. Por ejemplo, en el siguiente código usaremos los mismos objetos de remuestreo y control para cada flujo de trabajo, junto con un tamaño de cuadrícula de 25. La función `workflow_map()` tiene un argumento adicional llamado `seed`, que se usa para garantizar que cada ejecución de `tune_grid()` consume los mismos números aleatorios.\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-grid_1463da9d37a0bc638fc9e71676fbb8f5'}\n\n```{.r .cell-code}\ngrid_ctrl <-\n   control_grid(\n      save_pred = TRUE,\n      parallel_over = \"everything\",\n      save_workflow = TRUE\n   )\n\ngrid_results <-\n   all_workflows %>%\n   workflow_map(\n      seed = 1503,\n      resamples = concrete_folds,\n      grid = 25,\n      control = grid_ctrl\n   )\n```\n:::\n\n\n\n\nLos resultados muestran que las columnas `option` y `result` se han actualizado:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-grid-print_858b8016a716dab7bef83f5147391948'}\n\n```{.r .cell-code}\ngrid_results\n## # A workflow set/tibble: 12 × 4\n##   wflow_id    info             option    result   \n##   <chr>       <list>           <list>    <list>   \n## 1 MARS        <tibble [1 × 4]> <opts[3]> <tune[+]>\n## 2 CART        <tibble [1 × 4]> <opts[3]> <tune[+]>\n## 3 CART_bagged <tibble [1 × 4]> <opts[3]> <rsmp[+]>\n## 4 RF          <tibble [1 × 4]> <opts[3]> <tune[+]>\n## 5 boosting    <tibble [1 × 4]> <opts[3]> <tune[+]>\n## 6 Cubist      <tibble [1 × 4]> <opts[3]> <tune[+]>\n## # ℹ 6 more rows\n```\n:::\n\n\nLa columna `option` ahora contiene todas las opciones que usamos en la llamada `workflow_map()`. Esto hace que nuestros resultados sean reproducibles. En las columnas `result`, las notaciones \"`tune[+]`\" y \"`rsmp[+]`\" significan que el objeto no tuvo problemas. Un valor como \"`tune[x]`\" ocurre si todos los modelos fallaron por algún motivo.\n\nHay algunas funciones convenientes para examinar resultados, como `grid_results`. La función `rank_results()` ordenará los modelos según alguna métrica de rendimiento. De forma predeterminada, utiliza la primera métrica del conjunto de métricas (RMSE en este caso). Vamos a `filter()` para mirar solo RMSE:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-rank_f8695ac223074f99efeb85965190d1f0'}\n\n```{.r .cell-code}\ngrid_results %>% \n   rank_results() %>% \n   filter(.metric == \"rmse\") %>% \n   select(model, .config, rmse = mean, rank)\n## # A tibble: 252 × 4\n##   model      .config                rmse  rank\n##   <chr>      <chr>                 <dbl> <int>\n## 1 boost_tree Preprocessor1_Model04  4.25     1\n## 2 boost_tree Preprocessor1_Model06  4.29     2\n## 3 boost_tree Preprocessor1_Model13  4.31     3\n## 4 boost_tree Preprocessor1_Model14  4.39     4\n## 5 boost_tree Preprocessor1_Model16  4.46     5\n## 6 boost_tree Preprocessor1_Model03  4.47     6\n## # ℹ 246 more rows\n```\n:::\n\n\nAdemás, de forma predeterminada, la función clasifica todos los conjuntos de candidatos; es por eso que el mismo modelo puede aparecer varias veces en el resultado. Se puede utilizar una opción, llamada `select_best`, para clasificar los modelos utilizando su mejor combinación de parámetros de ajuste.\n\nEl método `autoplot()` traza las clasificaciones; también tiene un argumento `select_best`. El gráfico en @fig-workflow-set-ranks visualiza los mejores resultados para cada modelo y se genera con:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-plot-rank_89d34a055cc0c8fbb571a7e309023368'}\n\n```{.r .cell-code}\nautoplot(\n   grid_results,\n   rank_metric = \"rmse\",  # <- cómo pedir modelos\n   metric = \"rmse\",       # <- qué métrica visualizar\n   select_best = TRUE     # <- un punto por flujo de trabajo\n) +\n   geom_text(aes(y = mean - 1/2, label = wflow_id), angle = 90, hjust = 1) +\n   lims(y = c(3.5, 9.5)) +\n   theme(legend.position = \"none\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/fig-workflow-set-ranks_ca853e984204899f5bf30c2ae1229c45'}\n::: {.cell-output-display}\n![RMSE estimado (e intervalos de confianza aproximados) para la mejor configuración del modelo en cada flujo de trabajo.](15-workflow-sets_files/figure-html/fig-workflow-set-ranks-1.png){#fig-workflow-set-ranks fig-align='center' fig-alt='RMSE estimado (e intervalos de confianza aproximados) para la mejor configuración del modelo en cada flujo de trabajo. El eje y es el RMSE estimado y el eje x es el rango del modelo basado en RMSE. Las reglas cubistas y los árboles potenciados muestran los valores RMSE más pequeños. ' width=100%}\n:::\n:::\n\n\nEn caso de que desee ver los resultados de los parámetros de ajuste para un modelo específico, como @fig-workflow-sets-autoplot, el argumento `id` puede tomar un único valor de la columna `wflow_id` para qué modelo trazar:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-plot-model_bdbc1f6081f5c2e0d78a1cff127fbe5c'}\n\n```{.r .cell-code}\nautoplot(grid_results, id = \"Cubist\", metric = \"rmse\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/fig-workflow-sets-autoplot_3cbe36933b78e2d86338512e5ab436fb'}\n::: {.cell-output-display}\n![Los resultados `autoplot()` para el modelo cubista contenido en el conjunto de flujo de trabajo.](15-workflow-sets_files/figure-html/fig-workflow-sets-autoplot-1.png){#fig-workflow-sets-autoplot fig-align='center' fig-alt='Los resultados `autoplot()` para el modelo cubista contenido en el conjunto de flujo de trabajo. La visualización tiene un panel para cada parámetro de ajuste y muestra el rendimiento frente a los valores de los parámetros.' width=100%}\n:::\n:::\n\n\nTambién hay métodos para `collect_predictions()` y `collect_metrics()`.\n\nLa selección del modelo de ejemplo con nuestros datos de mezcla de concreto se ajusta a un total de modelos 12,600. Utilizando trabajadores de 4 en paralelo, el proceso de estimación tardó 8.9 horas en completarse.\n\n## Modelos De Detección Eficiente {#sec-racing-example}\n\nUn método eficaz para seleccionar un gran conjunto de modelos de manera eficiente es utilizar el enfoque de carreras descrito en @sec-racing. Con un flujo de trabajo configurado, podemos usar la función `workflow_map()` para este enfoque de carrera. Recuerde que después de canalizar nuestro conjunto de flujos de trabajo, el argumento que usamos es la función que se aplicará a los flujos de trabajo; en este caso, podemos usar un valor de `\"tune_race_anova\"`. También pasamos un objeto de control apropiado; de lo contrario, las opciones serían las mismas que el código de la sección anterior.\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-race_d07246ba74b52713e1ac99c1d0ae2f9f'}\n\n```{.r .cell-code}\nlibrary(finetune)\n\nrace_ctrl <-\n   control_race(\n      save_pred = TRUE,\n      parallel_over = \"everything\",\n      save_workflow = TRUE\n   )\n\nrace_results <-\n   all_workflows %>%\n   workflow_map(\n      \"tune_race_anova\",\n      seed = 1503,\n      resamples = concrete_folds,\n      grid = 25,\n      control = race_ctrl\n   )\n```\n:::\n\n\n\n\nEl nuevo objeto se ve muy similar, aunque los elementos de la columna `resultado` muestran un valor de `\"race[+]\"`, lo que indica un tipo diferente de objeto:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-race-print_a858c9b8fdb1c50f6a56acf6432e95af'}\n\n```{.r .cell-code}\nrace_results\n## # A workflow set/tibble: 12 × 4\n##   wflow_id    info             option    result   \n##   <chr>       <list>           <list>    <list>   \n## 1 MARS        <tibble [1 × 4]> <opts[3]> <race[+]>\n## 2 CART        <tibble [1 × 4]> <opts[3]> <race[+]>\n## 3 CART_bagged <tibble [1 × 4]> <opts[3]> <rsmp[+]>\n## 4 RF          <tibble [1 × 4]> <opts[3]> <race[+]>\n## 5 boosting    <tibble [1 × 4]> <opts[3]> <race[+]>\n## 6 Cubist      <tibble [1 × 4]> <opts[3]> <race[+]>\n## # ℹ 6 more rows\n```\n:::\n\n\nLas mismas funciones útiles están disponibles para este objeto para interrogar los resultados y, de hecho, el método básico `autoplot()` que se muestra en @fig-workflow-set-racing-ranks[^15-workflow-sets-1] produce tendencias. similar a @fig-workflow-set-ranks. Esto es producido por:\n\n[^15-workflow-sets-1]: A partir de febrero de 2022, vemos métricas de rendimiento ligeramente diferentes para la red neuronal cuando se entrena con macOS en arquitectura ARM (chip Apple M1) en comparación con la arquitectura Intel.\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-plot-race-rank_14bb48ce1c012b91f903839b53fefc42'}\n\n```{.r .cell-code}\nautoplot(\n   race_results,\n   rank_metric = \"rmse\",  \n   metric = \"rmse\",       \n   select_best = TRUE    \n) +\n   geom_text(aes(y = mean - 1/2, label = wflow_id), angle = 90, hjust = 1) +\n   lims(y = c(3.0, 9.5)) +\n   theme(legend.position = \"none\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/fig-workflow-set-racing-ranks_5f60189a424cf299b427a83ae48dea0d'}\n::: {.cell-output-display}\n![RMSE estimado (e intervalos de confianza aproximados) para la mejor configuración del modelo en cada flujo de trabajo en los resultados de las carreras.](15-workflow-sets_files/figure-html/fig-workflow-set-racing-ranks-1.png){#fig-workflow-set-racing-ranks fig-align='center' fig-alt='RMSE estimado (e intervalos de confianza aproximados) para la mejor configuración del modelo en cada flujo de trabajo en los resultados de las carreras. El eje y es el RMSE estimado y el eje x es el rango del modelo basado en RMSE. Las reglas cubistas y los árboles potenciados muestran los valores RMSE más pequeños.' width=100%}\n:::\n:::\n\n\nEn general, el enfoque de carreras estimó un total de 900 modelos, 7.14% del conjunto completo de 12,600 modelos en la cuadrícula completa. Como resultado, el enfoque de carrera fue 7-veces más rápido.\n\n¿Obtuvimos resultados similares? Para ambos objetos, clasificamos los resultados, los fusionamos y los comparamos entre sí en @fig-racing-concordance.\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-racing-concordance_ea8bfe8971d33104053d22c6302e5db9'}\n\n```{.r .cell-code}\nmatched_results <- \n   rank_results(race_results, select_best = TRUE) %>% \n   select(wflow_id, .metric, race = mean, config_race = .config) %>% \n   inner_join(\n      rank_results(grid_results, select_best = TRUE) %>% \n         select(wflow_id, .metric, complete = mean, \n                config_complete = .config, model),\n      by = c(\"wflow_id\", \".metric\"),\n   ) %>%  \n   filter(.metric == \"rmse\")\n\nlibrary(ggrepel)\n\nmatched_results %>% \n   ggplot(aes(x = complete, y = race)) + \n   geom_abline(lty = 3) + \n   geom_point() + \n   geom_text_repel(aes(label = model)) +\n   coord_obs_pred() + \n   labs(x = \"Cuadrícula completa RMSE\", y = \"Carreras RMSE\") \n```\n:::\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/fig-racing-concordance_7cc99e9d4e638f29e8fa049634f7049c'}\n::: {.cell-output-display}\n![RMSE estimado para la cuadrícula completa y los resultados de las carreras.](15-workflow-sets_files/figure-html/fig-racing-concordance-1.png){#fig-racing-concordance fig-align='center' fig-alt='RMSE estimado para la cuadrícula completa y los resultados de las carreras. Los resultados muestran que muchos modelos tienen el mismo resultado RMSE y los demás son muy similares.' width=100%}\n:::\n:::\n\n\nSi bien el enfoque de carreras seleccionó los mismos parámetros candidatos que la cuadrícula completa solo para 33.33% de los modelos, las métricas de rendimiento de los modelos seleccionados por las carreras eran casi iguales. La correlación de los valores RMSE fue 0.965 y la correlación de rango fue 0.951. Esto indica que, dentro de un modelo, había múltiples combinaciones de parámetros de ajuste que tenían resultados casi idénticos.\n\n## Finalizando Un Modelo\n\nDe manera similar a lo que hemos mostrado en capítulos anteriores, el proceso de elegir el modelo final y ajustarlo al conjunto de entrenamiento es sencillo. El primer paso es elegir un flujo de trabajo para finalizar. Dado que el modelo de árbol mejorado funcionó bien, lo extraeremos del conjunto, actualizaremos los parámetros con la mejor configuración numérica y lo ajustaremos al conjunto de entrenamiento:\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-finalize_7b22c3891306158c9673aa7c53482ba8'}\n\n```{.r .cell-code}\nbest_results <- \n   race_results %>% \n   extract_workflow_set_result(\"boosting\") %>% \n   select_best(metric = \"rmse\")\nbest_results\n## # A tibble: 1 × 7\n##   trees min_n tree_depth learn_rate loss_reduction sample_size .config              \n##   <int> <int>      <int>      <dbl>          <dbl>       <dbl> <chr>                \n## 1  1800    25          4      0.109       9.84e-10       0.850 Preprocessor1_Model16\n\nboosting_test_results <- \n   race_results %>% \n   extract_workflow(\"boosting\") %>% \n   finalize_workflow(best_results) %>% \n   last_fit(split = concrete_split)\n```\n:::\n\n\nPodemos ver los resultados de las métricas del conjunto de pruebas y visualizar las predicciones en @fig-concrete-test-results.\n\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-collect-test-metrics_87be896f8cfb521c0c90733a54be7183'}\n\n```{.r .cell-code}\ncollect_metrics(boosting_test_results)\n## # A tibble: 2 × 4\n##   .metric .estimator .estimate .config             \n##   <chr>   <chr>          <dbl> <chr>               \n## 1 rmse    standard       3.46  Preprocessor1_Model1\n## 2 rsq     standard       0.953 Preprocessor1_Model1\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/workflow-sets-test-results_71e4ed289ddc5658609ce5cc9b0ca218'}\n\n```{.r .cell-code}\nboosting_test_results %>% \n   collect_predictions() %>% \n   ggplot(aes(x = compressive_strength, y = .pred)) + \n   geom_abline(color = \"gray50\", lty = 2) + \n   geom_point(alpha = 0.5) + \n   coord_obs_pred() + \n   labs(x = \"observados\", y = \"predichos\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='15-workflow-sets_cache/html/fig-concrete-test-results_1db442a92258006ba99c50f84a306201'}\n::: {.cell-output-display}\n![Valores observados versus valores predichos para el conjunto de prueba.](15-workflow-sets_files/figure-html/fig-concrete-test-results-1.png){#fig-concrete-test-results fig-align='center' fig-alt='Valores observados versus valores predichos para el conjunto de prueba. Los valores caen estrechamente a lo largo de la línea de identidad de 45 grados.' width=100%}\n:::\n:::\n\n\nAquí vemos qué tan bien se alinean la resistencia a la compresión observada y prevista para estas mezclas de concreto.\n\n## Resumen Del Capítulo {#sec-workflow-sets-summary}\n\nA menudo, un profesional de datos necesita considerar una gran cantidad de posibles enfoques de modelado para una tarea en cuestión, especialmente para nuevos conjuntos de datos y/o cuando hay poco conocimiento sobre qué estrategia de modelado funcionará mejor. Este capítulo ilustró cómo utilizar conjuntos de flujos de trabajo para investigar múltiples modelos o estrategias de ingeniería de características en tal situación. Los métodos de carrera pueden clasificar los modelos de manera más eficiente que ajustar cada modelo candidato que se esté considerando.\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}