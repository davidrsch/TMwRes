{
  "hash": "307baab54d9dc3fdbfa9b17ccf6b04e1",
  "result": {
    "markdown": "\n\n\n# Reducción de Dimensionalidad {#sec-dimensionality}\n\nLa reducción de dimensionalidad transforma un conjunto de datos de un espacio de alta dimensión a un espacio de baja dimensión y puede ser una buena opción cuando se sospecha que hay \"demasiadas\" variables. Un exceso de variables, normalmente predictores, puede ser un problema porque resulta difícil comprender o visualizar datos en dimensiones superiores.\n\n## ¿Qué problemas puede resolver la reducción de dimensionalidad?\n\nLa reducción de dimensionalidad se puede utilizar en ingeniería de características o en análisis de datos exploratorios. Por ejemplo, en experimentos de biología de alta dimensión, una de las primeras tareas, antes de cualquier modelado, es determinar si hay tendencias no deseadas en los datos (por ejemplo, efectos no relacionados con la cuestión de interés, como la transferencia de laboratorio a laboratorio). diferencias de laboratorio). Depurar los datos es difícil cuando hay cientos de miles de dimensiones y la reducción de la dimensionalidad puede ser una ayuda para el análisis exploratorio de datos.\n\nOtra posible consecuencia de tener una multitud de predictores es el posible daño a un modelo. El ejemplo más simple es un método como la regresión lineal ordinaria donde la cantidad de predictores debe ser menor que la cantidad de puntos de datos utilizados para ajustar el modelo. Otro problema es la multicolinealidad, donde las correlaciones entre predictores pueden afectar negativamente las operaciones matemáticas utilizadas para estimar un modelo. Si hay un número extremadamente grande de predictores, es bastante improbable que haya un número igual de efectos subyacentes reales. Los predictores pueden estar midiendo los mismos efectos latentes y, por lo tanto, dichos predictores estarán altamente correlacionados. Muchas técnicas de reducción de dimensionalidad prosperan en esta situación. De hecho, la mayoría puede ser eficaz sólo cuando existen relaciones entre predictores que puedan explotarse.\n\n::: rmdnote\nAl iniciar un nuevo proyecto de modelado, reducir las dimensiones de los datos puede proporcionar cierta intuición sobre cuán difícil puede ser el problema de modelado.\n:::\n\nEl análisis de componentes principales (PCA) es uno de los métodos más sencillos para reducir el número de columnas en el conjunto de datos porque se basa en métodos lineales y no está supervisado (es decir, no considera los datos de resultados). Para un problema de clasificación de alta dimensión, un gráfico inicial de los componentes principales del PCA podría mostrar una separación clara entre las clases. Si este es el caso, entonces es bastante seguro asumir que un clasificador lineal podría hacer un buen trabajo. Sin embargo, lo contrario no es cierto; la falta de separación no significa que el problema sea insuperable.\n\nLos métodos de reducción de dimensionalidad discutidos en este capítulo generalmente *no* son métodos de selección de características. Los métodos como PCA representan los predictores originales utilizando un subconjunto más pequeño de características nuevas. Se requieren todos los predictores originales para calcular estas nuevas características. La excepción a esto son los métodos escasos que tienen la capacidad de eliminar por completo el impacto de los predictores al crear nuevas funciones.\n\n::: rmdnote\nEste capítulo tiene dos objetivos:\n\n-   Demuestre cómo utilizar recetas para crear un pequeño conjunto de funciones que capturen los aspectos principales del conjunto de predictores original.\n\n-   Describir cómo se pueden usar las recetas por sí solas (en lugar de usarse en un objeto de flujo de trabajo, como en @sec-using-recipes).\n:::\n\nEsto último resulta útil a la hora de probar o depurar una receta. Sin embargo, como se describe en @sec-using-recipes, la mejor manera de utilizar una receta para modelar es desde un objeto de flujo de trabajo.\n\nAdemás del paquete <span class=\"pkg\">tidymodels</span>, este capítulo utiliza los siguientes paquetes: <span class=\"pkg\">baguette</span>, <span class=\"pkg\">beans</span>, <span class=\"pkg\">bestNormalize</span>, <span class=\"pkg\">corrplot</span>, <span class=\"pkg\">discrim</span>, <span class=\"pkg\">embed</span>, <span class=\"pkg\">ggforce</span>, <span class=\"pkg\">klaR</span>, <span class=\"pkg\">learntidymodels</span>,[^16-dimensionality-reduction-1] <span class=\"pkg\">mixOmics</span>,[^16-dimensionality-reduction-2] y <span class=\"pkg\">uwot</span>.\n\n[^16-dimensionality-reduction-1]: El paquete <span class=\"pkg\">learntidymodels</span> se puede encontrar en su sitio de GitHub: <https://github.com/tidymodels/learntidymodels>\n\n[^16-dimensionality-reduction-2]: El paquete <span class=\"pkg\">mixOmics</span> no está disponible en CRAN, sino en Bioconductor: <https://doi.org/doi:10.18129/B9.bioc.mixOmics>\n\n## Una imagen vale más que mil... Frijoles {#sec-beans}\n\nVeamos cómo usar la reducción de dimensionalidad con <span class=\"pkg\">recipes</span> para ver un conjunto de datos de ejemplo. @beans publicó un conjunto de datos de características visuales de los frijoles secos y describió métodos para determinar las variedades de frijoles secos en una imagen. Si bien la dimensionalidad de estos datos no es muy grande en comparación con muchos problemas de modelado del mundo real, proporciona un buen ejemplo práctico para demostrar cómo reducir la cantidad de funciones. De su manuscrito:\n\n> El objetivo principal de este estudio es proporcionar un método para la obtención de variedades de semillas uniformes a partir de la producción de cultivos, la cual es en forma de población, por lo que las semillas no están certificadas como una única variedad. Así, se desarrolló un sistema de visión por computadora para distinguir siete variedades diferentes registradas de frijol seco con características similares con el fin de obtener una clasificación uniforme de las semillas. Para el modelo de clasificación se tomaron imágenes de 13.611 granos de 7 diferentes frijoles secos registrados con una cámara de alta resolución.\n\nCada imagen contiene varios beans. El proceso de determinar qué píxeles corresponden a un frijol en particular se llama *segmentación de imágenes*. Estos píxeles se pueden analizar para producir características para cada frijol, como el color y la morfología (es decir, la forma). Estas características se utilizan luego para modelar el resultado (variedad de frijol) porque las diferentes variedades de frijol se ven diferentes. Los datos de entrenamiento provienen de un conjunto de imágenes etiquetadas manualmente, y este conjunto de datos se utiliza para crear un modelo predictivo que puede distinguir entre siete variedades de frijol: Cali, Horoz, Dermason, Seker, Bombay, Barbunya y Sira. Producir un modelo eficaz puede ayudar a los fabricantes a cuantificar la homogeneidad de un lote de granos.\n\nExisten numerosos métodos para cuantificar las formas de los objetos [@Mingqiang08]. Muchos están relacionados con los límites o regiones del objeto de interés. Ejemplos de características incluyen:\n\n-   El *área* (o tamaño) se puede estimar utilizando el número de píxeles del objeto o el tamaño del casco convexo alrededor del objeto.\n\n-   Podemos medir el *perímetro* usando el número de píxeles en el límite así como el área del cuadro delimitador (el rectángulo más pequeño que encierra un objeto).\n\n-   El *eje mayor* cuantifica la línea más larga que conecta las partes más extremas del objeto. El *eje menor* es perpendicular al eje mayor.\n\n-   Podemos medir la *compacidad* de un objeto usando la relación entre el área del objeto y el área de un círculo con el mismo perímetro. Por ejemplo, los símbolos \"•\" y \"×\" tienen compacidades muy diferentes.\n\n-   También existen diferentes medidas de qué tan *alargado* u oblongo es un objeto. Por ejemplo, la estadística de *excentricidad* es la relación entre los ejes mayor y menor. También existen estimaciones relacionadas para la redondez y la convexidad.\n\nObserve la excentricidad de las diferentes formas en @fig-eccentricity.\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/fig-eccentricity_c858418d54fa2842620801b9c1cc522c'}\n::: {.cell-output-display}\n![Algunos ejemplos de formas y sus estadísticas de excentricidad.](premade/morphology.svg){#fig-eccentricity fig-align='center' fig-alt='Algunos ejemplos de formas y sus estadísticas de excentricidad. Los círculos y cuadrados tienen los valores de excentricidad más pequeños, mientras que las formas X y los relámpagos tienen los valores más grandes. Además, la excentricidad es la misma cuando se giran las formas.' width=95%}\n:::\n:::\n\n\nLas formas como círculos y cuadrados tienen una excentricidad baja, mientras que las formas oblongas tienen valores altos. Además, la métrica no se ve afectada por la rotación del objeto.\n\nMuchas de estas características de la imagen tienen altas correlaciones; es más probable que los objetos con áreas grandes tengan perímetros grandes. A menudo existen varios métodos para cuantificar las mismas características subyacentes (por ejemplo, tamaño).\n\nEn los datos de los frijoles, se calcularon las características morfológicas de 16: area, perimeter, major axis length, minor axis length, aspect ratio, eccentricity, convex area, equiv diameter, extent, solidity, roundness, compactness, shape factor 1, shape factor 2, shape factor 3, and shape factor 4. Los últimos cuatro se describen en @symons1988211.\n\nPodemos comenzar cargando los datos:\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-import_683e3bfe9a7175644a9b0b944dfdf341'}\n\n```{.r .cell-code}\nlibrary(tidymodels)\ntidymodels_prefer()\nlibrary(beans)\n```\n:::\n\n\n::: rmdwarning\nEs importante mantener una buena disciplina de datos al evaluar técnicas de reducción de dimensionalidad, especialmente si las utilizará dentro de un modelo.\n:::\n\nPara nuestros análisis, comenzamos reteniendo un conjunto de pruebas con `initial_split()`. Los datos restantes se dividen en conjuntos de entrenamiento y validación:\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-split_a8ee4ff4ed5eafc5e696039aef08a504'}\n\n```{.r .cell-code}\nset.seed(1601)\nbean_split <- initial_validation_split(beans, strata = class, prop = c(0.75, 0.125))\n## Warning: Too little data to stratify.\n## • Resampling will be unstratified.\nbean_split\n## <Training/Validation/Testing/Total>\n## <10206/1702/1703/13611>\n\n# Devolver marcos de datos:\nbean_train <- training(bean_split)\nbean_test <- testing(bean_split)\nbean_validation <- validation(bean_split)\n\nset.seed(1602)\n# Devuelve un objeto 'rset' para usarlo con las funciones de sintonización:\nbean_val <- validation_set(bean_split)\nbean_val$splits[[1]]\n## <Training/Validation/Total>\n## <10206/1702/11908>\n```\n:::\n\n\nPara evaluar visualmente qué tan bien funcionan los diferentes métodos, podemos estimar los métodos en el conjunto de entrenamiento (n = 10,206 beans) y mostrar los resultados usando el conjunto de validación ( n = `formato r(nrow(bean_validation), big.mark = \",\")`).\n\nAntes de comenzar cualquier reducción de dimensionalidad, podemos dedicar algún tiempo a investigar nuestros datos. Como sabemos que muchas de estas características de forma probablemente miden conceptos similares, echemos un vistazo a la estructura de correlación de los datos en @fig-beans-corr-plot usando este código.\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-corr-plot_03bd6f789a93b78cbbfd275c6e51c95a'}\n\n```{.r .cell-code}\nlibrary(corrplot)\ntmwr_cols <- colorRampPalette(c(\"#91CBD765\", \"#CA225E\"))\nbean_train %>% \n  select(-class) %>% \n  cor() %>% \n  corrplot(col = tmwr_cols(200), tl.col = \"black\", method = \"ellipse\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/fig-beans-corr-plot_1cfa3364feebf6130adba3af34cc8ffd'}\n::: {.cell-output-display}\n![Matriz de correlación de los predictores con variables ordenadas mediante clustering](16-dimensionality-reduction_files/figure-html/fig-beans-corr-plot-1.png){#fig-beans-corr-plot fig-align='center' fig-alt='Una matriz de correlación de los predictores con variables ordenadas mediante clustering. Hay dos o tres grupos que tienen altas correlaciones dentro del grupo.' width=70%}\n:::\n:::\n\n\nMuchos de estos predictores están altamente correlacionados, como el área y el perímetro o los factores de forma 2 y 3. Si bien no nos tomamos el tiempo para hacerlo aquí, también es importante ver si esta estructura de correlación cambia significativamente entre las categorías de resultados. Esto puede ayudar a crear mejores modelos.\n\n## Una Receta Inicial\n\nEs hora de mirar los datos de los beans en un espacio más pequeño. Podemos comenzar con una receta básica para preprocesar los datos antes de cualquier paso de reducción de dimensionalidad. Varios predictores son razones y, por lo tanto, es probable que tengan distribuciones sesgadas. Estas distribuciones pueden causar estragos en los cálculos de varianza (como los que se utilizan en PCA). El paquete [<span class=\"pkg\">bestNormalize</span>](https://petersonr.github.io/bestNormalize/) tiene un paso que puede imponer una distribución simétrica para los predictores. Usaremos esto para mitigar el problema de las distribuciones sesgadas:\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-initial-rec_1fc6236c8d354fefa57cfd612d973486'}\n\n```{.r .cell-code}\nlibrary(bestNormalize)\nbean_rec <-\n  # Utilice los datos de entrenamiento del objeto dividido bean_val\n  recipe(class ~ ., data = bean_train) %>%\n  step_zv(all_numeric_predictors()) %>%\n  step_orderNorm(all_numeric_predictors()) %>% \n  step_normalize(all_numeric_predictors())\n```\n:::\n\n\n::: rmdnote\nRecuerde que al invocar la función `recipe()` los pasos no se estiman ni ejecutan de ninguna manera.\n:::\n\nEsta receta se ampliará con pasos adicionales para los análisis de reducción de dimensionalidad. Antes de hacerlo, repasemos cómo se puede utilizar una receta fuera de un flujo de trabajo.\n\n## Recetas en la naturaleza {#sec-recipe-functions}\n\nComo se menciona en @sec-using-recipes, un flujo de trabajo que contiene una receta usa `fit()` para estimar la receta y el modelo, luego `predict()` para procesar los datos y hacer predicciones del modelo. Hay funciones análogas en el paquete <span class=\"pkg\">recipes</span> que se pueden usar para el mismo propósito:\n\n-   `prep(recipe, training)` ajusta la receta al conjunto de entrenamiento.\n-   `bake(recipe, new_data)` aplica las operaciones de la receta a `new_data`.\n\n@fig-recipe-process resume esto. Veamos cada una de estas funciones con más detalle.\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/fig-recipe-process_661d216de769a6146b91df563bfae289'}\n::: {.cell-output-display}\n![Resumen de funciones relacionadas con recetas](premade/recipes-process.svg){#fig-recipe-process fig-align='center' fig-alt='Un resumen de las funciones relacionadas con recetas.' width=80%}\n:::\n:::\n\n\n### Preparando una receta {#sec-prep}\n\nEstimemos `bean_rec` usando los datos del conjunto de entrenamiento, con `prep(bean_rec)`:\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-prep-rec_9ac89fc3a4d187eff11d20ea4e020da1'}\n\n```{.r .cell-code}\nbean_rec_trained <- prep(bean_rec)\nbean_rec_trained\n## \n## ── Recipe ───────────────────────────────────────────────────────────────────────────\n## \n## ── Inputs\n## Number of variables by role\n## outcome:    1\n## predictor: 16\n## \n## ── Training information\n## Training data contained 10206 data points and no incomplete rows.\n## \n## ── Operations\n## • Zero variance filter removed: <none> | Trained\n## • orderNorm transformation on: area, perimeter, major_axis_length, ... | Trained\n## • Centering and scaling for: area, perimeter, major_axis_length, ... | Trained\n```\n:::\n\n\n::: rmdnote\nRecuerde que `prep()` para una receta es como `fit()` para un modelo.\n:::\n\nTenga en cuenta en el resultado que los pasos han sido entrenados y que los selectores ya no son generales (es decir, `all_numeric_predictors()`); ahora muestran las columnas reales que se seleccionaron. Además, `prep(bean_rec)` no requiere el argumento `training`. Puede pasar cualquier dato a ese argumento, pero omitirlo significa que se utilizarán los \"datos\", `data`, originales de la llamada a `recipe()`. En nuestro caso, estos fueron los datos del conjunto de entrenamiento.\n\nUn argumento importante para `prep()` es `retain`. Cuando `retain = TRUE` (el valor predeterminado), la versión estimada del conjunto de entrenamiento se mantiene dentro de la receta. Este conjunto de datos ha sido preprocesado siguiendo todos los pasos enumerados en la receta. Dado que `prep()` tiene que ejecutar la receta a medida que avanza, puede ser ventajoso mantener esta versión del conjunto de entrenamiento para que, si ese conjunto de datos se va a utilizar más adelante, se puedan evitar cálculos redundantes. Sin embargo, si el conjunto de entrenamiento es grande, puede resultar problemático mantener una cantidad tan grande de datos en la memoria. Utilice `retain = FALSE` para evitar esto.\n\nUna vez que se agregan nuevos pasos a esta receta estimada, volver a aplicar `prep()` estimará solo los pasos no entrenados. Esto será útil cuando probemos diferentes métodos de extracción de características.\n\n::: rmdwarning\nSi encuentra errores al trabajar con una receta, puede usar `prep()` con su opción `verbose` para solucionar problemas:\n:::\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-prep-fail_383b35adeaec819917a893f708431d58'}\n\n```{.r .cell-code}\nbean_rec_trained %>% \n  step_dummy(cornbread) %>%  # <- no es un predictor real\n  prep(verbose = TRUE)\n## oper 1 step zv [pre-trained]\n## oper 2 step orderNorm [pre-trained]\n## oper 3 step normalize [pre-trained]\n## oper 4 step dummy [training]\n## Error in `step_dummy()`:\n## Caused by error in `prep()`:\n## ! Can't subset columns that don't exist.\n## ✖ Column `cornbread` doesn't exist.\n```\n:::\n\n\nOtra opción que puede ayudarte a entender lo que sucede en el análisis es `log_changes`:\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-prep-log_f2e2bce74f81b2dea854f9512b0db0c9'}\n\n```{.r .cell-code}\nshow_variables <- \n  bean_rec %>% \n  prep(log_changes = TRUE)\n## step_zv (zv_RLYwH): same number of columns\n## \n## step_orderNorm (orderNorm_Jx8oD): same number of columns\n## \n## step_normalize (normalize_GU75D): same number of columns\n```\n:::\n\n\n### Hornear la receta {#sec-bake}\n\n::: rmdnote\nUsar `bake()` con una receta es muy parecido a usar `predict()` con un modelo; las operaciones estimadas a partir del conjunto de entrenamiento se aplican a cualquier dato, como datos de prueba o datos nuevos en el momento de la predicción.\n:::\n\nPor ejemplo, las muestras del conjunto de validación se pueden procesar:\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-bake_6cfc9542c1b7ab2f231462916c505e58'}\n\n```{.r .cell-code}\nbean_val_processed <- bake(bean_rec_trained, new_data = bean_validation)\n```\n:::\n\n\n@fig-bean-area muestra histogramas del predictor de `area` antes y después de que se preparara la receta.\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-bake-off_da512fc61a202aa54f92d19fa27a23e0'}\n\n```{.r .cell-code}\nlibrary(patchwork)\np1 <- \n  bean_validation %>% \n  ggplot(aes(x = area)) + \n  geom_histogram(bins = 30, color = \"white\", fill = \"blue\", alpha = 1/3) + \n  ggtitle(\"Datos del conjunto de validación original\")\n\np2 <- \n  bean_val_processed %>% \n  ggplot(aes(x = area)) + \n  geom_histogram(bins = 30, color = \"white\", fill = \"red\", alpha = 1/3) + \n  ggtitle(\"Datos del conjunto de validación procesados\")\n\np1 + p2\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/fig-bean-area_d9b0771f699362018a47e17d5fe86bee'}\n::: {.cell-output-display}\n![El predictor de `area` antes y después del preprocesamiento](16-dimensionality-reduction_files/figure-html/fig-bean-area-1.png){#fig-bean-area fig-align='center' fig-alt='El predictor de `area` antes y después del preprocesamiento. El panel anterior muestra una distribución ligeramente bimodal y sesgada hacia la derecha. El panel de popa tiene una distribución bastante acampanada.' width=672}\n:::\n:::\n\n\nAquí vale la pena señalar dos aspectos importantes de `bake()`.\n\nPrimero, como se mencionó anteriormente, el uso de `prep(recipe, retener = TRUE)` mantiene la versión procesada existente del conjunto de entrenamiento en la receta. Esto permite al usuario utilizar `bake(recipe, new_data = NULL)`, que devuelve ese conjunto de datos sin más cálculos. Por ejemplo:\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-new-data-null_5752c6f54d3ec71782c0dba705e734b0'}\n\n```{.r .cell-code}\nbake(bean_rec_trained, new_data = NULL) %>% nrow()\n## [1] 10206\nbean_train %>% nrow()\n## [1] 10206\n```\n:::\n\n\nSi el conjunto de entrenamiento no es patológicamente grande, usar este valor de `retain` puede ahorrar mucho tiempo de cálculo.\n\nEn segundo lugar, se pueden utilizar selectores adicionales en la llamada para especificar qué columnas devolver. El selector predeterminado es `everything()`, pero se pueden usar directivas más específicas.\n\nUsaremos `prep()` y `bake()` en la siguiente sección para ilustrar algunas de estas opciones.\n\n## Técnicas de extracción de características\n\nDado que las recetas son la opción principal en tidymodels para la reducción de dimensionalidad, escribamos una función que estime la transformación y represente los datos resultantes en una matriz de diagrama de dispersión a través del paquete <span class=\"pkg\">ggforce</span>:\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-function_cfb3f9c93c1f32caf62554496d6561d5'}\n\n```{.r .cell-code}\nlibrary(ggforce)\nplot_validation_results <- function(recipe, dat = bean_validation) {\n  recipe %>%\n    # Calcule los pasos adicionales\n    prep() %>%\n    # Procesar los datos (la validación establecida por defecto)\n    bake(new_data = dat) %>%\n    # Crear la matriz del diagrama de dispersión\n    ggplot(aes(x = .panel_x, y = .panel_y, color = class, fill = class)) +\n    geom_point(alpha = 0.4, size = 0.5) +\n    geom_autodensity(alpha = .3) +\n    facet_matrix(vars(-class), layer.diag = 2) + \n    scale_color_brewer(palette = \"Dark2\") + \n    scale_fill_brewer(palette = \"Dark2\")\n}\n```\n:::\n\n\nReutilizaremos esta función varias veces en este capítulo.\n\nAquí se exploran una serie de varias metodologías de extracción de características. Se puede encontrar una descripción general de la mayoría en la [Sección 6.3.1](https://bookdown.org/max/FES/numeric-many-to-many.html#linear-projection-methods) de @fes y las referencias allí contenidas. . El método UMAP se describe en @mcinnes2020umap.\n\n### Análisis de componentes principales\n\nYa hemos mencionado la PCA varias veces en este libro y es hora de entrar en más detalles. PCA es un método no supervisado que utiliza combinaciones lineales de predictores para definir nuevas características. Estas características intentan dar cuenta de la mayor variación posible en los datos originales. Agregamos `step_pca()` a la receta original y usamos nuestra función para visualizar los resultados en el conjunto de validación en @fig-bean-pca usando:\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-pca_791cca172fa6db2ef03645959c4df7e3'}\n\n```{.r .cell-code}\nbean_rec_trained %>%\n  step_pca(all_numeric_predictors(), num_comp = 4) %>%\n  plot_validation_results() + \n  ggtitle(\"Análisis de componentes principales\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/fig-bean-pca_e7c788e53541784fd7269e0f652cf629'}\n::: {.cell-output-display}\n![Puntuaciones de los componentes principales para el conjunto de validación de beans, coloreadas por clase](16-dimensionality-reduction_files/figure-html/fig-bean-pca-1.png){#fig-bean-pca fig-align='center' fig-alt='Puntuaciones de los componentes principales para el conjunto de validación de beans, coloreadas por clase. Las clases se separan cuando los dos primeros componentes se comparan entre sí.' width=672}\n:::\n:::\n\n\nVemos que los dos primeros componentes `PC1` y `PC2`, especialmente cuando se usan juntos, hacen un trabajo eficaz al distinguir o separar las clases. Esto puede llevarnos a esperar que el problema general de clasificar estos granos no sea especialmente difícil.\n\nRecuerde que PCA no está supervisada. Para estos datos, resulta que los componentes del PCA que explican la mayor variación en los predictores también predicen las clases. ¿Qué características son el rendimiento de conducción? El paquete <span class=\"pkg\">learntidymodels</span> tiene funciones que pueden ayudar a visualizar las características principales de cada componente. Necesitaremos la receta preparada; el paso PCA se agrega en el siguiente código junto con una llamada a `prep()`:\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-pca-loadings_1a73d15fc72de72233d79ff9a046f4c4'}\n\n```{.r .cell-code}\nlibrary(learntidymodels)\nbean_rec_trained %>%\n  step_pca(all_numeric_predictors(), num_comp = 4) %>% \n  prep() %>% \n  plot_top_loadings(component_number <= 4, n = 5) + \n  scale_fill_brewer(palette = \"Paired\") +\n  ggtitle(\"Análisis de Componentes Principales\")\n```\n:::\n\n\nEsto produce @fig-pca-loadings.\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/fig-pca-loadings_17dc7976b817320c3632d5f1f37dffc8'}\n::: {.cell-output-display}\n![Cargas de predictores para la transformación PCA.](16-dimensionality-reduction_files/figure-html/fig-pca-loadings-1.png){#fig-pca-loadings fig-align='center' fig-alt='Cargas de predictores para la transformación PCA. Para el primer componente, la longitud del eje mayor, el segundo factor de forma, el área convexa y el área tienen el mayor efecto.' width=672}\n:::\n:::\n\n\nLas cargas superiores están relacionadas principalmente con el grupo de predictores correlacionados que se muestran en la parte superior izquierda del gráfico de correlación anterior: perímetro, área, longitud del eje principal y área convexa. Todos estos están relacionados con el tamaño del frijol. El factor de forma 2, de @symons1988211, es el área sobre el cubo de la longitud del eje mayor y, por lo tanto, también está relacionado con el tamaño del frijol. Las medidas de alargamiento parecen dominar el segundo componente de PCA.\n\n### Mínimos cuadrados parciales {#sec-partial-least-squares}\n\nPLS, que presentamos en @sec-submodel-trick, es una versión supervisada de PCA. Intenta encontrar componentes que maximicen simultáneamente la variación en los predictores y al mismo tiempo maximicen la relación entre esos componentes y el resultado. @fig-bean-pls muestra los resultados de esta versión ligeramente modificada del código PCA:\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-pls_30fe9c154dcc55724c953e2b12afe3e1'}\n\n```{.r .cell-code}\nbean_rec_trained %>%\n  step_pls(all_numeric_predictors(), outcome = \"class\", num_comp = 4) %>%\n  plot_validation_results() + \n  ggtitle(\"Mínimos cuadrados parciales\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/fig-bean-pls_e65105112779cd3842fb321a0eaf2749'}\n::: {.cell-output-display}\n![Puntuaciones de componentes PLS para el conjunto de validación de beans, coloreadas por clase](16-dimensionality-reduction_files/figure-html/fig-bean-pls-1.png){#fig-bean-pls fig-align='center' fig-alt='Puntuaciones de componentes PLS para el conjunto de validación de beans, coloreadas por clase. Los dos primeros componentes PLS son casi idénticos a los dos primeros componentes PCA.' width=672}\n:::\n:::\n\n\n¡Los dos primeros componentes PLS trazados en @fig-bean-pls son casi idénticos a los dos primeros componentes PCA! Encontramos este resultado porque esos componentes de PCA son muy efectivos para separar las variedades de frijoles. Los componentes restantes son diferentes. @fig-pls-loadings visualiza las cargas, las características principales de cada componente.\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-pls-loadings_20fb1ec705c638cf1e991aa433c701fa'}\n\n```{.r .cell-code}\nbean_rec_trained %>%\n  step_pls(all_numeric_predictors(), outcome = \"class\", num_comp = 4) %>%\n  prep() %>% \n  plot_top_loadings(component_number <= 4, n = 5, type = \"pls\") + \n  scale_fill_brewer(palette = \"Paired\") +\n  ggtitle(\"Mínimos cuadrados parciales\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/fig-pls-loadings_beaa5c65fb380f46e48e5c51f8806cbb'}\n::: {.cell-output-display}\n![Predictor loadings for the PLS transformation](16-dimensionality-reduction_files/figure-html/fig-pls-loadings-1.png){#fig-pls-loadings fig-align='center' fig-alt='Predictor loadings for the PLS transformation. For the first component, the major axis length, second shape factor, the equivalent diameter, convex area, and area have the largest effect. ' width=672}\n:::\n:::\n\n\nLa solidez (es decir, la densidad del grano) impulsa el tercer componente del PLS, junto con la redondez. La solidez puede estar capturando características del frijol relacionadas con las \"baches\" de la superficie del frijol, ya que puede medir la irregularidad de los límites del frijol.\n\n### Análisis de componentes independientes\n\nICA (Análisis de componentes independientes) es ligeramente diferente a PCA en que encuentra componentes que son lo más independientes estadísticamente posible entre sí (en lugar de no estar correlacionados). Se puede considerar que maximiza la \"no gaussianidad\" de los componentes de ICA, o separa información en lugar de comprimir información como PCA. Usemos `step_ica()` para producir @fig-bean-ica:\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-ica_ba8cde8f9eb14058cad001040dd5a167'}\n\n```{.r .cell-code}\nbean_rec_trained %>%\n  step_ica(all_numeric_predictors(), num_comp = 4) %>%\n  plot_validation_results() + \n  ggtitle(\"Análisis de componentes independientes\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/fig-bean-ica_e18ba411e633dfc95749e8b862351a34'}\n::: {.cell-output-display}\n![Puntuaciones de componentes ICA para el conjunto de validación de beans, coloreadas por clase](16-dimensionality-reduction_files/figure-html/fig-bean-ica-1.png){#fig-bean-ica fig-align='center' fig-alt='Puntuaciones de componentes ICA para el conjunto de validación de beans, coloreadas por clase. Existe una importante superposición en los dos primeros componentes del ICA.' width=672}\n:::\n:::\n\n\nAl inspeccionar este gráfico, no parece haber mucha separación entre las clases en los primeros componentes cuando se usa ICA. Estos componentes independientes (o lo más independientes posible) no separan los tipos de frijoles.\n\n### Aproximación y proyección de variedades uniformes.\n\nUMAP es similar al popular método t-SNE para la reducción de dimensiones no lineales. En el espacio original de alta dimensión, UMAP utiliza un método de vecino más cercano basado en la distancia para encontrar áreas locales de los datos donde es más probable que los puntos de datos estén relacionados. La relación entre puntos de datos se guarda como un modelo de gráfico dirigido donde la mayoría de los puntos no están conectados.\n\nA partir de ahí, UMAP traduce los puntos del gráfico al espacio dimensional reducido. Para hacer esto, el algoritmo tiene un proceso de optimización que utiliza entropía cruzada para asignar puntos de datos al conjunto más pequeño de características para que el gráfico sea bien aproximado.\n\nPara crear el mapeo, el paquete <span class=\"pkg\">embed</span> contiene una función de paso para este método, visualizada en @fig-bean-umap.\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-umap_d053e7636586c7fa6361dfd59acd87e7'}\n\n```{.r .cell-code}\nlibrary(embed)\nbean_rec_trained %>%\n  step_umap(all_numeric_predictors(), num_comp = 4) %>%\n  plot_validation_results() +\n  ggtitle(\"UMAP\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/fig-bean-umap_8b53786f838aee92a7976beb6846a7e4'}\n::: {.cell-output-display}\n![Puntuaciones de componentes UMAP para el conjunto de validación de beans, coloreadas por clase](16-dimensionality-reduction_files/figure-html/fig-bean-umap-1.png){#fig-bean-umap fig-align='center' fig-alt='Puntuaciones de componentes UMAP para el conjunto de validación de beans, coloreadas por clase. Existe un grado muy alto de separación entre los grupos, pero varios de ellos contienen más de una clase.' width=672}\n:::\n:::\n\n\nSi bien el espacio entre grupos es pronunciado, los grupos pueden contener una mezcla heterogénea de clases.\n\nTambién existe una versión supervisada de UMAP:\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-umap-supervised_e65724d6eb2ef2374b0ede7c2f25834d'}\n\n```{.r .cell-code}\nbean_rec_trained %>%\n  step_umap(all_numeric_predictors(), outcome = \"class\", num_comp = 4) %>%\n  plot_validation_results() +\n  ggtitle(\"UMAP (supervisado)\")\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/fig-bean-umap-supervised_96a533cfeff492b3d03d12e049354124'}\n::: {.cell-output-display}\n![Puntajes de componentes UMAP supervisados para el conjunto de validación de beans, coloreados por clase](16-dimensionality-reduction_files/figure-html/fig-bean-umap-supervised-1.png){#fig-bean-umap-supervised fig-align='center' fig-alt='Puntuaciones de componentes UMAP supervisadas para el conjunto de validación de beans, coloreadas por clase. Nuevamente hay un grado muy alto de separación entre los clústeres y ahora hay menos instancias de un clúster que contiene múltiples clases.' width=672}\n:::\n:::\n\n\nEl método supervisado que se muestra en @fig-bean-umap-supervised parece prometedor para modelar los datos.\n\nUMAP es un método poderoso para reducir el espacio de funciones. Sin embargo, puede ser muy sensible a los parámetros de ajuste (por ejemplo, el número de vecinos, etc.). Por esta razón, sería útil experimentar con algunos de los parámetros para evaluar qué tan sólidos son los resultados de estos datos.\n\n## Modelado {#sec-bean-models}\n\nVale la pena investigar tanto el método PLS como el UMAP junto con diferentes modelos. Exploremos una variedad de modelos diferentes con estas técnicas de reducción de dimensionalidad (sin ninguna transformación): una red neuronal de una sola capa, árboles en bolsas, análisis discriminante flexible (FDA), Bayes ingenuo y análisis discriminante regularizado (RDA).\n\nAhora que volvemos al \"modo de modelado\", crearemos una serie de especificaciones de modelo y luego usaremos un conjunto de flujo de trabajo para ajustar los modelos en el siguiente código. Tenga en cuenta que los parámetros del modelo se ajustan junto con los parámetros de la receta (por ejemplo, tamaño de la dimensión reducida, parámetros UMAP).\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-models_649620a411b151e735cf59019be67a6d'}\n\n```{.r .cell-code}\nlibrary(baguette)\nlibrary(discrim)\n\nmlp_spec <-\n  mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>%\n  set_engine('nnet') %>%\n  set_mode('classification')\n\nbagging_spec <-\n  bag_tree() %>%\n  set_engine('rpart') %>%\n  set_mode('classification')\n\nfda_spec <-\n  discrim_flexible(\n    prod_degree = tune()\n  ) %>%\n  set_engine('earth')\n\nrda_spec <-\n  discrim_regularized(frac_common_cov = tune(), frac_identity = tune()) %>%\n  set_engine('klaR')\n\nbayes_spec <-\n  naive_Bayes() %>%\n  set_engine('klaR')\n```\n:::\n\n\nTambién necesitamos recetas para los métodos de reducción de dimensionalidad que probaremos. Comencemos con una receta base `bean_rec` y luego ampliémosla con diferentes pasos de reducción de dimensionalidad:\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-recipes_a5365b1b177f96dd56120e534e8a44a8'}\n\n```{.r .cell-code}\nbean_rec <-\n  recipe(class ~ ., data = bean_train) %>%\n  step_zv(all_numeric_predictors()) %>%\n  step_orderNorm(all_numeric_predictors()) %>%\n  step_normalize(all_numeric_predictors())\n\npls_rec <- \n  bean_rec %>% \n  step_pls(all_numeric_predictors(), outcome = \"class\", num_comp = tune())\n\numap_rec <-\n  bean_rec %>%\n  step_umap(\n    all_numeric_predictors(),\n    outcome = \"class\",\n    num_comp = tune(),\n    neighbors = tune(),\n    min_dist = tune()\n  )\n```\n:::\n\n\nUna vez más, el paquete <span class=\"pkg\">workflowsets</span> toma los preprocesadores y modelos y los cruza. La opción `control` `parallel_over` está configurada para que el procesamiento paralelo pueda funcionar simultáneamente en todas las combinaciones de parámetros de ajuste. La función `workflow_map()` aplica la búsqueda de cuadrícula para optimizar los parámetros del modelo/preprocesamiento (si los hay) en 10 combinaciones de parámetros. El área multiclase bajo la curva ROC se estima en el conjunto de validación.\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-workflows_165d0a2b4ff88670df17b35234b975a6'}\n\n```{.r .cell-code}\nctrl <- control_grid(parallel_over = \"everything\")\nbean_res <- \n  workflow_set(\n    preproc = list(basic = class ~., pls = pls_rec, umap = umap_rec), \n    models = list(bayes = bayes_spec, fda = fda_spec,\n                  rda = rda_spec, bag = bagging_spec,\n                  mlp = mlp_spec)\n  ) %>% \n  workflow_map(\n    verbose = TRUE,\n    seed = 1603,\n    resamples = bean_val,\n    grid = 10,\n    metrics = metric_set(roc_auc),\n    control = ctrl\n  )\n```\n:::\n\n\nPodemos clasificar los modelos según sus estimaciones del conjunto de validación del área bajo la curva ROC:\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-ranked_9557b7109453e340b7d9d091bfe9c6a7'}\n\n```{.r .cell-code}\nrankings <- \n  rank_results(bean_res, select_best = TRUE) %>% \n  mutate(method = map_chr(wflow_id, ~ str_split(.x, \"_\", simplify = TRUE)[1])) \n\ntidymodels_prefer()\nfilter(rankings, rank <= 5) %>% dplyr::select(rank, mean, model, method)\n## # A tibble: 5 × 4\n##    rank  mean model               method\n##   <int> <dbl> <chr>               <chr> \n## 1     1 0.996 mlp                 pls   \n## 2     2 0.996 discrim_regularized pls   \n## 3     3 0.995 discrim_flexible    basic \n## 4     4 0.995 naive_Bayes         pls   \n## 5     5 0.994 naive_Bayes         basic\n```\n:::\n\n\n@fig-dimensionality-rankings ilustra esta clasificación.\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/fig-dimensionality-rankings_af8b4a99d409981a0d4ffb6b7ecb37fb'}\n::: {.cell-output-display}\n![Área bajo la curva ROC del conjunto de validación](16-dimensionality-reduction_files/figure-html/fig-dimensionality-rankings-1.png){#fig-dimensionality-rankings fig-align='center' fig-alt='Área bajo la curva ROC del conjunto de validación. Las tres mejores configuraciones de modelo utilizan PLS junto con un análisis discriminante regularizado, un perceptrón multicapa y un modelo ingenuo de Bayes.' width=672}\n:::\n:::\n\n\nDe estos resultados se desprende claramente que la mayoría de los modelos ofrecen muy buen rendimiento; hay pocas malas decisiones aquí. Para la demostración, usaremos el modelo RDA con características PLS como modelo final. Finalizaremos el flujo de trabajo con los mejores parámetros numéricamente, lo ajustaremos al conjunto de entrenamiento y luego lo evaluaremos con el conjunto de prueba:\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-final_561862722924589c2e252b8da39f5260'}\n\n```{.r .cell-code}\nrda_res <- \n  bean_res %>% \n  extract_workflow(\"pls_rda\") %>% \n  finalize_workflow(\n    bean_res %>% \n      extract_workflow_set_result(\"pls_rda\") %>% \n      select_best(metric = \"roc_auc\")\n  ) %>% \n  last_fit(split = bean_split, metrics = metric_set(roc_auc))\n\nrda_wflow_fit <- extract_workflow(rda_res)\n```\n:::\n\n\n¿Cuáles son los resultados de nuestra métrica (ROC AUC multiclase) en el conjunto de pruebas?\n\n\n::: {.cell layout-align=\"center\" hash='16-dimensionality-reduction_cache/html/dimensionality-test_65b460ff7cd31b06c3b3859f19df19ca'}\n\n```{.r .cell-code}\ncollect_metrics(rda_res)\n## # A tibble: 1 × 4\n##   .metric .estimator .estimate .config             \n##   <chr>   <chr>          <dbl> <chr>               \n## 1 roc_auc hand_till      0.995 Preprocessor1_Model1\n```\n:::\n\n\n¡Bastante bien! Usaremos este modelo en el próximo capítulo para demostrar métodos de importancia variable.\n\n\n\n\n\n## Resumen del capítulo {#sec-dimensionality-summary}\n\nLa reducción de dimensionalidad puede ser un método útil para el análisis exploratorio de datos y el modelado. Los paquetes <span class=\"pkg\">recipes</span> y <span class=\"pkg\">embed</span> contienen pasos para una variedad de métodos diferentes y <span class=\"pkg\">workflowsets</span> facilita la elección de un método apropiado para un conjunto de datos. Este capítulo también analizó cómo se pueden usar recetas por sí solas, ya sea para depurar problemas con una receta o directamente para análisis exploratorio de datos y visualización de datos.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}